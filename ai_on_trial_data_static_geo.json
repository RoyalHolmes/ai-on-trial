[
  {
    "region":"United States",
    "court":"Texas District Court",
    "caseName":"A.F., on behalf of J.F. v. Character Technologies, Inc.",
    "year":2024,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":"The complainants allege that, due to its defective design, the Character AI system is not safe to consumers, particularly youth, and led to psychological and physical harms to a minor.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/69450881\/af-on-behalf-of-jf-v-character-technologies-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"A.T. v. OpenAI LP",
    "year":2023,
    "issue":"Privacy",
    "finalDecision":"Yes",
    "summary":"The complainants allege that the practices of web-scraping violate privacy and property interests related to the data of the class members. The court granted the defendant\u2019s motion to dismiss, noting that, although being almost 200 pages long, the complaint failed to state why the plaintiffs are entitled to relief. The complainants gave notice that they did not intend to proceed with amendments of their complaint, and the case was closed.",
    "excerpt":"\"Here, the complaint is not only excessive in length, but also contains swaths of\nunnecessary and distracting allegations making it nearly impossible to determine the adequacy of\nthe plaintiffs\u2019 legal claims. To cite just a couple of examples, the plaintiffs spend over five pages\non how various political leaders and European governments have reacted to recent advancements\nin AI technology and three-plus pages discussing copyright concerns even though none of the\nplaintiffs assert a copyright claim. [\u2026] In addition to the irrelevant portions of the complaint, the plaintiffs also include rhetoric and policy grievances that are not suitable for resolution by federal courts.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/67764022\/t-v-openai-lp\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Illinois Circuit Court",
    "caseName":"ACLU v. Clearview AI, Inc.",
    "year":2020,
    "issue":"Biometrics",
    "finalDecision":"Yes",
    "summary":"The complainants allege that data collection to develop Clearview\u2019s facial recognition systems without individual consent violates Illinois Biometric Information Privacy Act. A settlement was reached in which Clearview agrees to deny access to Clearview to any private entity or individual and, for a period of 5 years, any Illinois State and Local agencies. Moreover, Clearview agrees to delete the facial vectors that existed before private access to the system was terminated, and to filter Illinois-based photographs from the Clearview App. Finally, an opt-out program for Illinois residents will be created. ",
    "excerpt":"- ",
    "link":"https:\/\/www.aclu.org\/cases\/aclu-v-clearview-ai#; https:\/\/www.courthousenews.com\/wp-content\/uploads\/2022\/05\/aclu-v-clearview-settlement.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Massachussets District Court",
    "caseName":"ACLU v. DOJ",
    "year":2019,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"The complaint pursued the production of public records related to the DOJs use of facial recognition programs, based on the Freedom of Information Act. The action was closed without entry of judgement, and could be re-opened upon motions by any party if any further action was required. In 2024, the parties jointly moved to reopen the action and stipulated that it be dismissed.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/16407892\/american-civil-liberties-union-v-united-states-department-of-justice\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Advance Local Media LLC v. Cohere",
    "year":2025,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complaint comes from a group of news publishers that allege Cohere used their articles to train AI models, committing direct copyright infringement. Furthermore, they also argue that, if users are held as the liable party for copyright infringement, Cohere would still have committed indirect infringement.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/69636122\/advance-local-media-llc-v-cohere-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Colorado District Court",
    "caseName":"Allen v. Perlmutter",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"Although the complainant created an AI-assisted image through several hundred iterations with the system, they were denied authorship by the Copyright Office. The denial is being questioned in the Court.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/69198079\/allen-v-perlmutter\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Authors Guild v. OpenAI, Inc.",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The consolidated complaint alleges a class of copyright owners had their rights violated during OpenAI AI models\u2019 training. The classes are delimited by authors of nonfiction books with an ISBN number and authors of fiction registered with the Copyright Office.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67810584\/authors-guild-v-openai-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District of New Jersey",
    "caseName":"Altman et al v. Caesars Entertainment, Inc. et al",
    "year":2023,
    "issue":"Antitrust",
    "finalDecision":"No",
    "summary":"The complainants allege a group of hotel operators (MGM Resorts, Hard Rock, etc.) had been sharing pricing algorithms to set prices higher than they could in competitive conditions.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67354519\/altman-v-caesars-entertainment-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the Northern District of California",
    "caseName":"Andersen v. Stability AI Ltd.",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The complainants are visual artists that argue their works have been used to train the Stable Diffusion model, which infringe copyright, violate their rights of publicity, represent unfair competition. They also argue that copyright management information has been unduly removed. The Court first dismissed the copyright complaints of the artists that did not have registered their works. The Court also concluded several of the claims did not have enough background to proceed as is, but leave to amend was granted. An amended complaint was later filed. The Court dismissed several claims, but let the copyright infringement ones proceed.",
    "excerpt":"\"Defendants\u2019 motions to dismiss the DMCA claims are GRANTED and the DMCA claims\nare DISMISSED WITH PREJUDICE. Defendants\u2019 motions to dismiss the unjust enrichment\nclaims are GRANTED and those claims are DISMISSED with leave to amend. Defendants\u2019\nmotions to dismiss the Copyright Act claims are DENIED. Midjourney\u2019s motion to dismiss the\nLanham Act claims is DENIED. DeviantArt\u2019s motion to dismiss the breach of contract and breach\nof the implied covenant of good faith and fair dealing claims is GRANTED and those claims are\nDISMISSED WITH PREJUDICE.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/66732129\/andersen-v-stability-ai-ltd\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Pennsylvania",
    "caseName":"Anderson v. Tiktok, Inc.",
    "year":2022,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"The complainant argue the design of Tiktok\u2019s algorithm had promoted dangerous challenges to her daughter, leading to her death. The District Court dismissed the lawsuit, pursuant Section 230c of the Communications Decency Act. The Third Circuit reversed the decision as it held the algorithm for promoting and moderating content consists first-party expressive activity from TikTok.",
    "excerpt":"\"Here, as alleged, TikTok\u2019s FYP algorithm \u201c[d]ecid[es]\non the third-party speech that will be included in or excluded\nfrom a compilation\u2014and then organiz[es] and present[s] the\nincluded items\u201d on users\u2019 FYPs. NetChoice, 144 S. Ct. at\n2402. Accordingly, TikTok\u2019s algorithm, which recommended\nthe Blackout Challenge to Nylah on her FYP, was TikTok\u2019s\nown \u201cexpressive activity,\u201d id., and thus its first-party speech.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/67500541\/tawainna-anderson-v-tiktok-inc\/; https:\/\/www.courtlistener.com\/docket\/63306022\/anderson-v-tiktok-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Arkansas Court of Appeals",
    "caseName":"Arkansas Department of Human Service v. Ledgerwood ",
    "year":2017,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"Arkansas changed from a method for determining patient\u2019s Attendant Care Hours that relied on human determination to an algorithm (ArChoice), cutting attendant hours for almost half of the patients. The Circuit Court granted an injunction against the algorithm. The Department then passed an Emergency Rule that granted nurses moderate discretion to adjust the hours after the algorithms\u2019 determination, which led to a finding of contempt that was later reversed by the Supreme Court of Arkansas.",
    "excerpt":"\"DHS contends it did not violate the express terms of the permanent injunction order when adopting the emergency rule. It therefore seeks reversal of the circuit court's order holding the agency in contempt. Because we conclude the rule was properly promulgated under the Administrative Procedure Act's (APA) emergency rulemaking provision, we find DHS did not violate the express terms of the circuit court's order. We reverse the order of contempt.\u201d",
    "link":"https:\/\/casetext.com\/case\/ark-dept-of-human-servs-v-ledgerwood-3",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court of Massachussets",
    "caseName":"Baker v. CVS Health Corporation ",
    "year":2023,
    "issue":"Labor",
    "finalDecision":"No",
    "summary":"The complainant argue CVS uses automated software from Hirevue to determine employability scores in violation of Massachussets General Laws chapter 149, section 19B(2)(b), which prohibits the use of lie detector tests. The case was finally settled.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67546027\/baker-v-cvs-health-corporation\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Palm Beach County District Court",
    "caseName":"Banner, Kim v. Tesla",
    "year":2019,
    "issue":"Autonomous Vehicles",
    "finalDecision":"Yes",
    "summary":"The complainant alleges that, due to Tesla\u2019s autopilot function lacking a crash avoidance system, her husband died in a car collision. The Circuit Court allowed the Estate to plead punitive damages but, on appeal, the decision was reversed because the Estate failed to prove gross negligence on the part of Tesla, that is, that it knew or should have known their driving assistance was likely to cause physical harm to drivers.",
    "excerpt":"\"The record does not support a finding that Tesla knew, or reasonably should have known, that its SAE Level 2 driving assistance features were likely to cause death or great bodily injury. Instead, the evidence indicates Tesla's Autopilot features were \u201cstate-of-the-art\u201d and complied with all industry and regulatory standards. Further, Tesla repeatedly warned against misuse of the features, which was industry practice. While the Estate's expert testified that Tesla is liable for gross negligence and intentional misconduct in \u201ctwenty ways,\u201d Tesla cannot be liable for failing to provide technology that it did not advertise and that did not exist.\u201d",
    "link":"https:\/\/caselaw.findlaw.com\/court\/fl-district-court-of-appeal\/117000103.html",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Kentucky Western District Court",
    "caseName":"Barrows et al v. Humana, Inc.",
    "year":2023,
    "issue":"Insurance",
    "finalDecision":"No",
    "summary":"The complainants allege the insurance company Humana\u2019s AI model wrongfully denies elderly patients from the Medicare Advantage medical care, overriding the judgement of human doctors.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68084618\/barrows-v-humana-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Michigan",
    "caseName":"Barry v. Lion",
    "year":2021,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"Michigan used an automated program to compare lists of those receiving Supplemental Nutrition Assistance Program benefits and felony warrants, as individuals fleeing confinement are not entitled to the Program. When a match was found, the benefits were terminated without disqualification notice. The District Court found the sole existence of a felony warrant, as currently searched by Michigan, is not enough for automated halting of the benefits without valid disqualification notices. The Sixth Circuit upheld the decision.",
    "excerpt":"\"The court was equally correct in finding that the state had deprived the plaintiffs of their\nright to assistance under the SNAP Act based on what was missing from Michigan law, i.e., the\nconditions precedent to valid disqualification under federal law: the felon in question must be\n(1) actively \u201cfleeing\u201d (2) to avoid prosecution for a crime that is a felony \u201cunder the law of the place from which the individual is fleeing,\u201d and the authorities must be (3) \u201cactively seeking\u201d to\nprosecute him or her for the offense.5 The district court correctly declared invalid the Michigan\nfugitive-felon policy and the portions of Michigan statutes on which the policy was based,\nentered summary judgment for the plaintiffs, and enjoined the state from automatically\ndisqualifying plaintiffs and other class members from receiving SNAP benefits based solely on\nan outstanding felony warrant.",
    "link":"https:\/\/www.courtlistener.com\/opinion\/4251251\/walter-barry-v-nick-lyon\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Bartz v. Anthropic PBC",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants allege Anthropic pirated versions of their nonfiction and fiction works to train AI models, violating their copyrights.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/69058235\/bartz-v-anthropic-pbc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of California District Court",
    "caseName":"Bason v. RealPage, Inc.",
    "year":2022,
    "issue":"Antitrust",
    "finalDecision":"No",
    "summary":"The complainants allege RealPage and their property management clients use algorithmic systems to fix prices superior to those that would occur in competitive conditions. The case was later voluntarily dismissed, without prejudice.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/65589222\/bason-v-realpage-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Michigan",
    "caseName":"Bauseman v. Unemployment Insurance Agency",
    "year":2015,
    "issue":"Administrative use of AI",
    "finalDecision":"No",
    "summary":"The complainants allege Michigan\u2019s use of automated fraud detection systems violated their due process rights in the context of receiving unemployment benefits. The Michigan Supreme Court agreed with the District Court that the complainants held a constitutional tort claim to receive monetary damages and remanded the case to the Court of Claims. The case was finally settled for 20 million dollars and the State agreed to refund over 100% of what the automated system claimed the plaintiffs owed.",
    "excerpt":"-",
    "link":"https:\/\/caselaw.findlaw.com\/court\/mi-supreme-court\/1991676.html",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"New York Nassau County Court",
    "caseName":"Berliner v. Nassau County",
    "year":2019,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainants allege Nassau\u2019s County use of automated systems to assess residential market values in the context of property tax led to inaccurate assessments and was not transparent.",
    "excerpt":"-",
    "link":"https:\/\/trellis.law\/case\/36059\/er22350679\/eric-berliner-v-nassau-county",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Louisiana",
    "caseName":"Bertuccelli v. Universal City Studios LLC",
    "year":2020,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"AI facial recognition was used in an expert assessment of the similarity between two masks as part of a copyright dispute. There was a motion to dismiss the evidence, but the court held the use of AI was valid. The case was later settled.",
    "excerpt":"\"The\nCourt finds Dr. Griffor\u2019s methodology reliable given that he conducted an artificial intelligence\nassisted facial recognition analysis of the King Cake Baby and Happy Death Day mask to\ndetermine whether the use of mathematics and target facial recognition algorithms comparing the\ntwo works would find that human perception would view the works as substantially similar.\nAccordingly, the Court finds Dr. Griffor is qualified to testify as an expert in this case\u201d",
    "link":"https:\/\/storage.courtlistener.com\/recap\/gov.uscourts.laed.229252\/gov.uscourts.laed.229252.253.0_1.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Middle District of Tennessee",
    "caseName":"Bright v. Brookdale Senior Living, Inc.",
    "year":2019,
    "issue":"Public services",
    "finalDecision":"No",
    "summary":"The complainants allege that Brookdale uses a staffing algorithm (Service Alignment Service) that underestimates the staffing requirements of assisted living facilities, in an deceptive and unfair trade practice and in a breach of contract. Class certification was denied due to not meeting the tipicality requirement.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/15066469\/bright-v-brookdale-senior-living-inc\/?page=3",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Virginia Circuit Court",
    "caseName":"Brooks v. Commonwealth",
    "year":2004,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"The complainant alleges statistical risk assessment factors used to assess recidivism led him to be sentenced to 10 years in prison, the maximum sentence to statutory rape. The Court of Appeals recognized that, as the sentence was within statutory limits, the trial court exercised discretion, even if its judgement was based on the risk assessment factors.",
    "excerpt":"\"Statutory rape is punishable by imprisonment from 2 to 10 years. Code \u00a7\u00a7 18.2-10 and -63. The trial court imposed a sentence within that statutory limit. The record plainly shows the trial judge considered the guidelines when fixing sentence but noted that each case \"rises and falls on its own.\" The judge explained, \"the Court uses its best judgment in sentencing\" and sentences \"within the parameters fixed by the statute.\" The trial court properly exercised its discretion, and accordingly, we affirm its decision.\u201d",
    "link":"https:\/\/casetext.com\/case\/brooks-v-commonwealth-2540-02",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Oregon District Court",
    "caseName":"C.S. et al v. Saiki",
    "year":2017,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainants question the use of the ANA-C\/CNA-C assessments tools by the Oregon Office of Developmental Disability Services to assess in-home attendant hours for those with developmental disabilities. A preliminary injunction was granted.",
    "excerpt":"\"The defendants may use the ANA-C or\nCNA-C to evaluate people with developmental or intellectual disabilities, but may not reduce in-\nhome attendant care services to a person receiving those services below the status quo level of\ncare: that level designated in the most recent ANA-C or CNA-C as of November 1, 2016\u201d",
    "link":"https:\/\/docs.justia.com\/cases\/federal\/district-courts\/oregon\/ordce\/6:2017cv00564\/131242\/11",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Michigan",
    "caseName":"Cahoo v. SAS Analytics Inc.",
    "year":2017,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainants allege Michigan\u2019s use of automated fraud detection systems violated their due process rights in the context of receiving unemployment benefits. The system led claimants to be falsely accused of fraud and automatically receive a penalty equal to 5x the benefits received. Class certification was denied. On the fact-specific individual claims, the Court found MiDAS provided enough notice and did not immediately deprive claimants of their property.",
    "excerpt":"\"Yes, MiDAS\u2019s logic trees spawned internal, interim fraud findings that marked\nindividuals for further review. But that internal step did not deprive a claimant of property. As\nnoted, those property deprivations came months or years later, following notices of deprivation\nand a multi-level appeal process. The missing link, then, is a case that clearly established the\ninadequacy of the questionnaires, notices of determination, and appeal processes available in the\nrun-up to the property deprivation. To this day, the plaintiffs have not provided that case. What precedent there was would not have clearly alerted Moffett-Massey and Geskey to the\nconstitutional inadequacies of the questionnaires and notices as to these plaintiffs and these\nproperty deprivations. See Rosen, 410 F.3d at 931; Shoemaker, 795 F.3d at 560; DePiero, 180\nF.3d at 788; Herrada, 275 F.3d at 557.\"",
    "link":"https:\/\/www.courtlistener.com\/docket\/4617065\/cahoo-v-sas-analytics-inc\/?page=4",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the Northern District of Illinois",
    "caseName":"Carmean v. Macy\u2019s Retail Holdings, Inc.",
    "year":2020,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"Claimants allege Macy\u2019s use of Clearview facial recognition software on over 6000 customers, without obtaining their consent, is illegal under the Biometric Information Privacy Act. The case was voluntarily dismissed.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/17428602\/carmine-v-macys-retail-holdings-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the Northern District of Illinois",
    "caseName":"Carpenter v. McDonald\u2019s Corporation",
    "year":2021,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"Claimants allege the drive-through voice assistant used in McDonald\u2019s restaurants are capable to collect and obtain a voiceprint, in violation of the Biometric Information Privacy Act. The case was settled. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/59950073\/carpenter-v-mcdonalds-corporation\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court of the Middle District of Tennessee",
    "caseName":"Cherry et al v. RealPage Inc et al",
    "year":2022,
    "issue":"Antitrust",
    "finalDecision":"No",
    "summary":"Claimants allege RealPage price-fixing software sets prices higher than those in competitive conditions for renting multifamily housing units, based on private competitor data. The claim survived a motion to dismiss.",
    "excerpt":"-",
    "link":"https:\/\/www.govinfo.gov\/app\/details\/USCOURTS-tnmd-3_23-cv-00332\/USCOURTS-tnmd-3_23-cv-00332-1\/context",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court of the Northern District of California",
    "caseName":"Concord Music Group, Inc. v. Anthropic PBC",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"Music publishers allege Anthropic infringes their copyrighted songs lyrics both by using it as input to train their models and in the output generated by the models.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68889092\/concord-music-group-inc-v-anthropic-pbc\/?page=2",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the District of Connecticut",
    "caseName":"Connecticut Fair Housing Center et al v. CoreLogic Rental Property",
    "year":2018,
    "issue":"Bias",
    "finalDecision":"Yes",
    "summary":"The complainants allege the automated tenant-screening software provided by CoreLogic to third-parties violates the Fair Housing Act insofar as it uses criminal records as rental criteria, which disproportionately disadvantage Black and Latino tenants. The District Court considered CoreLogic is not subject to the Fair Housing Act. An appeal was filed.",
    "excerpt":"\"The Plaintiffs have not met their \nburden in showing that CoreLogic in any way sets the terms, conditions, or \nprivileges of rental.                                                     \n    Accordingly, the central question is whether CoreLogic \u201cmakes unavailable \nor denies\u201d housing.   \u201cCongress\u2019 use of the phrase \u2018otherwise make unavailable\u2019 \n\nrefers to the consequences of an action rather than the actor\u2019s intent.\u201d (\u2026) The Plaintiffs did not prove their first theory: that CrimSAFE disqualifies \napplicants.  The Court finds that the evidence at trial establishes CrimSAFE \n\nmatched applicants with data, but it was the housing provider\u2014not CrimSAFE\u2014\nthat decided whether an applicant is qualified for housing.  The housing provider \ncontrols the disqualification process by making four key decisions in how it uses \nCrimSAFE: (1) who within their organization receives criminal reports, (2) what \ncriminal records are relevant for their decision, (3) how to review the records, and \n(4) when to accept an applicant.",
    "link":"https:\/\/www.courtlistener.com\/opinion\/9632548\/connecticut-fair-housing-ctr-v-corelogic-rental-property-solutions-llc\/?q=3:18-cv-00705",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Daily News LP v. Microsoft Corporation",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"DailyNews allege the defendants infringed their copyright when they used published articles without permission nor payment to aid the development and commercialization of generative AI products, such as ChatGPT and Copilot.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68484432\/daily-news-lp-v-microsoft-corporation\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of Illinois",
    "caseName":"Deyerler v. Hirevue Inc.",
    "year":2022,
    "issue":"Biometrics",
    "finalDecision":"Yes",
    "summary":"The complainants allege Hirevue\u2019s software\u2019s use of biometrical data without consent violates Illinois Biometric Information Privacy Act. A motion to dismiss based on lack of jurisdiction was denied as the software was marketed and sold to companies in Illinois and used to capture the Plaintiff\u2019s identifiers. The only material claim that the Court held the plaintiff\u2019s failed to state was selling, leasing, trading or profiting from biometric data, as it understood Hirevue profits from the software, not from selling biometrical data per se.",
    "excerpt":"\"The plaintiffs allege that HireVue profited from their biometric information\nbecause its clients paid for use of its software. (FAC \u00b6 26.) But the fact that HireVue\nprofited from the sale of its software does not plausibly indicate that it sold, leased,\ntraded, or otherwise profited from the plaintiffs\u2019 biometric data itself.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/63153815\/deyerler-v-hirevue-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of Illinois",
    "caseName":"Dinerstein v. Google, LLC",
    "year":2021,
    "issue":"Privacy",
    "finalDecision":"Yes",
    "summary":"University of Chicago and Google had partnered to create a predictive health software, through de-identified electronic health records. The complainant, who was a patient of the University, argued Google had enough data points to re-identify the patients (based on the records and the geolocation from Google apps), in a breach of contract and medical confidentiality. The case was dismissed and the decision was affirmed on appeal, as the Seventh Circuit understood it lacked plausibility.",
    "excerpt":"\"We start with the backward-looking form of injury. Cru-\ncially, Dinerstein does not allege that Google has already\nused the disclosed patient records to discern his identity.\nInstead he focuses on the conduct of the University, arguing\nthat the record transfer was itself an actionable invasion of\nhis medical privacy. This is so, Dinerstein asserts, regardless\nof whether Google ever actually identifies him. (\u2026) Put differently, just because some\nde-identification processes might be deficient, we cannot\nassume that the University\u2019s process was necessarily so. To\nthe contrary, the complaint acknowledges that the chal-\nlenged record transfer occurred pursuant to the Data Use\nAgreement, which states that \u201cthe majority of [patient]\nidentifiers will be removed,\u201d leaving only \u201cactual dates of\n[medical] service and events.\u201d Dinerstein\u2019s allegations of\ninsufficient anonymization therefore do not cross the plausi-\nbility threshold. See Silha v. ACT, Inc., 807 F.3d 169, 174 (7th\nCir. 2015) (\u201c[T]he Twombly-Iqbal facial plausibility require-\nment for pleading a claim is incorporated into the standard\nfor pleading subject matter jurisdiction.\u201d).\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/15841645\/dinerstein-v-google-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Superior Court of the District of Columbia",
    "caseName":"District of Columbia v. RealPage Inc et al.",
    "year":2023,
    "issue":"Antitrust",
    "finalDecision":"No",
    "summary":"The complainant alleges RealPage and their property management clients use algorithmic systems to fix prices superior to those that would occur in competitive conditions. Motion to dismiss was denied as the claims were considered plausible.",
    "excerpt":"\"Here, the Complaint plausibly alleges that\nJBG entered into agreement with the other Defendant Landlords because (i) the District alleges\nthat JBG and the Defendant Landlords engaged in parallel conduct when each entered into a\ncontract to share proprietary data through RealPage and almost invariably implemented the rents\nRealPage generated using their pooled data, and (ii) in combination with certain plus factors, this\nparallel conduct makes out a plausible case for conspiracy because it would not be in JBG\u2019s\ninterests to share proprietary pricing data with its competitors in the absence of an agreement to\nfix rents at the RealPage-generated prices\u201d",
    "link":"https:\/\/business.cch.com\/ald\/DistrictofColumbiavRealPageInc792024.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Divino Group LLC v. Google LLC",
    "year":2019,
    "issue":"Bias",
    "finalDecision":"Yes",
    "summary":"The complainants allege Youtube\u2019s restricted mode, which enables users to disable access that was automatically identified as adult, discriminate against LGBT content creators. The claims are dismissed, as there is no contract provision to require Youtube to post the content creator\u2019s posts on its platform, it has broad discretion on removing content and there was no contractual provision that required Youtube to apply its guidelines equally.",
    "excerpt":"\"As confirmed at oral argument, plaintiffs do not contend that there is an express contract\nprovision requiring defendants to post plaintiffs\u2019 videos on YouTube. Nor do plaintiffs deny that\ndefendants have broad discretion in deciding whether to remove, restrict, or demonetize content on\nYouTube. See Dkt. No. 136 (Mar. 21, 2023 Tr. at 26:20-27:4; 28:14-22; 38:1-9). Rather, plaintiffs claim that defendants\u2019 various \u201cForm Agreements, including the TOS [Terms of Service] Rules, Google\u2019s Privacy Policy, and related agreement(s)\u201d require defendants to apply their rules\nand policies equally to everyone. (\u2026) Plaintiffs acknowledge that there is no express contractual provision that prohibits\ndefendants from discriminating against plaintiffs based on their sexual or gender orientation or\nviewpoints. See Dkt. No. 136 (Mar. 21, 2023 Tr. at 21:8-11). They nonetheless maintain that\nYouTube\u2019s Community Guidelines, as a whole, are part of the various Terms of Service between\nplaintiffs and YouTube, and that the above-quoted provision, in particular, supports an implied\ncovenant that defendants will only remove, restrict, or demonetize plaintiffs\u2019 videos based on the\nvideos\u2019 content in the same manner they remove, restrict, or demonetize the videos of other\nYouTube users, and not based on the identities of the persons who created or posted that content. (\u2026)Unlike the statement in Block, the subject language from YouTube\u2019s Community\nGuidelines (i.e., that the Guidelines are \u201cappl[ied]. . . to everyone equally\u2014regardless of the\nsubject or the creator\u2019s background, political viewpoint, position, or affiliation\u201d) is more than a\nmere description of how YouTube works. Rather, the statement reasonably may be construed as\nan affirmative representation about how defendants apply and enforce the Guidelines\u2014namely,\nthat the Guidelines will be applied without regard to a \u201ccreator\u2019s background, political viewpoint,\nposition, or affiliation.\u201d (\u2026)However, defendants persuasively argue that the cited Community Guidelines cannot\nplausibly be the basis for plaintiffs\u2019 implied covenant claim, asserting that the subject text about\napplying those rules to \u201ceveryone equally\u201d was not added to the Community Guidelines until\nsometime in 2021, years after the moderation decisions alleged in plaintiffs\u2019 complaint.6\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/16054313\/divino-group-llc-v-google-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Doe 1 v. Github, Inc.",
    "year":2022,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"Complainants allege the Copilot coding tool was trained on open-source code available in the Github platform, without proper attribution, in a breach of contract. They also alleged DMCA violations due to copyright management information removal, but this claim was dismissed with prejudice. The dismissal was appealed and will be analyzed by the Ninth Circuit. The breach of contract claim survived a motion to dismiss.",
    "excerpt":"\"Plaintiffs advance claims for breach of the eleven suggested licenses GitHub presents to\nusers that require (1) attribution to the owner, (2) inclusion of a copyright notice, and (3) inclusion\nof the license terms. Compl. \u00b6 34 n.4. Plaintiffs attach each of these licenses to the complaint.\nPlaintiffs allege that use of licensed code \u201cis allowed only pursuant to the terms of the applicable\nSuggested License,\u201d and that each such license requires that any derivative work or copy include\nattribution, a copyright notice, and the license terms. Id. \u00b6\u00b6 173, 34 n.4. Plaintiffs further allege\nthat Codex and Copilot reproduce licensed code as output without attribution, copyright notice, or\nlicense terms, thereby violating the relevant provisions of each license. While Plaintiffs do not\nidentify the specific subsections of each suggested license that correspond to each of these\nrequirements, the Court finds that Plaintiffs have sufficiently identified \u201cthe contractual\nobligations allegedly breached,\u201d as required to plead a breach of contract claim. Williams, 449 F.\nSupp. 3d at 908.\nDefendants\u2019 motions to dismiss Plaintiffs\u2019 claim for breach of license is denied.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/65669506\/doe-1-v-github-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Dow Jones & Company, Inc. v. Perplexity AI, Inc.",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants, which are the publishers of The Wall Street Journal and the New York Post, among others, allege Perplexity\u2019s models, fueled by Retrieval-Augmented Generation, infringe on their copyright.",
    "excerpt":"- ",
    "link":"https:\/\/www.courtlistener.com\/docket\/69280523\/dow-jones-company-inc-v-perplexity-ai-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Dubus v. NVIDIA Corporation",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants allege their books were used to train NVIDIA\u2019s LLMs without their consent, as they were in The Pile database.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68497292\/dubus-v-nvidia-corporation\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Washington District Court",
    "caseName":"Duffy v. Yardi Systems, Inc.",
    "year":2023,
    "issue":"Antitrust",
    "finalDecision":"No",
    "summary":"The complainants allege that the automated pricing model called Revenue IQ, developed by the defendant, was used to price fix rents of multifamily units, as, instead of competing, the companies in the market colluded in using Revenue IQ.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67775053\/duffy-v-yardi-systems-inc\/?page=2",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"California Superior Court",
    "caseName":"Elon Musk v. Samuel Altman et al",
    "year":2024,
    "issue":"Corporate Law",
    "finalDecision":"No",
    "summary":"The complainant alleges OpenAI was created to develop models to benefit humanity, through non-profit activities. When the company achieved AGI, the software was supposed to be made available open-source. However, the company has since operated with closed models and with a capped-profit branch, including partnerships with other companies such as Microsoft. Thus, the complainant alleges OpenAI's founding agreement has been breached. Later, the complainant also sought an order to stop OpenAI from becoming a for-profit business through corporate structuring.",
    "excerpt":"-",
    "link":"https:\/\/webapps.sftc.org\/ci\/CaseInfo.dll?CaseNum=CGC24612746&SessionID=A4CF2F59A5FB2D6C1C8B1660D013D42FC7E0F937",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of New York",
    "caseName":"Equal Employment Opportunity Commission v. iTutorGroup",
    "year":2022,
    "issue":"Labor",
    "finalDecision":"No",
    "summary":"The Equal Employment Opportunity Commission alleged that iTutorGroup\u2019s platform hiring software automatically discarded older applicants. Equal applications, differing only by date of birth, led to different results, with only the younger applicant being selected. The case was settled and the company will pay over 300k USD to the harmed job candidates. ",
    "excerpt":"-",
    "link":"https:\/\/blogs.gwu.edu\/law-eti\/ai-litigation-database\/case-detail-page\/?equal-employment-opportunity-commission-v-itutorgroup-inc&pid=120",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court of Minnesota",
    "caseName":"Estate of Gene B. Lokken et al v. UnitedHealth Group, Inc. ",
    "year":2023,
    "issue":"Public services",
    "finalDecision":"Yes",
    "summary":"The complainants question UnitedHealth\u2019s use of AI software (nH Predict) to deny coverage, overriding physician\u2019s determinations. Several claims were considered preempted under the Medicare Act, but the breach of contract, breach of implied covenant of good faith and fair dealing were allowed to proceed. ",
    "excerpt":"\"Both the breach of contract and breach of implied covenant of good faith and fair\ndealing claims are not preempted. In these claims, Plaintiffs allege that UHC explicitly\ndescribed claim decisions as being made by \u201cclinical services staff\u201d and \u201cphysicians,\u201d\nwithout mention of any artificial intelligence. (Am. Compl. \u00b6 187.) These claims thus\neffectively arise out of UHC\u2019s evidence of coverage documents because the question\nwould be whether UHC complied with its statement that claim decisions would be made\nby \u201cclinical services staff\u201d and \u201cphysicians\u201d when it allegedly used artificial intelligence.\nThus, in analyzing these claims the Court would only be required to investigate whether\nUHC complied with its own written documents. Because ruling on these two claims would\nrequire the Court to only apply basic contract principles, the breach of contract and\nbreach of the implied covenant of good faith and fair dealing claims do not regulate the\nsame subject matter as the Medicare Act, and thus are not preempted.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/68006832\/estate-of-gene-b-lokken-the-v-unitedhealth-group-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the Middle District of Florida",
    "caseName":"e-Ventures Worldwide, LLC v. Google, LLC",
    "year":2014,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The complainants allege Google removed hundred of websites associated with e-Ventures from Google\u2019s search listings, which undermined their economic activity. They claim tortious interference and defamation under the Florida\u2019s Deceptive and Unfair Trade Practices Act. During the proceedings, the websites were found to be filled with spam. The matter was dismissed with prejudice as the Court understood Google\u2019s content removal decisions were as protected by the First Amendment as were decisions made by newspaper editors. ",
    "excerpt":"\"But there is a more fundamental reason why the First Amendment bars e-ventures\u2019\nclaims. Google\u2019s actions in formulating rankings for its search engine and in determining\nwhether certain websites are contrary to Google\u2019s guidelines and thereby subject to\nremoval are the same as decisions by a newspaper editor regarding which content to\npublish, which article belongs on the front page, and which article is unworthy of\npublication. The First Amendment protects these decisions, whether they are fair or\nunfair, or motivated by profit or altruism.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/4227514\/e-ventures-worldwide-llc-v-google-llc\/?page=2",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the Northern District of California",
    "caseName":"Faridian v. DoNotPay, Inc.",
    "year":2023,
    "issue":"Legal profession",
    "finalDecision":" No",
    "summary":"The complainants allege DoNotPay advertises its services as \u201cThe World\u2019s First Robot Lawyer\u201d, although they are not carried out by certified lawyers and provide substandard materials. They claim unlawful, unfair and fraudulent business practices under California\u2019s Unfair Competition Law. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67158596\/faridian-v-donotpay-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Flora v. Prisma Labs, Inc.",
    "year":2023,
    "issue":"Biometrics",
    "finalDecision":"Yes",
    "summary":"The complainants allege the defendant company\u2019s app Lensa stores user biometric data without obtaining their consent, in violation of the Illinois Biometric Information Act. However, arbitration was compelled due to a clause in the app\u2019s Terms of Use.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/66815972\/flora-v-prisma-labs-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Flores v. Stanford",
    "year":2019,
    "issue":"Criminal justice",
    "finalDecision":"No",
    "summary":"The complainants argue New York State Board of Parole\u2019s use of the COMPAS system during parole determination is discriminatory as the system considers youth as an factor of increased risk. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/6338529\/flores-v-stanford\/?page=3",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of New York",
    "caseName":"Force v. Facebook",
    "year":2016,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The complainants allege Facebook\u2019s promotion algorithms aided Hamas to reach users, resulting in terrorist attacks. The District Court considered Facebook was immunized under Section 230, which was upheld by the Second Circuit.",
    "excerpt":"\"Facebook's choices\nas to who may use its platform are inherently bound up in its decisions as to what may be said on\nits platform, and so liability imposed based on its failure to remove users would equally \"derive[]\nfrom [Facebook's] status or conduct as a 'publisher or speaker.'\" LeadClick Media. 838 F.3d\nat 175 (internal quotation marks and citations omitted). Section 230(c)(1) prevents courts from\nentertaining civil actions^ ^ that seek to impose liability on defendants like Facebook for allowing\nthird parties to post offensive or harmful content or failing to remove such content once posted.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/4521277\/force-v-facebook-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Western District of Washington",
    "caseName":"Federal Trade Commission v. Amazon",
    "year":2023,
    "issue":"Antitrust",
    "finalDecision":null,
    "summary":"The FTC alleges that Amazon has engaged in anticompetitive and monopolist behavior, through, among other mechanisms, an algorithm called Project Nessie which could determine the extent to which price raises would be followed by competitors. The claim regarding Project Nessie survived a motion to dismiss.",
    "excerpt":"\"Plaintiffs allege that when Amazon began testing Project Nessie, \u201c[t]hese early\nexperiments showed that \u2018in many cases competitors match us at the higher price.\u2019\u201d Dkt. # 171\nat 127. Plaintiffs also allege \u201cAmazon realized that it could increase its prices while reducing\nthe risk of shoppers finding a lower price off Amazon if Amazon focused its price increases on\nproducts sold by competitors that were matching Amazon\u2019s prices.\u201d Id. at 127\u201328 (emphasis\nadded). \u201cArmed with the knowledge that others would likely follow its price hikes, Amazon\ncould charge shoppers higher prices while minimizing the chance that shoppers would catch on.\u201d\nId. at 128 (emphasis added).\nTaking Plaintiffs\u2019 factual allegations as true and construing them in the light most\nfavorable to Plaintiffs, the Court determines that these allegations suffice to allege\nanticompetitive intent and purpose.\u201d",
    "link":"https:\/\/www.ftc.gov\/legal-library\/browse\/cases-proceedings\/1910129-1910130-amazoncom-inc-amazon-ecommerce",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Pennsylvania",
    "caseName":"FTC v. Rite Aid Corporation",
    "year":2023,
    "issue":"Biometrics",
    "finalDecision":"Yes",
    "summary":"The FTC alleges Rite Aid violated several provisions of Section 5 of the FTC Act by using facial recognition software to match consumers with shoplifting databases. In this sense, the FTC argues RiteAid did not ensure or test if the system had adequate accuracy nor took steps to mitigate the risks of disparate impacts for consumers of protected groups. They also allege Rite Aid failed to comply with a 2010 FTC Data Security Order. The stipulation order required Rite Aid to create safeguards for the use of its systems, banned use of facial recognition systems for surveillance in the next 5 years, determined the deletion of ill-gotten data, including that of models developed using the biometrical data, among others.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68101251\/federal-trade-commission-v-rite-aid-corporation\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Middle District of Florida",
    "caseName":"Garcia v. Character Technologies",
    "year":2024,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":"The complainant alleges Character.AI system exchanged romantic and sexual texts with her 14 year old son, who later died by suicide, claiming liability for the defective design of the system. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/69300919\/garcia-v-character-technologies-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District of Delaware",
    "caseName":"Getty Images, Inc. v. Stability AI, Inc.",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"Getty Images argues Stability AI used its images without consent to train their models, infringing on their copyright. Moreover, the complainant argues that, since Stable Diffusion has generated its watermark in its outputs, their trademark has also been infringed upon.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/66788385\/getty-images-us-inc-v-stability-ai-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District of Nevada",
    "caseName":"Gibson v. CENDYN Group, LLC",
    "year":2023,
    "issue":"Antitrust",
    "finalDecision":"Yes",
    "summary":"The complainant alleges Cendyn Group and other hotel operators colluded to inflate hotel rooms prices in Las Vegas through the pricing software offered by defendant. Motion to dismiss was granted. ",
    "excerpt":"\"For example, Plaintiffs\u2019 \u201ccomplaint does not answer the basic questions: who,\ndid what, to whom (or with whom) . . . and when?\u201d Kendall v. Visa U.S.A., Inc., 518 F.3d\n1042, 1048 (9th Cir. 2008). \u201c",
    "link":"https:\/\/www.courtlistener.com\/docket\/66760320\/gibson-v-mgm-resorts-international\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Gonzalez v. Google, LLC",
    "year":2017,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The complainants are the family of a US citizen who was killed in an ISIS attack. They allege Youtube recommended ISIS videos to users, and thus should be considered the publishers of those videos. The District Court considered Youtube to be shielded by Section 230. On appeal, the decision was upheld. Certioriati was granted by the Supreme Court. After the decision on Twitter v. Taamneh (family claims are not allowable under the Antiterrorism Act), the case was remanded to the Ninth Circuit. ",
    "excerpt":"\"In light of those unchallenged\nholdings and our disposition of Twitter, on which we also\ngranted certiorari and in which we today reverse the Ninth\nCircuit\u2019s judgment, it has become clear that plaintiffs\u2019 com-\nplaint\u2014independent of \u00a7230\u2014states little if any claim for\nrelief. As plaintiffs concede, the allegations underlying\ntheir secondary-liability claims are materially identical to\nthose at issue in Twitter. See Tr. of Oral Arg. 58. Since we\nhold that the complaint in that case fails to state a claim for\naiding and abetting under \u00a72333(d)(2), it appears to follow that the complaint here likewise fails to state such a claim.\nAnd, in discussing plaintiffs\u2019 revenue-sharing claims, the\nNinth Circuit held that plaintiffs plausibly alleged neither\nthat \u201cGoogle reached an agreement with ISIS,\u201d as required\nfor conspiracy liability, nor that Google\u2019s acts were \u201cin-\ntended to intimidate or coerce a civilian population, or to\ninfluence or affect a government,\u201d as required for a direct-\nliability claim under \u00a72333(a).\u201d",
    "link":"https:\/\/www.supremecourt.gov\/opinions\/22pdf\/21-1333_6j7a.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Western District of Wisconsin",
    "caseName":"Henderson v. Steinburg",
    "year":2018,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"The complainant alleges he was denied parole due to the use of COMPAS automated risk assessment, which is racially biased. However, it was found he received the lowest possible score both on Violent and General Recidivism Risk, and the case was dismissed. The complainant appealed to the Seventh Circuit.",
    "excerpt":"\"Ultimately, the disputed research on racial bias in COMPAS is immaterial for two\nreasons. First, some research suggests that COMPAS has a disparate impact on Black offenders,\nbut it does not directly support a claim of intentional race discrimination, which is what\nHenderson must show here. Second, and more important to this case, Henderson fails to\npresent evidence showing that his COMPAS assessment worked against him in the parole\nhearing. Henderson\u2019s COMPAS recidivism score was the lowest possible, so he cannot show\nthat his COMPAS recidivism score was the reason he was denied parole. Both sides\u2019 objections\nto the other\u2019s experts will be denied as moot.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/7457980\/henderson-titus-v-steinsberg-dean\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of Texas",
    "caseName":"Houston Federation of Teachers v. Houston Independent School District ",
    "year":2014,
    "issue":"Administrative use of AI",
    "finalDecision":"No",
    "summary":"The complainants question Houston Independent School District\u2019s use of value-added models in the context of teacher\u2019s contract\u2019s renewal, retirement, among others. The case was settled, provided the scores won\u2019t be used anymore to terminate contracts.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/6059688\/houston-federation-of-teachers-local-2415-v-houston-independent-school\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Florida Orange County Court",
    "caseName":"Hudson v. Tesla, Inc.",
    "year":2018,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":"The complainant alleges Tesla\u2019s autopilot feature is advertised as capable of detecting traffic hazards, but that his Model S crashed into another vehicle, causing him injuries. The case was voluntarily dismissed. ",
    "excerpt":"-",
    "link":"https:\/\/www.plainsite.org\/dockets\/3ha6x6ce4\/circuit-court-of-the-ninth-judicial-circuit\/hudson-shawn-v-tesla-inc-et-al\/?",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of Illinois",
    "caseName":"Huskey v. State Farm Fire & Casualty Company",
    "year":2022,
    "issue":"Bias",
    "finalDecision":"Yes",
    "summary":"The complainants allege the State Farm claims-processing system discriminates against Black applicants. The disparate claim survived a motion to dismiss.",
    "excerpt":"\"Third, Plaintiffs plausibly allege a connection between State Farm\u2019s policy and the\nstatistical racial disparities. From Plaintiffs\u2019 allegations describing how machine-learning\nalgorithms\u2014especially antifraud algorithms\u2014are prone to bias, the inference that State Farm\u2019s\nuse of algorithmic decision-making tools has resulted in longer wait times and greater scrutiny for\nBlack policyholders is plausible. No more is necessary. Plaintiffs have adequately alleged a\ndisparate-impact claim under \u00a7 3604(b) of the FHA.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/66635423\/huskey-v-state-farm-fire-casualty-company\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Securities and Exchange Commission",
    "caseName":"In the matter of BlueCrest Capital Management Limited",
    "year":2020,
    "issue":"Financial markets",
    "finalDecision":"Yes",
    "summary":"The case involves 2 funds managed by BlueCrest: its flagship hedge fund (BlueCrest Capital International - BCI) and its proprietary hedge fund (BSMA Limited - BSMA). The SEC notes BlueCrest transferred traders from BCI to BSMA, in which it had larger ownership interests, and employed an automated trading system in BCI. The system (Rates Management Trading - RMT) operated in a next-day basis and tracked some of the activity of the live traders. RMT systematically underperformed. Employing RMT in BCI created another conflict of interest: as RMT did not involve live traders, BlueCrest could retain a greater percentage of the performance fees (after all, it did not have to pay incentive compensation to the traders). The conflicts of interest were not adequately disclosed, nor was the use of RMT. BlueCrest was fined over 170 million USD.",
    "excerpt":"-",
    "link":"https:\/\/www.sec.gov\/files\/litigation\/admin\/2020\/33-10896.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of Illinois",
    "caseName":"In Re: Clearview AI, Inc., Consumer Privacy Litigation",
    "year":2021,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"This Multi-District Litigation involved the use by Clearview of individuals biometric data without their consent, which allegedly violated the Illinois Biometric Information Privacy Act. The case was settled and the class members were assigned an equity stake in Clearview AI.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/29102457\/in-re-clearview-ai-inc-consumer-privacy-litigation\/?page=4",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"In Re: Google Assistant Privacy Litigation",
    "year":2019,
    "issue":"Privacy",
    "finalDecision":"No",
    "summary":"Google Assistant is sometimes falsely activated (false accepts). Even in those cases, it provides a script of the audio recording, which is compared by human annotators to the audio recording, to improve the accuracy of the tool. The data from the audio recordings is recorded and used to target advertisement to users.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/15971537\/in-re-google-assistant-privacy-litigation\/?page=3",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"In Re: Google Generative AI Copyright Litigation",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The initial complaint concerned Google\u2019s collection of personal data and the removal copyright management information in the process of developing BARD systems. The motion to dismiss was granted with leave to amend, citing the reasoning of Court v. OpenAI, LP. The amended complaint was focused only on direct copyright infringement. The case  Levy v. Google was later consolidated with Zhang v. Google, and now addresses BARD and Imagen.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67599029\/l-v-alphabet-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"In Re: OpenAI ChatGPT Litigation",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":null,
    "summary":"Complainants make several copyright-related claims considering OpenAI\u2019s use of literary works during the development of its AI models. Several of the original claims were dismissed, including that of vicarious copyright infringement and the removal of copyright management information. The original case (Tremblay v. OpenAI) was consolidated with others and the consolidated complaint focuses only on direct copyright infringement and unfair competition. ",
    "excerpt":"\"Distinctly, Plaintiffs here have not alleged that the ChatGPT\noutputs contain direct copies of the copyrighted books. Because they fail to allege direct copying,\nthey must show a substantial similarity between the outputs and the copyrighted materials. See\nSkidmore, 952 F.3d at 1064; Corbello, 974 F.3d at 973-74.\nPlaintiffs\u2019 allegation that \u201cevery output of the OpenAI Language Models is an infringing\nderivative work\u201d is insufficient. Tremblay Compl. \u00b6 59; Silverman Compl. \u00b6 60. Plaintiffs fail to\nexplain what the outputs entail or allege that any particular output is substantially similar \u2013 or\nsimilar at all \u2013 to their books. Accordingly, the Court dismisses the vicarious copyright\ninfringement claim with leave to amend. (\u2026) Plaintiffs argue that OpenAI\u2019s failure to state which internet books it uses\nto train ChatGPT shows that it knowingly enabled infringement, because ChatGPT users will not\nknow if any output is infringing. Response at 21-22. However, Plaintiffs do not point to any\ncaselaw to suggest that failure to reveal such information has any bearing on whether the alleged\nremoval of CMI in an internal database will knowingly enable infringement. Plaintiffs have failed\nto state a claim under Section 12(b)(1).\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/67538258\/tremblay-v-openai-inc\/?page=3",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"In Re: Wells Fargo Mortgage Discrimination Litigation",
    "year":2022,
    "issue":"Bias",
    "finalDecision":"No",
    "summary":"The complainants allege Wells Fargo discriminated against Black and non-Black minorities in their loaning and refinancing processes through their automated system CORE. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/63052766\/in-re-wells-fargo-mortgage-discrimination-litigation\/?page=2",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Middle District of Tennessee",
    "caseName":"In Re: Realpage, Inc., Rental Software Antitrust Litigation",
    "year":2023,
    "issue":"Antitrust",
    "finalDecision":"Yes",
    "summary":"The DOJ opened an investigation into RealPage, arguing that its software algorithms facilitate price-fixing in the rental market of multifamily housing developers and student housing. The motion to dismiss the multifamily housing cases was denied, and the one related to student housing was granted. ",
    "excerpt":"\"At this stage of the case, the Court finds that Plaintiffs have plausibly alleged that\nDefendants engaged in parallel conduct when they each became RealPage RMS clients and began\nprioritizing raising rent prices over decreasing vacancy rates. This parallel conduct is consistent\nwith RealPage\u2019s pledge to its RMS clients that it will help them \u201coutperform the market,\u201d primarily\nthrough raising rent prices. Logic dictates and the Court understands Plaintiffs\u2019 allegations to state\nthat by 2016 the effects of this strategy change could be measured, at least in the four submarkets\nof Atlanta, Orlando, Phoenix, and Dallas.\u201d",
    "link":"https:\/\/www.tnmd.uscourts.gov\/sites\/tnmd\/files\/690.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"In Re: Social Media Adolescente Addiction",
    "year":2022,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"The complainants allege social media companies have designed their platforms in a way that exposes youth to addiction and harm, through maximizing scree time engagement. Several claims have been allowed to proceed.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/65407433\/in-re-social-media-adolescent-addictionpersonal-injury-products-liability\/?page=8",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Securities and Exchange Commission",
    "caseName":"In the matter of Delphia USA Inc.",
    "year":2024,
    "issue":"Financial markets",
    "finalDecision":"Yes",
    "summary":"The SEC charged Delphia with several violations to antifraud sections of the Advisers Act for arguing it used AI to analyze clients spending in order to direct its investments when it actually did not implement such AI system. The charges were settled for 400k USD.",
    "excerpt":"\"From at least August\n2019 to August 2023, Delphia represented that it used artificial intelligence and machine learning to\nanalyze its retail clients\u2019 spending and social media data to inform its investment advice when, in\nfact, no such data was being used in its investment process. After an examination by the\nCommission\u2019s Division of Examinations, Delphia agreed to correct the false and misleading\nstatements in 2021 and to take steps to ensure that no such statements were made in the future.\nWhile certain corrective efforts were made, additional false and misleading statements concerning\nthe use of its retail clients\u2019 data in the investment process continued to be made through August\n2023. In addition, Delphia failed to adopt and implement written policies and procedures\nreasonably designed to prevent violations of the Advisers Act and the rules adopted thereunder. As\na result of this conduct, Delphia willfully violated Sections 206(2) and 206(4) of the Advisers Act\nand Rules 206(4)-1 and 206(4)-7 thereunder.\u201d",
    "link":"https:\/\/www.sec.gov\/files\/litigation\/admin\/2024\/ia-6573.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Securities and Exchange Commission",
    "caseName":"In the matter of Global Predictions, Inc.",
    "year":2024,
    "issue":"Financial markets",
    "finalDecision":"Yes",
    "summary":"The SEC alleges Global Predictions violated the Advisers Act and the Marketing Rule for advertising it had AI-driven forecasts and AI financial advisors when it actually did not implement such systems. The charges were settled for 400k USD.",
    "excerpt":"\"This matter involves violations of the Advisers Act by Global Predictions by\nmaking false and misleading claims about its use of artificial intelligence (\u201cAI\u201d), its status as the\n\u201cfirst regulated AI financial advisor,\u201d and the services that it offered. (\u2026)\u201d",
    "link":"https:\/\/www.sec.gov\/files\/litigation\/admin\/2024\/ia-6574.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Central District of California",
    "caseName":"Inkie Lee v. Tesla, Inc.",
    "year":2020,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":"The complainants are owners of Tesla vehicles which allege their car\u2019s operating software had a sudden acceleration defect. Arbitration was compelled for most of the claims, apart from the request for public injunctive relief for California residents.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/16731676\/inkie-lee-v-tesla-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Central District of California",
    "caseName":"Jobiak LLC v. Botmakers LLC",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"Jobiak\u2019s platform scrapes Google results and creates AI-generated descriptions for job listings. They claim their database comprises of original material and, thus, could not be used by Botmakers without consent. Botmakers allege the AI-generated material is not copyright protected.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67877065\/jobiak-llc-v-botmakers-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Los Angeles County Superior Court",
    "caseName":"Justine Hsu v. Tesla, Inc.",
    "year":2020,
    "issue":"Autonomous Vehicles",
    "finalDecision":"Yes",
    "summary":"The complainant alleges Tesla's traffic aware cruise control led to a crash as the car swerved into the median of a street, activating the airbag and causing her personal injuries. Tesla\u2019s response mentioned the complainant should have been in control of the car and that its manual explicitly informs drivers that the auto steer function should not be used in city traffic. The jury\u2019s verdict was that Tesla had clearly instructed the complainant that its software is for assistance and does not create conditions for autonomous driving. ",
    "excerpt":"-",
    "link":"https:\/\/www.repairerdrivennews.com\/wp-content\/uploads\/2023\/04\/verdict.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Kadrey v. Meta Platforms, inc.",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The complainants allege Meta\u2019s use of The Pile\u2019s dataset (which includes a collection of thousands of books) infringe on the copyright of US-based authors. All claims were dismissed (e.g., removal of copyright management information and derivative works claims for the model itself and for the generated outputs), except for the allegation that copying the books for training LLaMA infringes on the author\u2019s copyrights. ",
    "excerpt":"\"1. The plaintiffs allege that the \u201cLLaMA language models are themselves infringing\nderivative works\u201d because the \u201cmodels cannot function without the expressive information\nextracted\u201d from the plaintiffs\u2019 books. This is nonsensical. A derivative work is \u201ca work based\nupon one or more preexisting works\u201d in any \u201cform in which a work may be recast, transformed,\nor adapted.\n\u201d 17 U.S.C. \u00a7 101. There is no way to understand the LLaMA models themselves as a\nrecasting or adaptation of any of the plaintiffs\u2019 books. 2. Another theory is that \u201cevery output of the LLaMA language models is an infringing\nderivative work,\u201d and that because third-party users initiate queries of LLaMA, \u201cevery output\nfrom the LLaMA language models constitutes an act of vicarious copyright infringement.\u201d But\nthe complaint offers no allegation of the contents of any output, let alone of one that could be understood as recasting, transforming, or adapting the plaintiffs\u2019 books. Without any plausible\nallegation of an infringing output, there can be no vicarious infringement. See Perfect 10, Inc. v.\namazon.com, Inc., 508 F.3d 1146, 1169 (9th Cir. 2007).\nThe plaintiffs are wrong to say that, because their books were duplicated in full as part of\nthe LLaMA training process, they do not need to allege any similarity between LLaMA outputs\nand their books to maintain a claim based on derivative infringement. To prevail on a theory that\nLLaMA\u2019s outputs constitute derivative infringement, the plaintiffs would indeed need to allege\nand ultimately prove that the outputs \u201cincorporate in some form a portion of\u201d the plaintiffs\u2019\nbooks. Litchfield v. Spielberg, 736 F.2d 1352, 1357 (9th Cir. 1984); see also Andersen v.\nStability AI Ltd., No. 23-CV-00201-WHO, 2023 WL 7132064, at *7-8 (N.D. Cal. Oct. 30, 2023)\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/67569326\/kadrey-v-meta-platforms-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of California",
    "caseName":"Kisting-Leung v. Cigna Corporation",
    "year":2023,
    "issue":"Insurance",
    "finalDecision":"No",
    "summary":"The complainants allege Cigna uses an automated claims system that wrongfully deny medical payments.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67631023\/kisting-leung-v-cigna-corp\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of California",
    "caseName":"Kohls v. Bonta",
    "year":2024,
    "issue":"Elections",
    "finalDecision":"Yes",
    "summary":"The complainant alleges California electoral laws regulating AI-generated content (AB 2839), which impose labeling requirements and prohibit the distribution of deceptive AI-generated content, violates his First and Fourteenth Amendments rights and chills parody and satire content. Preliminary injunction was granted as the Court understood AB 2839 does not pass constitutional scrutiny. This conclusion was largely based on the fact that there were least restrictive alternatives, such as counter speech.",
    "excerpt":"\"AB 2839 does not pass constitutional scrutiny because the\nlaw does not use the least restrictive means available for\nadvancing the State\u2019s interest here. As Plaintiffs persuasively\nargue, counter speech is a less restrictive alternative to\nprohibiting videos such as those posted by Plaintiff, no matter\nhow offensive or inappropriate someone may find them.\n\u2018\u201cEspecially as to political speech, counter speech is the tried\nand true buffer and elixir,\u201d not speech restriction.\u2019 Motion for\nPrelim. Inj., p. 13 (citations omitted), ECF No. 6-1.\nWhile California has a valid interest in protecting the\nintegrity and reliability of the electoral process, AB 2839 is\nunconstitutional because it lacks the narrow tailoring and least\nrestrictive alternative that a content based law requires under\nstrict scrutiny. Motion for Prel. Inj., pp. 12-13, ECF No. 6-1.\nFor all the reasons discussed below, the Court finds that\nPlaintiff is entitled to a preliminary injunction.2\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/69172215\/kohls-v-bonta\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the District of Minnesota",
    "caseName":"Kohls v. Ellison",
    "year":2024,
    "issue":"Elections",
    "finalDecision":"Yes",
    "summary":"Complainants allege Minnessota Statute \u00a7 609.771 violate the First and Fourteenth Amendments insofar as it criminalizes the dissemination of deepfakes related to the elections. This is due to the chilling effects the law might have on political speech, such as parody and satirical content. Injunctive relief was denied. To one of the complainants, he was considered as lacking standing because his contents were labeled as parody, and thus he had not posted content that is defined by the law as being considered a deepfake. To the other plaintiff, although standing was recognized, The Court considered she did not prove she suffered irreparable harm and, thus, was not entitled to injunctive relief.",
    "excerpt":"\"First, the Court concludes that Minn. Stat. \u00a7 609.771 does not penalize pure parody\nor satire. Constitutionally speaking, parody is that which \u201ccannot \u2018reasonably [be]\ninterpreted as stating actual facts\u2019 about an individual.\n\u201d Milkovich v. Lorain Journal Co.,\n497 U.S. 1, 20 (1990) (quoting Hustler Mag., Inc. v. Falwell, 485 U.S. 46, 50 (1988))\n(alteration in original). But the statute at issue here only proscribes a deepfake insofar as\nit \u201cis so realistic that a reasonable person would believe it depicts speech or conduct of an\nindividual who did not in fact engage in such speech or conduct.\u201d Minn. Stat. \u00a7 609.771,\nsubd. 1(c)(1). The statute\u2019s definition of a deepfake thus categorically excludes\nconstitutional parody from its sweep. If the speech in question \u201ccannot reasonably be\ninterpreted as stating actual facts about an individual,\u201d then it cannot be a deepfake under\nthe statute.\u201d",
    "link":"https:\/\/storage.courtlistener.com\/recap\/gov.uscourts.mnd.220348\/gov.uscourts.mnd.220348.47.0.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Lehrman v. Lovo, Inc.",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants question the use of their voice samples provided in the LOVO platform to develop an AI synthesis software, without their consent or knowledge, as the recordings were provided under the guise of a supposedly academic project which would keep them private.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68535780\/lehrman-v-lovo-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the District of Wisconsin",
    "caseName":"Loomis v. Wisconsin",
    "year":2016,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"The complainant alleges the use of COMPAS to assess his recidivism risk was used to deny him probation and that the proprietary nature of the system violated his due process rights. The Wisconsin Supreme Court held that the use of COMPAS did not violate his due process rights because the judges could be adequately cautioned that the system is not transparent and there has been evidence that it shows bias to minorities; that the COMPAS assessment was only one of the factors considered; and that gender is used as a factor to promote accuracy, not to discriminate, and the complainant did not carry forward an equal protection claim.",
    "excerpt":"\" \u00b68 Ultimately, we conclude that if used properly,\nobserving the limitations and cautions set forth herein, a\ncircuit court's consideration of a COMPAS risk assessment at\nsentencing does not violate a defendant's right to due process.\n\u00b69 We determine that because the circuit court explained\nthat its consideration of the COMPAS risk scores was supported\nby other independent factors, its use was not determinative in\ndeciding whether Loomis could be supervised safely and\neffectively in the community. Therefore, the circuit court did\nnot erroneously exercise its discretion. We further conclude\nthat the circuit court's consideration of the read-in charges\nwas not an erroneous exercise of discretion because it employed\nrecognized legal standards. (\u2026) However, Loomis asserts that even if statistical\ngeneralizations based on gender are accurate, they are not\nnecessarily constitutional. He cites to Craig v. Boren, 429\nU.S. 190, 208-210 (1976), a case where the United States Supreme\nCourt concluded that an Oklahoma law that prohibited the sale of\n3.2% beer to men under the age 21 and to women under the age of\n18 violated the equal protection clause of the Fourteenth\nAmendment. The Court explained that although state officials\noffered sociological or empirical justifications for the gender-\nbased difference in the law, \"the principles embodied in the\nEqual Protection Clause are not to be rendered inapplicable by\nstatistically measured but loose-fitting generalities concerning\nthe drinking tendencies of aggregate groups.\" Id. at 208-09.\n\u00b680 Notably, however, Loomis does not bring an equal\nprotection challenge in this case. Thus, we address whether\nLoomis's constitutional due process right not to be sentenced on\nthe basis of gender is violated if a circuit court considers a\nCOMPAS risk assessment at sentencing. See Harris, 326\nWis. 2d 685, \u00b63\"",
    "link":"https:\/\/cases.justia.com\/wisconsin\/supreme-court\/2016-2015ap000157-cr.pdf?ts=1468415026",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the District of Massachussets",
    "caseName":"Louis et al v. SafeRent et al",
    "year":2022,
    "issue":"Bias",
    "finalDecision":"Yes",
    "summary":"The complainants allege the SafeRent Score system unlawfully discriminates against Black and Hispanic renters due to the factors it takes into account (credit history) and the factors it fails to take into account (the use of housing vouchers makes the tenants more likely to pay the rents). The motion to dismiss was denied in part, and claims under the Fair Housing Act were allowed to proceed. The case was finally settled. ",
    "excerpt":"\" Contrary to SafeRent\u2019s characterization of its actions, the\namended complaint plausibly claims that SafeRent did have the \u201cauthority to make housing\ndecisions\u201d [see Dkt. 32 at 16], because SafeRent \u201ceffectively controls the decision to approve or\nreject a rental application,\u201d as it \u201chas sole control over how scores are calculated\u201d [Am. Compl. at \u00b6 43]. Taken together, the allegations in the amended complaint suggest that SafeRent\u2019s\nprovision of the SafeRent Score is \u201cdirectly related\u201d to the rental transaction \u201cbecause it\ndetermined who was qualified to occupy a housing unit.\u201d5 CoreLogic, 369 F. Supp. 3d at 373.\nBecause that determination may disqualify otherwise qualified rental applicants and, as alleged,\nresults in a disparate impact on protected groups, SafeRent is subject to the FHA.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/63335697\/louis-v-saferent-solutions-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Florida District Court",
    "caseName":"Lynch v. State of Florida",
    "year":2018,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"The complainant alleges facial recognition software (FACE) was used to identify and charge him, leading to an innacurate match. The court considered that other factors were used to identify the complainant. ",
    "excerpt":"-",
    "link":"https:\/\/law.justia.com\/cases\/florida\/second-district-court-of-appeal\/2024\/2d2023-0274.html",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Central District of California",
    "caseName":"Main Sequence, Ltd. v. Dudesy, LLC",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants allege the use of generative AI to create a comedy special, through the use of the works and likeness of George Carlin, violated his copyright and right of publicity. The case was settled.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68195331\/main-sequence-ltd-v-dudesy-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Matsko v. Tesla",
    "year":2022,
    "issue":"Autonomous Vehicles",
    "finalDecision":"No",
    "summary":"The complainant alleges Tesla misrepresents its Autopilot feature, violating the Magnusson-Moss Warranty Act. Arbitration was compelled. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/65347117\/matsko-v-tesla-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Supreme Court of New York",
    "caseName":"Rayner v. New York State Department of Corrections",
    "year":2022,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainant challenges the denial of a Freedom of Information Law request which sought information about the COMPAS algorithm. The denial was based on trade interests of the company who developed COMPAS.  The court considered the content to be a bona fide trade secret, which is an exemption from FOIL, and that its disclosure would undermine the company\u2019s competitive position.",
    "excerpt":"\"But if petitioner's FOIL application were granted and equivant's technology opened to the public, it would be a simple matter for one of the State's information technology vendors to supply DOCCS with the functionality of COMPAS-NY at a much lower cost. After all, a software developer given access to the inner workings of COMPAS-NY would not have to invest \"substantial money and effort\" in developing the \"scales, formulas, and analysis\" used within the program to generate scores and qualitative assessments (Dr. Jackson Aff., \u00b6 26).\nThus, continued secrecy of COMPAS-NY has real value to equivant and gives it a clear \"advantage over competitors\" that do not have access to the scales, norming data, and cut-off points incorporated into the program (Restatement of Torts \u00a7 757, Comment b; see also Restatement [Third] of Unfair Competition \u00a7 39 [\"potential economic advantage over others\"]; id., Comment e [\"advantage\" need only be \"more than trivial\u201d])\".",
    "link":"https:\/\/law.justia.com\/cases\/new-york\/other-courts\/2023\/2023-ny-slip-op-23293.html",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Millette v. Google, LLC",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainant alleges transcriptions of YouTube Videos were used to train generative AI models, leading to unjust enrichment and constituting unfair competition. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/69012654\/millette-v-google-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"California Superior Court",
    "caseName":"Molander v. Tesla, Inc.",
    "year":2020,
    "issue":"Autonomous Vehicles",
    "finalDecision":"Yes",
    "summary":"The complainants allege the defective Autopilot feature led to a crash, causing personal injuries. The jury found Tesla to be not liable.",
    "excerpt":"-",
    "link":"https:\/\/news.bloomberglaw.com\/esg\/tesla-prevails-in-first-jury-trial-over-fatal-autopilot-crash",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court of Harris County, Texas",
    "caseName":"Murphy, Jr. v. Essilorluxottica USA, Inc.",
    "year":2024,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"The complainant alleges the use of facial recognition system by Macy\u2019s led him to be wrongfully arrested. He was subsequently found innocent, but suffered physical and sexual violence during his time in prison. ",
    "excerpt":"-",
    "link":"https:\/\/trellis.law\/case\/48201\/202403265\/murphy-harvey-eugene-jr-vs-essilorluxottica-usa-inc",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Court of Appeals for the Ninth Circuit",
    "caseName":"Mehier Taamneh v. Twitter, Inc.",
    "year":2018,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The complainants allege the Twitter platform aided and abetted ISIS as it allowed them to spread content and recruit terrorists. The district court granted the motion to dismiss due to lack of causation and due to the lack of substantial assistance. The Ninth Circuit reversed, considering that media had covered ISIS social media activities and thus the defendant was generally aware of it, and that the defendants had failed to take steps to prevent ISIS activities, providing an essential platform to its growth. The Supreme Court reversed the decision, and considered there weren\u2019t enough elements to conclude Twitter aided and abetted ISIS. ",
    "excerpt":"\"(c) Plaintiffs have satisfied Halberstam\u2019s first two elements by al-\nleging both that ISIS committed a wrong and that defendants knew\nthey were playing some sort of role in ISIS\u2019 enterprise. But plaintiffs\u2019\nallegations do not show that defendants gave such knowing and sub-\nstantial assistance to ISIS that they culpably participated in the Reina\nattack. Pp. 21\u201330. (\u2026) None of plaintiffs\u2019 allegations suggest that defendants culpably \u201cas-\nsociate[d themselves] with\u201d the Reina attack, \u201cparticipate[d] in it as\nsomething that [they] wishe[d] to bring about,\u201d or sought \u201cby [their]\naction to make it succeed.\u201d Nye & Nissen, 336 U. S., at 619 (internal\nquotation marks omitted). Defendants\u2019 mere creation of their media\nplatforms is no more culpable than the creation of email, cell phones,\nor the internet generally. And defendants\u2019 recommendation algo-\nrithms are merely part of the infrastructure through which all the con-\ntent on their platforms is filtered. Moreover, the algorithms have been presented as agnostic as to the nature of the content. At bottom, the\nallegations here rest less on affirmative misconduct and more on pas-\nsive nonfeasance. To impose aiding-and-abetting liability for passive\nnonfeasance, plaintiffs must make a strong showing of assistance and\nscienter. Plaintiffs fail to do so. (\u2026) plaintiffs identify no duty that would require defendants or other com-\nmunication-providing services to terminate customers after discover-\ning that the customers were using the service for illicit ends. Even if\nsuch a duty existed in this case, it would not transform defendants\u2019\ndistant inaction into knowing and substantial assistance that could\nestablish aiding and abetting the Reina attack. And the expansive\nscope of plaintiffs\u2019 claims would necessarily hold defendants liable as\nhaving aided and abetted each and every ISIS terrorist act committed\nanywhere in the world. The allegations plaintiffs make here are not\nthe type of pervasive, systemic, and culpable assistance to a series of\nterrorist activities that could be described as aiding and abetting each\nterrorist act by ISIS.\u201d",
    "link":"https:\/\/www.supremecourt.gov\/opinions\/22pdf\/21-1496_d18f.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of West Virginia",
    "caseName":"Michael T. v. Bowling",
    "year":2015,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainants allege the use by West Virginia Department of Health and Human Resources of an automated algorithm to assess waiver benefits violated their due process rights, insofar as they lacked transparency and an appeal process. A preliminary injunction was granted. The algorithm was substituted with a transparent matrix, individualized assessments and an appeal process, which was held by the court to have removed the due process violations.",
    "excerpt":"\"The Court concludes that the APS Algorithm used by Defendant when determining\nPlaintiffs\u2019 individualized budgets does not employ ascertainable standards. The record provides\nno information as to what factors are incorporated into the APS Algorithm, how each factor is\nweighted, or the overarching methodology APS utilizes in the APS Algorithm to create each I\/DD\nWaiver Program member\u2019s individualized budget. In short, there is simply no way to determine\nhow the APS Algorithm generates each waiver recipient\u2019s individualized budget. Further, absent\nsome indication of the basis for each Plaintiffs\u2019 benefits determination, Plaintiffs cannot\nmeaningfully challenge this determination. \u201c",
    "link":"https:\/\/storage.courtlistener.com\/recap\/gov.uscourts.wvsd.192754.122.0.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Mobley v. Workday, Inc.",
    "year":2023,
    "issue":"Bias",
    "finalDecision":"No",
    "summary":"The complainant alleges Workday\u2019s screening algorithm for hiring decisions discriminates against Black, older and disabled people, violating the Civil Rights Act, the Age Discrimination in Employment Act and the Americans with Disabilities Act. ",
    "excerpt":"\"The anti-discrimination laws under which Mobley has sued all prohibit discrimination not\njust by employers themselves but also by agents of those employers. Title VII, the ADA, and the\nADEA all define the term \u201cemployer\u201d to include \u201cany agent of\u201d an employer. 42 U.S.C. \u00a7\u00a7\n2000e(b), 12111(5)(A); 29 U.S.C. \u00a7 630(b). Employers cannot escape liability for\ndiscrimination by delegating their traditional functions, like hiring, to a third party. (\u2026) The FAC plausibly alleges that Workday\u2019s customers delegate traditional hiring\nfunctions, including rejecting applicants, to the algorithmic decision-making tools provided by\nWorkday. According to the FAC, Workday\u2019s software is not simply implementing in a rote way\nthe criteria that employers set forth, but is instead participating in the decision-making process\nby recommending some candidates to move forward and rejecting others. Workday allegedly\nembeds artificial intelligence and machine learning into its algorithmic decision-making tools to\n\u201cmake hiring decisions,\u201d and its software can \u201cautomatically disposition[] or mov[e] candidates\nforward in the recruiting process.\u201d (FAC \u00b6\u00b6 94, 99.) This is illustrated by the rejection emails\nMobley allegedly received in the middle of the night, giving rise to a plausible inference that the\ndecision was automated. (Id. \u00b6\u00b6 77, 85.)\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/66831340\/mobley-v-workday-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"National Fair Housing Alliance v. Facebook",
    "year":2018,
    "issue":"Bias",
    "finalDecision":"No",
    "summary":"The complainants allege Facebook allowed users to exclude and include audiences, including protected categories, and its algorithms carried out the discrimination. The case was settled. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/6346604\/national-fair-housing-alliance-v-facebook-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Nazemian v. NVIDIA Corporation",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants allege NVIDIA used their books to train their LLMs, especially through the use of the dataset The Pile, violating their copyright.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68325563\/nazemian-v-nvidia-corporation\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Nilsson v. General Motors",
    "year":2018,
    "issue":"Autonomous Vehicles",
    "finalDecision":"No",
    "summary":"The complainant allege he suffered harm due to a collision with a self-driving Chevrolet Bolt, which swerved to his lane. The case was settled.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/6280461\/nilsson-v-general-motors-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Third Judicial Circuit of Michigan",
    "caseName":"Oliver v. City of Detroit",
    "year":2020,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"The complainant alleges Detroit\u2019s use of facial recognition technology, despite its higher error rate among Black people, was discriminatory. The case was voluntarily dismissed.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/18508594\/oliver-v-detroit-city-of\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"In Re: Mosaic LLM Litigation",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants allege their books were used to train LLMs without their consent, as the Books3 dataset was used.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68325564\/onan-v-databricks-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of Illinois",
    "caseName":"Open Communities v. Harbor Group Management Company, LLC",
    "year":2023,
    "issue":"Bias",
    "finalDecision":"No",
    "summary":"The complainants allege individuals who received housing assistance were discriminated agains, through receiving refusals through an automated AI system. The case was settled and, in a consent decree, the defendant agreed to change its policies, allowing individuals who receive housing vouchers to proceed with their renting applications and sharing the reasons for denials.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67824178\/open-communities-v-harbor-group-management-co-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"P.M. v. OpenAI LP",
    "year":2023,
    "issue":"Privacy",
    "finalDecision":"No",
    "summary":"The complainants allege the collection of personal data in web-scraping to train ChatGPT, and the collection through interacting with the system in the OpenAI website and in others in which the GPT model is integrated, violate several privacy-related laws. The complaint was voluntarily dismissed. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67535351\/pm-v-openai-lp\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Pandolfi v. AviaGames, Inc. ",
    "year":2023,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":"The complainants allege the game-developer advertises their games (such as Bingo Tours) are skill-related, but, unbeknownst to players, pair them with bots, which they claim amount to racketeering and conspiracy. The motion to compel arbitration was denied (it had a delegation and a bellwether provision). ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68018617\/pandolfi-v-aviagames-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the District of New Jersey",
    "caseName":"Parks v. McCormac",
    "year":2020,
    "issue":"Criminal justice",
    "finalDecision":"No",
    "summary":"The complainant seeks compensation for injuries he suffered due to defendants using facial recognition software to recognise him as culprit of a crime he did not commit. The case was settled. ",
    "excerpt":"- ",
    "link":"https:\/\/www.courtlistener.com\/docket\/59701745\/parks-v-mccormac\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of California District Court",
    "caseName":"Parsa et al v. Google LLC et al",
    "year":2019,
    "issue":"Platforms",
    "finalDecision":"No",
    "summary":"The complainant alleges the use of AI by defendants led to several harms, including by providing technology that was used to prosecute minorities in China. The case was dismissed because defendants had not been served. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/16596963\/parsa-v-google-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of Illinois",
    "caseName":"Patel v. Facebook, Inc.",
    "year":2018,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"The complainants allege the collection of biometric face information in the Tag Suggestions feature of Facebook violates the Illinois Biometric Information Privacy Act. The case was settled. ",
    "excerpt":"-",
    "link":"https:\/\/epic.org\/documents\/patel-v-facebook\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Ninth Circuit",
    "caseName":"Prager University v. Google, LLC",
    "year":2018,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The complainants allege Youtube violate their free speech rights, insofar as they restrict their videos, automatically flagging them as inappropriate without even explaining the reasons to do so. The district court granted the motion to dismiss and, on appeal, the decision was upheld. The Court of Appeal considered Youtube to be a private forum, not a public one, thus, not subject to the First Amendment.  ",
    "excerpt":"\"Addressing the First Amendment claims, the panel held\nthat despite YouTube\u2019s ubiquity and its role as a public-\nfacing platform, it remains a private forum, not a public\nforum subject to judicial scrutiny under the First\nAmendment. The panel noted that just last year, the\nSupreme Court held that \u201cmerely hosting speech by others is\nnot a traditional, exclusive public function and does not\nalone transform private entities into state actors subject to\nFirst Amendment constraints.\u201d Manhattan Cmty. Access\nCorp. v. Halleck, 139 S. Ct. 1921, 1930 (2019). The panel\nheld that the Internet does not alter this state action\nrequirement of the First Amendment. The panel therefore\nrejected plaintiff\u2019s assertion that YouTube is a state actor\nbecause it performs a public function.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/7829210\/prager-university-v-google-llc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"State Court of Cobb County, Georgia",
    "caseName":"Rana v. Amazon et al ",
    "year":2021,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":"The complainant was injured by a crash with an Amazon delivery truck. She alleges that, as Amazon algorithmically controls the route, the number of packages delivered, and other factors, they are vicariously liable for the injuries she suffered. ",
    "excerpt":"-",
    "link":"https:\/\/cdn.arstechnica.net\/wp-content\/uploads\/2022\/09\/Ans-Rana-v-Amazon-Complaint-10-22-21.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Raw Story Media, Inc. v. OpenAI, Inc. ",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The complainant alleges their news articles were used to train ChatGPT without their consent, and also that ChatGPT reproduces the content without attributing it to the newspaper. The motion to dismiss was granted in its entirety. A motion for leave to file first amended complaint was submitted by the complainants.",
    "excerpt":"\"I agree with Defendants. Plaintiffs allege that ChatGPT has been trained on \"a scrape of\nmost of the internet,\" Compl. , 29, which includes massive amounts of information from\ninnumerable sources on almost any given subject. Plaintiffs have nowhere alleged that the information in their articles is copyrighted, nor could they do so. When a user inputs a question\ninto ChatGPT, ChatGPT synthesizes the relevant information in its repository into an answer.\nGiven the quantity of information contained in the repository, the likelihood that ChatGPT would\noutput plagiarized content from one of Plaintiffs' articles seems remote. And while Plaintiffs\nprovide third-party statistics indicating that an earlier version of ChatGPT generated responses\ncontaining significant amounts of plagiarized content, Compl. ~ 5, Plaintiffs have not plausibly\nalleged that there is a \"substantial risk\" that the current version of ChatGPT will generate a\nresponse plagiarizing one of Plaintiffs' articles.\nAccordingly, Plaintiffs lack Article III standing to seek injunctive relief for their alleged\nlnjury. (\u2026)\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/68290709\/raw-story-media-inc-v-openai-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of Georgia",
    "caseName":"Reid v. Bartholomew",
    "year":2023,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"The complainant seeks compensation for having been misidentified as the perpetrator of a crime through the use of facial recognition systems.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67800075\/reid-v-bartholomew\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Massachussets",
    "caseName":"Rodriguez v. Massachusetts Parole Board",
    "year":2021,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"The complainant challenges the use of a risk-assessment tool to deny him parole. Moreover, he questions the lack of transparency regarding the tool. The Supreme Judicial Court of Massachussets granted an application for direct appellate review, and the Board\u2019s decision was not reassessed, because it had adequately considered youth-related factors.",
    "excerpt":"\"The plaintiff contends that the board insufficiently\nconsidered his advanced age and his rehabilitative efforts as\nfactors weighing in favor of his release,6 insufficiently\nexplained its reasons for denying him parole in its written\ndecision,7 utilized an inappropriate tool (Level of Service\/Case Management Inventory) to perform the statutorily required \"risk\nand needs assessment,\" and prejudiced his future attempts to\nsecure parole by failing to release its decision until ten\nmonths after his review hearing. These arguments fall outside\nthe scope of our review. We have emphasized that our review is\nlimited to determining whether the board has taken into account\nthe youth-related factors in making its decision, and that we\nwill remand the decision only if the board has failed to do so.\nSee Deal, 484 Mass. at 461; Diatchenko II, 471 Mass. at 31. As\nexplained supra, we conclude that the board has taken youth-\nrelated attributes into account in coming to its decision; the\nplaintiff does not argue otherwise.\u201d",
    "link":"https:\/\/epic.org\/documents\/rodriguez-v-massachusetts-parole-board\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Rumble, Inc. v. Google, LLC",
    "year":2021,
    "issue":"Antitrust",
    "finalDecision":"Yes",
    "summary":"The complainants allege Google has engaged in anticompetitive behavior as its search algorithm ranks Youtube videos first and only then the videos of its competitors. The motion to dismiss was denied. Trial is set to July 2025.",
    "excerpt":"\"Without real dispute, Plaintiff has adequately alleged a Section 2 claim. First, it alleges\nthat Defendant obtained and maintains monopoly power in the online video platform market,\nasserting that YouTube controls 73% of global online video activity. Id. \u00b6 37, 63, 193. And\nsecond, Plaintiff alleges among other things that Defendant, with no valid business purpose or\nbenefit to users, designs its search engine algorithms to show users YouTube links instead of links\nto its competitors\u2019 sites. Id. \u00b6 71; see also \u00b6\u00b6 68-74. According to Plaintiff, \u201cRumble and\nconsumers (e.g. content creators) are disadvantaged, and competition is harmed, in the defined\nmarket because Google provides self-preferencing search advantages to its wholly-owned\nYouTube platform as a part of its scheme to maintain its monopoly power, and to reap a\nmonopolist\u2019s financial rewards.\u201d Id. \u00b6 74\u201d",
    "link":"https:\/\/storage.courtlistener.com\/recap\/gov.uscourts.cand.371759\/gov.uscourts.cand.371759.57.0.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Alter v. OpenAI, Inc. ",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants argue the use of their works without consent to train AI models infringes on their copyright.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68024915\/sancton-v-openai-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"New York Supreme Court",
    "caseName":"Stanfield et al v. Mean LLC et al",
    "year":2023,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The complainants argue social media platforms (Youtube and Reddit) are liable for their products promoting inflammatory content, which influenced a mass shooter to carry forward his racially motivated homicide acts. The motion to dismiss was denied. ",
    "excerpt":"\"The social media\/internet defendants may still prove that their platforms were mere\nmessage boards and\/or do not contain sophisticated algorithms thereby providing them with the\nprotections of the CDA and\/or First Amendment. In addition, they may yet establish that their\nplatforms are not products or that the negligent design features plaintiffs have alleged are not part\nof their platforms. However, at this stage of the litigation the Court must base its ruling on the\nallegations of the complaint and not \u201cfacts\u201d asserted by the defendants in their briefs or during\noral argument and those allegations allege viable causes of action under a products liability\ntheory. (\u2026) At this juncture of the litigation it is far too early to rule as a matter of law that the actions, or\ninaction, of the social media\/internet defendants through their platforms require dismissal on\nproximate cause. The facts alleged do not show \u201conly one conclusion\u201d that could be made as to\nthe connection between these defendants alleged negligence and the plaintiffs\u2019 injuries (quoting\nDerdiarian 51 NY2d).\u201d",
    "link":"https:\/\/iapps.courts.state.ny.us\/nyscef\/DocumentList?docketId=7CgiV6Vri6hGlXKgQHrphA==&PageNum=2&narrow=",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the District of Columbia",
    "caseName":"Thaler v. Perlmutter et al",
    "year":2022,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The complainant challenges the US Copyright Office decision to deny copyright in the image \u201cA Recent Entrance to Paradise\u201d, in which application an AI (Creativity Machine) was listed as author. The judge considered that works generated by AI are not eligible for copyright if human involvement is absent. The complainant appealed.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67892225\/stephen-thaler-v-shira-perlmutter\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Virginia",
    "caseName":"Thaler v. Vidal",
    "year":2021,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The complainant challenges the refusal to give him rights over creations developed by the DABUS AI system. The district understood an \u201cindividual\" in the Patent Act is a natural person because of (i) its common usage and the Supreme Court application of the Dictionary Act; (ii) the Federal Circuit\u2019s jurisprudence and (iii) the statute was amended in 2011, when AI already existed. The decision was affirmed by the Court of Appeals.",
    "excerpt":"\"Consequently, the Supreme Court has held that, when\nused in statutes, the word \u201cindividual\u201d refers to human be-\nings unless there is \u201csome indication Congress intended\u201d a\ndifferent reading. Id. at 455 (emphasis omitted).\n4 Nothing\nin the Patent Act indicates Congress intended to deviate\nfrom the default meaning. To the contrary, the rest of the\nPatent Act supports the conclusion that \u201cindividual\u201d in the\nAct refers to human beings.\nFor instance, the Act uses personal pronouns \u2013 \u201chim-\nself\u201d and \u201cherself\u201d \u2013 to refer to an \u201cindividual.\u201d \u00a7 115(b)(2).\nIt does not also use \u201citself,\u201d which it would have done if\nCongress intended to permit non-human inventors.\u201d",
    "link":"https:\/\/www.cafc.uscourts.gov\/opinions-orders\/21-2347.OPINION.8-5-2022_1988142.pdf",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"The Center for Investigative Reporting, Inc. v. OpenAI, Inc.",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants argue the use of their works without consent to train AI models infringes on their copyright.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68892274\/the-center-for-investigative-reporting-inc-v-openai-inc\/?page=2",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"The Intercept Media, Inc. v. OpenAI, Inc.",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The complainants argue the use of their works without consent to train AI models infringes on their copyright. The claim related to the removal of copyright management information was not dismissed. ",
    "excerpt":"\"The Intercept cites factual matter that it believes plausibly supports OpenAI\u2019s knowledge of two categories of likely infringement: (1) its concealment of its own infringement in reproducing The Intercept\u2019s articles in training sets; and (2) its facilitation of ChatGPT users\u2019 downstream infringement of regurgitations of its articles produced in ChatGPT outputs. The Intercept does not clearly explain the first category. (\u2026) The Court is, however, persuaded by the second theory, which concerns downstream infringement. The Intercept explains that OpenAI \u201cpossess[es] a repository of every regurgitation of [its] works\u201d by ChatGPT. Am. Compl. \u00b6 63. And even though, according to The Intercept, OpenAI has more recently adjusted ChatGPT\u2019s settings to limit regurgitation, The Intercept still alleges that ChatGPT \u201cregurgitate[s] verbatim . . . copyright-protected works of journalism\u201d without CMI, \u201c[a]t least some of the time.\u201d Id. \u00b6 64. In fact, The Intercept\u2019s data scientist was able to produce three regurgitations from ChatGPT in response to detailed prompts.\u201d",
    "link":"https:\/\/www.courtlistener.com\/docket\/68290804\/the-intercept-media-inc-v-openai-inc\/?page=2",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"The New York Times Company v. Microsoft",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants argue the use of their works without consent to train AI models infringes on their copyright.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68117049\/the-new-york-times-company-v-microsoft-corporation\/?page=3",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District of Delaware",
    "caseName":"Thomson Reuters Enterprise Centre v. Ross Intelligence",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The complainant alleges ROSS Intelligence compiled Westlaw cases and proprietary headnotes to develop a ML-based legal research platform. In 2025, the Court held that the headnotes were original, extracting particular sections of the decisions and phrasing it in their own words, granting summary judgement for a subset of them. The reproduction by ROSS Intelligence was not considered as fair use: the character of the use was commercial and its purpose was to develop a product in the same market as Westlaw, so it was not considered transformative.  ",
    "excerpt":"\"First, the headnotes are a compilation. \u201cFactual compilations\u201d are original if the\ncompiler makes \u201cchoices as to selection and arrangement\u201d using \u201ca minimal degree of\ncreativity.\u201d Feist, 499 U.S. at 348. Thomson Reuters\u2019s selection and arrangement of\nits headnotes easily clears that low bar.\nMore than that, each headnote is an individual, copyrightable work. That became\nclear to me once I analogized the lawyer\u2019s editorial judgment to that of a sculptor. A\nblock of raw marble, like a judicial opinion, is not copyrightable. Yet a sculptor creates\na sculpture by choosing what to cut away and what to leave in place. That sculpture\nis copyrightable. 17 U.S.C. \u00a7 102(a)(5). So too, even a headnote taken verbatim from\nan opinion is a carefully chosen fraction of the whole. Identifying which words matter\nand chiseling away the surrounding mass expresses the editor\u2019s idea about what the\nimportant point of law from the opinion is. (\u2026) My prior opinion wrongly concluded that I had to send this factor to a jury. 694 F.\nSupp. 3d at 483\u201384. I based that conclusion on Sony and Sega. Since then, I have\nrealized that the intermediate-copying cases (1) are computer-programming copying\ncases; and (2) depend in part on the need to copy to reach the underlying ideas. Nei-\nther is true here. Because of that, this case fits more neatly into the newer framework\nadvanced by Warhol. I thus look to the broad purpose and character of Ross\u2019s use.\nRoss took the headnotes to make it easier to develop a competing legal research tool.\nSo Ross\u2019s use is not transformative. Because the AI landscape is changing rapidly, I\nnote for readers that only non-generative AI is before me today.\u201d",
    "link":"https:\/\/blogs.gwu.edu\/law-eti\/ai-litigation-database\/case-detail-page\/?thomson-reuters-enterprise-centre-gmbh-v-ross-intelligence-inc&pid=102",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the District of Massachussets",
    "caseName":"UMG Recordings, Inc. et al v. Suno, Inc.",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants argue the use of their songs without consent to train AI models which create other songs on demand infringes on their copyright.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68878608\/umg-recordings-inc-v-suno-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"UMG Recordings, Inc. et al v. Uncharted Labs, Inc.",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants argue the use of their songs without consent to train AI models which create other songs on demand infringes on their copyright.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/68878697\/umg-recordings-inc-v-uncharted-labs-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"United States of America v. Meta Platforms, inc.",
    "year":2022,
    "issue":"Bias",
    "finalDecision":"No",
    "summary":"The complainants allege Facebook allowed advertisers to exclude and include audiences based on their protected categories, unlawfully discriminating against them. The case was settled. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/63398625\/united-states-v-meta-platforms-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Middle District of North Carolina",
    "caseName":"United States of America v. RealPage, Inc.",
    "year":2024,
    "issue":"Antitrust",
    "finalDecision":"No",
    "summary":"The complainants allege RealPage and their property management clients, along with other rental companies, use algorithmic systems to fix prices superior to those that would occur in competitive conditions.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/69074245\/united-states-of-america-v-realpage-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"United States v. Smith",
    "year":2024,
    "issue":"Criminal justice",
    "finalDecision":"No",
    "summary":"The defendant allegedly used thousands of AI-generated songs to dupe streaming platforms, through bot streaming the songs to earn revenue.",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/69129096\/united-states-v-smith\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District of Delaware",
    "caseName":"Vacker v. Eleven Labs, Inc.",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants allege their voice recordings, which are protected by copyright, were used to create synthetic voice clones without their consent. ",
    "excerpt":"- ",
    "link":"https:\/\/www.courtlistener.com\/docket\/69111793\/vacker-v-elevenlabs-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"District Court for the District of Connecticut",
    "caseName":"Van Pelt v. Cigna Group",
    "year":2023,
    "issue":"Insurance",
    "finalDecision":"No",
    "summary":"The complainant alleges the insurer Cigna uses AI (the system PxDx) to automatically deny medical care claims. The claims were voluntarily dismissed. ",
    "excerpt":"- ",
    "link":"https:\/\/www.courtlistener.com\/docket\/67732601\/van-pelt-v-cigna-group\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Velesaca v. Decker",
    "year":2020,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"The complainant alleges ICE switched from individual detention assessments to a Risk Classification Assessment Tool, which inadvertently flags all cases as requiring detention, denying them the possibility of release with bonds. Preliminary injunction was granted, then a protective order, which stipulated ICE had to file a report about each individual detained without a bond. The case was finally settled. ",
    "excerpt":"\"Next, the key question: Has ICE indeed adopted the No-Release Policy? As noted supra, Plaintiffs argue, and Defendants do not dispute, that 8 U.S.C. \u00a7 1226(a) and its implementing regulations require ICE officials to make an individualized custody determination. See Pl. PI Mem. at 20-22. Plaintiffs argue that the data analyzed and reviewed in the Hausman Declaration show that ICE has been applying a No-Release Policy. (\u2026) Plaintiffs argue that the numbers speak for themselves and I agree. One need not fix the precise point between 2015 and 2017 that a change took place to see plainly that a change, of considerable magnitude, took place. Per the data, ICE went from releasing (on bond or recognizance) upwards of 30% of alien arrestees to releasing around 2%. The percentage of arrestees released in 2013 and 2014 was around 40%; in 2018 and 2019, between 1% and 2%. The comparisons are striking. (\u2026) I find that Plaintiffs have demonstrated, at this stage, that they are likely to succeed in proving the existence of the No-Release Policy. As Defendants acknowledge, a No-Release Policy is inconsistent with the INA and regulations passed thereunder, at least without notice-and-comment rule making. Plaintiffs have thus shown a likelihood of success on the merits of their claims. As the Court has already found that Plaintiffs have shown they will suffer irreparable harm without relief and that the equities tilt in Plaintiffs\u2019 favor, injunctive relief is called for here.\u201d",
    "link":"https:\/\/www.nyclu.org\/court-cases\/jose-l-velesaca-v-decker-et-al",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of Georgia",
    "caseName":"Walters v. OpenAI, LLC",
    "year":2023,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":"The complainant seeks compensation for having been inaccurately represented by ChatGPT as the defendant in a fraud case. The motion to dismiss was denied. ",
    "excerpt":"-",
    "link":"https:\/\/knowingmachines.org\/knowing-legal-machines\/legal-explainer\/cases\/walters-v-openai",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Michigan",
    "caseName":"Williams v. City of Detroit",
    "year":2021,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"The complainant seeks compensation for having been misidentified as the perpetrator of a crime through the use of facial recognition systems. The case was later settled. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/59815822\/williams-v-city-of-detroit-michigan-a-municipal-corporation\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Northern District of California District Court",
    "caseName":"Williams-Sonoma, Inc. v. Amazon, Inc.",
    "year":2018,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The complainant alleges Amazon\u2019s algorithm selected his copyright protected photos and displayed them in third-party vendors\u2019 product announcements. The motion to dismiss was denied, as the Court considered the algorithm\u2019s active selection of the photographs voided the safe harbor provision of section 512(c) of the DMCA. ",
    "excerpt":"\"Here, as WSI persuasively argues, \u201cAmazon goes a significant step farther\u2014it not only\ncurates and selects the images to be searched out by others, it publishes them\u201d\n\u2014\u201c[u]nlike the\nmoderators in Zillow, Amazon is actually performing the acts of reproduction and display that\nconstitute infringement.\u201d ECF No. 112 at 18. Indeed, as alleged and accepted as true for this\nmotion, once Amazon\u2019s sellers upload proposed images to Amazon\u2019s internal catalog, they have\nno control over, or further role in, Amazon\u2019s image-selection and PDP publication process, see\nSAC \u00b6\u00b6 6, 116\u201317, 200; when multiple sellers upload competing images for potential inclusion in\na PDP, Amazon, in its \u201csole discretion,\u201d decides which photo has the best sales appeal and then\ncopies that image from the catalog to a server for display on the published PDP, see id.; and\nAmazon\u2019s algorithm selected, copied, and publicly displayed WSI\u2019s Peppermint Bark Photo on its\nPDP on amazon.com where Amazon shoppers who searched for that product saw it, see id. \u00b6\u00b6 6\u2013\n8, 116\u201317, 120\u201321. At the pleading stage, these allegations adequately support WSI\u2019s assertion\nthat Amazon exercised the requisite level of volition necessary to be held liable as a direct\ninfringer of WSI\u2019s reproduction and public display rights.\"",
    "link":"https:\/\/www.courtlistener.com\/docket\/8418854\/williams-sonoma-inc-v-amazoncom-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Michigan",
    "caseName":"Woodruff v. City of Detroit",
    "year":2023,
    "issue":"Biometrics",
    "finalDecision":"No",
    "summary":"The complainant seeks compensation for having been misidentified as the perpetrator of a crime through the use of facial recognition systems. The case was later settled. ",
    "excerpt":"-",
    "link":"https:\/\/www.courtlistener.com\/docket\/67661093\/woodruff-v-detroit-city-of\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Central District of California",
    "caseName":"Young v. NeoCortext, Inc.",
    "year":2023,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"The complainant alleges that the face-swapping app developed by the defendant violated her right to publicity insofar as it used her image without consent. The motion to dismiss was denied, as the Court understood a transformative use defense would not apply to the case. The decision was affirmed by the Ninth Circuit.",
    "excerpt":"\"At this stage, to defeat Young\u2019s claim, NeoCortext must show that its use is\ntransformative as a matter of law. See Hilton, 599 F.3d at 911. NeoCortext argues that\nit has done so because \u201c[t]he very purpose of Reface is to transform a photo or video in\nwhich Plaintiff\u2019s (or others) [sic] image appears into a new work in which Plaintiff\u2019s\nface does not appear.\u201d (Mot. to Dismiss at 11). But Young\u2019s face is the only thing that\nchanges in the end product; at least in some instances, the end photograph still depicts\nthe rest of Young\u2019s body in the setting in which he became a celebrity.\nThe Ninth Circuit has found that depictions that are arguably more transformative\nthan those created with Reface do not entitle a defendant to the affirmative defense as\na matter of law. \u201c",
    "link":"https:\/\/www.courtlistener.com\/docket\/67127939\/kyland-young-v-neocortext-inc\/",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Southern District of New York",
    "caseName":"Zhang v. Baidu.com, Inc.",
    "year":2013,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The complainants allege Baidu censored their pro-democracy content in the US, violating their First Amendment rights. The Court considered that the search engine had the autonomy to control which content it would show in its platform, given it had editorial judgement, granting the motion to dismiss. ",
    "excerpt":"\"In light of those principles, there is a strong argument to be made that the First Amendment fully immunizes search-engine results from most, if not all, kinds of civil liability and government regulation. See, e.g., Benjamin, supra, at 1458-72; Volokh & Falk, supra, at 884-92. The central purpose of a search engine is to retrieve relevant information from the vast universe of data on the Internet and to organize it in a way that would be most helpful to the searcher. In doing so, search engines inevitably make editorial judgments about what information (or kinds of information) to include in the results and how and where to display that information (for example, on the first page of the search results or later). (\u2026) Here, the very theory of Plaintiffs' claims is that Baidu exercises editorial control over its search results on certain political topics \u2014 namely, by disfavoring expression concerning \"the Democracy movement in China\" and related subjects. (Compl. \u00b6 22). In other words, Plaintiffs do not \u2014 and, in light of their own allegations, cannot \u2014 make any argument that Baidu is merely an \"infrastructure or platform that delivers content\" in a neutral way. Bracha & Pasquale, supra, at 1192-97 (arguing that because \"search engines do not function as publishers or editors of the content to which they channel users,\" their results should not be treated as speech covered by the First Amendment).[5] Instead, they seek to hold Baidu liable for, and thus punish Baidu for, a conscious decision to design its search-engine algorithms to favor certain expression on core political subjects over other expression on those same political subjects.[6] To allow such a suit to proceed would plainly \"violate[] the fundamental rule of protection under the First Amendment, that a speaker has the autonomy to choose the content of his own message.\" Hurley, 515 U.S. at 573; see also, e.g., Agency for Intl Dev. v. Alliance for Open Soc'y Intl, 133 S. Ct. 2321, 2327 (2013) (\"[F]reedom of speech prohibits the government from telling people what they must say.\" (internal quotation marks omitted)).\u201d",
    "link":"https:\/\/scholar.google.com\/scholar_case?case=496194286290910310&q=Search+King,+Inc.+v.+Google+Tech.,+Inc.,+No.+CIV-02-1457-M,&hl=en&as_sdt=6,45",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"United States",
    "court":"Eastern District of Michigan",
    "caseName":"Zynda et al v. Zimmer et al",
    "year":2015,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainant alleges the Michigan Unemployment Insurance Agency automated-system for assessing unemployment fraud deprives people of their benefits of their due process rights and of their rights under the Social Security Act. The motion to dismiss was partly denied, allowing complainants to seek an order that defendants establish a new procedure for detecting incidents of fraud that would be constitutionally more adequate. The claims under the Eight Amendment (excessive penalties) were dismissed.",
    "excerpt":"-",
    "link":"https:\/\/docs.justia.com\/cases\/federal\/district-courts\/michigan\/miedce\/2:2015cv11449\/300638\/27",
    "lat":37.0902,
    "lng":-95.7129
  },
  {
    "region":"European Union",
    "court":"Court of Justice of the European Union",
    "caseName":"Yettel Bulgaria, C-806\/24",
    "year":2024,
    "issue":"Automated decisions",
    "finalDecision":"No",
    "summary":"The Sofiyski rayonen sad (a Bulgarian court) requested a prejudicial decision with several AI-related points: (i) should Article 86(1) of Regulation 2024\/1689 (AI Act) be interpreted as meaning the consumer has a right to know how automated decisions were generated from automatically collected data; (ii) should Articles 6(1) and 7(1) of the Directive 93\/12\/EEC be interpreted meaning they are applicable to activities based on AI or automated decisions; (iii) should Article 3(1) of Directive 2011\/83\/EU be interpreted as meaning the protection of consumer rights is applicable to AI\/automated decision systems; (iv) must Articles 86(1) of the AI Act, read together with Arts. 38 and 47 of the EU Charter of Fundamental Rights, and with Articles 6(1) and 7(1) of the Directive 93\/13\/EEC, and Article 5 of the Directive 2011\/83\/EU, be interpreted as meaning the Court can demand black box data, source code and algorithms related to automated decisions took under consumer contracts? ",
    "excerpt":"-",
    "link":"https:\/\/eur-lex.europa.eu\/legal-content\/EN\/TXT\/PDF\/?uri=OJ:C_202501080",
    "lat":null,
    "lng":null
  },
  {
    "region":"European Union",
    "court":"Court of Justice of the European Union",
    "caseName":"Case T-37\/24 (C\/2024\/1881)",
    "year":2024,
    "issue":"Administrative use of AI",
    "finalDecision":"No",
    "summary":"The applicant claims she was illegally assessed by artificial intelligence in a selection process for the competition EPSO\/AST\/150\/21-3.",
    "excerpt":"-",
    "link":"https:\/\/eur-lex.europa.eu\/legal-content\/EN\/TXT\/PDF\/?uri=OJ:C_202401881",
    "lat":null,
    "lng":null
  },
  {
    "region":"European Union",
    "court":"Court of Justice of the European Union",
    "caseName":"Ligue des droits humains v. Conseil des ministres",
    "year":2022,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The Belgium Constitutional Court had posed several questions with regards to the GDPR and the use of passengers data to prevent and investigate terrorism and criminality (PNR Directive). The Court understood national law could be interpreted in conformity with EU law. One of the factors it remarked as protecting fundamental rights from unwarranted intrusion was that the criteria with regards to which the PNR data is processed are pre-determined. This would preclude the use of AI. It also noted that the profiles used in the algorithmic decision-making don\u2019t need to be public so the process can be considered transparent, but that the algorithmic decision-making must be identifiable.",
    "excerpt":"\"Thirdly, it emerges both from the wording of Article 6(3)(b) of the PNR Directive and from\nthe system of safeguards surrounding the automated processing of PNR data under the PNR\nDirective that the algorithms used for the analysis provided for in that provision must function\ntransparently, and that the result of their application must be traceable. That requirement of\ntransparency clearly does not mean that the \u2018profiles\u2019 used must be made public. It does in\ncontrast require the algorithmic decision-making to be identifiable. On the one hand, the\nrequirement that the criteria on the basis of which that analysis is carried out must be\n\u2018pre-determined\u2019 means that they must not be modifiable without human intervention and,\ntherefore, precludes the use of \u2018machine learning\u2019 artificial intelligence technology,225 which,\nwhilst it may be more precise, is difficult to interpret, even for the operators who carried out the\nautomated processing.226 On the other hand, if it is to be effective, the safeguard set out in\nArticle 6(5) and (6) of the PNR Directive, according to which any positive match resulting from\nthe automated processing of PNR data under Article 6(2)(a) must be individually reviewed by\nnon-automated means, requires \u2013 in relation to the analysis under Article 6(3)(b) of the PNR Directive \u2013 that it must be possible to understand why the program arrived at that match, which\ncannot be guaranteed when, for example, self-learning systems are used. The same is true as\nregards monitoring the lawfulness of the analysis \u2013 including in relation to the fact that the\nresults obtained must be non-discriminatory, which is the responsibility of the data protection\nofficer and the national supervisory authority, under Article 6(7) and Article 15(3)(b) of the PNR\nDirective respectively. Transparency in the functioning of the algorithms used is also a necessary\nprecondition for the data subjects to be able to exercise their rights to complain and their right to\nan effective judicial remedy.\u201d",
    "link":"https:\/\/eur-lex.europa.eu\/legal-content\/EN\/TXT\/PDF\/?uri=CELEX:62019CC0817",
    "lat":null,
    "lng":null
  },
  {
    "region":"European Union",
    "court":"European Patent Office",
    "caseName":"J 0008\/20 - 3.1.01",
    "year":2021,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The applicant filed two patents, one for a food container and other for \u201cdevices and methods for attracting enhanced attention\u201d. The inventor field of the application form was filled with \u201cDABUS\u201d, indicating that the inventions had been autonomously generated by an AI system. The owner of the system sought to be recognized as the assignee of the patents. The patents were rejected, because an inventor had necessarily to be a human person. The decision was upheld, on appeal.",
    "excerpt":"\"The main request is not allowable because the\ndesignation of the inventor does not comply with Article 81, first sentence, EPC. Under the EPC the\ndesignated inventor has to be a person with legal\ncapacity. This is not merely an assumption on which the\nEPC was drafted. It is the ordinary meaning of the term\ninventor (see, for instance, Oxford Dictionary of\nEnglish: \u201ca person who invented a particular process or\ndevice or who invents things as an occupation\u201d; Collins\nDictionary of the English language: \u201ca person who\ninvents, esp. as a profession\u201d).\nThere is no reason to assume that the EPC uses the term\nin a special way departing from its ordinary meaning.\nWhen a provision of the EPC 2000 refers to or includes\nthe inventor(s), it uses the terms person or legal\npredecessor (e.g., Article 60(2) EPC or Article 55(1)\nEPC). So did the EPC 1973 in the corresponding legal\nprovisions. Article 60(1) EPC vests the rights to the\nEuropean patent in the inventor; thus, it postulates a\nperson with legal capacity. In this context, with the\nsecondary legislation (Rule 19 EPC) invoked by the\nReceiving Section supporting this interpretative\noutcome, it is not necessary to resort to the travaux\nfor the analysis. There is no lexical or contextual\nambiguity which the Board needs to dispel.\u201d",
    "link":"https:\/\/www.epo.org\/boards-of-appeal\/decisions\/pdf\/j200008eu1.pdf",
    "lat":null,
    "lng":null
  },
  {
    "region":"United Kingdom",
    "court":"United Kingdom Supreme Court",
    "caseName":"Thaler v. Comptroller-General of Patents, Designs and Trade Marks",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The applicant filed two patents, one for a food container and other for \u201cdevices and methods for attracting enhanced attention\u201d. The inventor field of the application form was filled with \u201cDABUS\u201d, indicating that the inventions had been autonomously generated by an AI system. The owner of the system sought to be recognized as the assignee of the patents. The Supreme Court of the United Kingdom considered that the appeal was not concerned with inventions generated by AI should be patentable, or if the meaning of the term \u201cinventor\" should be expanded, because those are policy issues. Restricting itself to the interpretation of the 1977 Act, the Court considered hat an inventor had to be a natural person.",
    "excerpt":"\"In my judgment, the position taken by the Comptroller on this issue is entirely\ncorrect. The structure and content of sections 7 and 13 of the Act, on their own and in\nthe context of the Act as a whole, permit only one interpretation: an inventor within the\nmeaning of the 1977 Act must be a natural person, and DABUS is not a person at all, let\nalone a natural person: it is a machine and on the factual assumption underpinning these\nproceedings, created or generated the technical advances disclosed in the applications\non its own. Here I use the term \u201ctechnical advance\u201d rather than \u201cinvention\u201d\n, and the\nterms \u201ccreate\u201d or \u201cgenerate\u201d rather than \u201cdevise\u201d or \u201cinvent\u201d deliberately to avoid prejudging the first issue we have to decide. But it is indisputable that DABUS is a\nmachine, not a person (whether natural or legal), and I do not understand Dr Thaler to\nsuggest otherwise.\u201d",
    "link":"https:\/\/supremecourt.uk\/uploads\/uksc_2021_0201_judgment_3f445a5dc7.pdf",
    "lat":55.3781,
    "lng":-3.436
  },
  {
    "region":"United Kingdom",
    "court":"High Court of Justice",
    "caseName":"Felicity Harber v. The Commissioners for HMRC",
    "year":2023,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The appellant used case law which was hallucinated by ChatGPT. However, they considered she did not know how to check their validity, and thus did not take her reliance on genAI into account. However, the Court noted this wastes time and public money, and also promotes cynicism about judicial precedents. ",
    "excerpt":"\"We acknowledge that providing fictitious cases in reasonable excuse tax appeals is likely to have less impact on the outcome than in many other types of litigation, both because the law on reasonable excuse is well-settled, and because the task of a Tribunal is to consider how that law applies to the particular facts of each appellant\u2019s case. But that does not mean that citing invented judgments is harmless. It causes the Tribunal and HMRC to waste time and public money, and this reduces the resources available to progress the cases of other court users who are waiting for their appeals to be determined. As Judge Kastel said, the practice also \u201cpromotes cynicism\u201d about judicial precedents, and this is important, because the use of precedent is \u201ca cornerstone of our legal system\u201d and \u201can indispensable foundation upon which to decide what is the law and its application to individual cases\u201d, as Lord Bingham\u2019s said in Kay v LB of Lambeth [2006] UKHL 10 at [42]. Although FTT judgments are not binding on other Tribunals, they nevertheless \u201cconstitute persuasive authorities which would be expected to be followed\u201d by later Tribunals considering similar fact patterns, see Ardmore Construction Limited v HMRC [2014] UKFTT 453 at [19].\n\u201c",
    "link":"https:\/\/caselaw.nationalarchives.gov.uk\/ukftt\/tc\/2023\/1007?query=\"artificial+intelligence\"",
    "lat":55.3781,
    "lng":-3.436
  },
  {
    "region":"United Kingdom",
    "court":"High Court of Justice",
    "caseName":"Getty Images, Inc. v. Stability AI, Ltd.",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"Getty Images argues Stability AI used its images without consent to train their models, infringing on their copyright. Moreover, the complainant argues that, since Stable Diffusion has generated its watermark in its outputs, their trademark has also been infringed upon. Stability AI filed an application seeking reverse summary judgement and to strike out the claims. The Court\u2019s decision focused mainly on whether the training had happened in the UK. It held that there were reasonable grounds for considering delivery may add to or alter the question of where Stable Diffusion was trained. Thus, the Training and Development claims were considered to have enough prospects of success to proceed to trial. The claims with regards to copyright infringement by Stable Diffusion generating works substantially similar to this copyright-protected and to database right infringement will also proceed to trial. ",
    "excerpt":"\"Having examined with care all the evidence before the court, I am not so satisfied. There seems to me to be (i) evidence potentially pointing away from the factual determination on the Location Issue that I am invited to reach by the Defendant; (ii) evidence raising unanswered questions and inconsistencies relevant to that determination; and (iii) reasonable grounds for believing that disclosure may add to or alter the evidence relevant to the question of where the training and development of Stable Diffusion took place. All of this clearly supports the proposition that the Training and Development Claim has a real prospect of success and must be permitted to go to trial. The Location Issue is certainly not an issue on which I can say at present that the Claimants\u2019 claim is doomed to fail.\u201c",
    "link":"https:\/\/caselaw.nationalarchives.gov.uk\/ewhc\/ch\/2023\/3090?query=\"artificial+intelligence\"",
    "lat":55.3781,
    "lng":-3.436
  },
  {
    "region":"United Kingdom",
    "court":"Court of Appeals",
    "caseName":"Comptroller-General of Patents, Designs and Trade Marks v. Emotional Perception AI Limited",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The case concerns the patentability of an artificial neural network (ANN)-based system developed by Emotional Perception AI Ltd (EPL), which provides media recommendations based on human emotional perception. The key legal question was whether the invention was excluded from patentability under Section 1(2) of the UK Patents Act 1977, which excludes computer programs \u201cas such.\u201d\n\nThe UK Intellectual Property Office (IPO) rejected the patent application, arguing that the ANN system was merely a computer program. The High Court (Sir Anthony Mann J) overturned this decision, ruling that the exclusion did not apply because the system was not a computer program as such and involved a technical effect. The Comptroller-General of Patents appealed. The Court of Appeal held that an ANN qualifies as a computer program because its weights and biases function as a set of instructions for processing information, regardless of whether implemented in hardware or software. Moreover, The Court of Appeal found that the ultimate function of the system (i.e., making subjective media recommendations) is not a technical effect under patent law. Instead, it relates to aesthetic preferences, making it excluded subject matter.",
    "excerpt":"\"In my judgment the Hearing Officer\u2019s conclusion is the right one. What makes the recommended file worth recommending are its semantic qualities. This is a matter of aesthetics or, in the language used by the Hearing Officer, they are subjective and cognitive in nature. They are not technical and do not turn this into a system which produces a technical effect outside the excluded subject matter\u201d",
    "link":"https:\/\/caselaw.nationalarchives.gov.uk\/ewca\/civ\/2024\/825?query=\"artificial+intelligence\"",
    "lat":55.3781,
    "lng":-3.436
  },
  {
    "region":"United Kingdom",
    "court":"First-Tier Tribunal (General Regulatory Chamber)",
    "caseName":"Public Law Project v. The Information Commissioner",
    "year":2023,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"This appeal was brought under section 57 of the Freedom of Information Act 2000 (FOIA) against a decision by the Information Commissioner (IC) dated 26 July 2022 (IC-130877-C0S1). The appellant sought access to information regarding the criteria used by the Home Office\u2019s (HO) MRAU triage model for assessing potential sham marriages. The Home Office withheld parts of the requested information under sections 31(1)(a) (prevention\/detection of crime) and 40(2) (personal data protection) of FOIA. The IC upheld the Home Office\u2019s decision, leading to this appeal. The appellant emphasized the public interest in transparency and accountability, particularly regarding the use of automated decision-making in immigration control. The Tribunal acknowledged the controversial nature of the triage model, noting its role within the UK\u2019s \u201chostile environment\u201d immigration policy. However, the Tribunal concluded that the risk of individuals exploiting the system outweighed the public interest in disclosure. The Tribunal noted that alternative legal mechanisms, such as judicial review, exist to challenge potential bias or discrimination.",
    "excerpt":"\"In relation to public interest, the Tribunal are of the view that there is a strong argument in favour of maintaining the exemption in so far as it is in the interests of the public to ensure immigration investigations are allowed to be conducted by those closest to considering all material issues pertaining to the detection of, for example misrepresentation, or gaming, or fraudulent scams, in a way that is lawful but protected under the appropriate use of exemptions and therefore is not interfered with. In that regard the Tribunal are of the view that the HO, in this case have acted properly and fairly in all the circumstances of the impugned request the subject of this appeal.\u201d",
    "link":"https:\/\/caselaw.nationalarchives.gov.uk\/ukftt\/grc\/2023\/102?query=\"artificial+intelligence\"",
    "lat":55.3781,
    "lng":-3.436
  },
  {
    "region":"Europe",
    "court":"Court of Justice of the European Union",
    "caseName":"Republic of Poland v. European Parliament, Council of the European Union",
    "year":2021,
    "issue":"Platforms",
    "finalDecision":null,
    "summary":"This case concerns the legality and implications of Article 17 of Directive 2019\/790, particularly its requirement for online content-sharing service providers to take measures to prevent copyright infringement. The core debate revolves around whether the directive, in practice, imposes an obligation on service providers to implement automatic content recognition (ACR) tools\u2014such as digital fingerprinting\u2014to filter and block copyrighted content before it is uploaded.\n\nThe Opinion acknowledges that while the final version of the Directive does not explicitly require ACR tools, it effectively mandates their use through the conditions for exemption from liability. To avoid liability, providers must demonstrate they have made \u201cbest efforts\u201d to prevent the upload of infringing content in accordance with \u201chigh industry standards.\u201d Given the scale of content uploaded to such platforms, manual review is impractical, leaving automated filtering as the only feasible solution. The Opinion concludes that Article 17 of Directive 2019\/790 can respect freedom of expression, but only if implemented with sufficient safeguards to prevent overblocking of lawful content. The key argument is that while the directive imposes significant restrictions on user expression by requiring proactive content filtering, it does not automatically violate freedom of expression because it includes safeguards\u2014particularly the recognition of user rights under copyright exceptions and the requirement for a complaint and redress mechanism.",
    "excerpt":"\"149.\u00a0In view of the risks of \u2018over-blocking\u2019 described in the subsection above, a liability regime such as that resulting from the contested provisions must, in my view, be accompanied by sufficient safeguards to minimise those risks and, therefore, ensure that the extent of the interference with freedom of expression is precisely circumscribed.\u00a0(187) Generally speaking, any kind of delegation, by public authorities, of the review of online legality to intermediary providers,\u00a0(188) in the form of monitoring obligations which are imposed directly or indirectly on those intermediaries, must be accompanied by such safeguards.\n(\u2026) 158.\u00a0The defendants and the interveners have rightly pointed out that one of the main safeguards intended to limit the risk of sharing service providers preventing, pursuant to the contested provisions, the availability on their services of content which lawfully reproduces the works and other protected subject matter identified by rightholders is contained in Article\u00a017(7) of Directive 2019\/790.\n159.\u00a0First, the first subparagraph of that paragraph provides that \u2018the cooperation between\u00a0\u2026 sharing service providers and rightholders\u00a0(194) shall not result in the prevention of the availability of works or other subject matter uploaded by users, which do not infringe copyright and related rights, including where such works or other subject matter are covered by an exception or limitation\u2019.\u00a0(195)\n160.\u00a0Secondly, in accordance with the second subparagraph of that paragraph, Member States must ensure that users are able to rely on the exceptions and limitations relating to (a) quotation, criticism and review and (b) use for the purpose of caricature, parody or pastiche\u00a0(196) when they upload content to sharing services.\n\u201c",
    "link":"https:\/\/www.bailii.org\/cgi-bin\/format.cgi?doc=\/eu\/cases\/EUECJ\/2021\/C40119_O.html&query=(\"artificial+intelligence\")",
    "lat":null,
    "lng":null
  },
  {
  "region": "European Union",
  "court": "Court of Justice of the European Union",
  "caseName": "Case C-203/22",
  "year": 2025,
  "issue": "Automated decisions",
  "finalDecision": "Yes",
  "summary": "The complainant sought meaningful information about the automated profiling that led to her credit denial, but the data controller refused full disclosure, citing trade secrets. The Court ruled that Article 15(1)(h) GDPR grants data subjects a right to an explanation of the logic behind automated decision-making, especially where such decisions significantly affect them. This right is instrumental for exercising Article 22(3) GDPR, expressing one’s view and contesting the decision, which would be ineffective without understanding how the decision was reached; thus, “meaningful information” must explain the procedure and principles used, in an intelligible and accessible manner.",
  "excerpt": "55 In particular, in the specific context of the adoption of a decision based solely on automated processing, the main purpose of the data subject’s right to obtain the information provided for in Article 15(1)(h) of the GDPR is to enable him or her effectively to exercise the rights conferred on him or her by Article 22(3) of that regulation, namely the right to express his or her point of view on that decision and to contest it.\n\n56 If the individuals affected by an automated decision, including profiling, were not in a position to understand the reasons which led to that decision before expressing their point of view or contesting the decision, those rights would not, accordingly, satisfy in full their purpose of protecting those individuals against the particular risks to their rights and freedoms represented by the automated processing of their personal data (see, to that effect, judgment of 7 December 2023, SCHUFA Holding and Others (Scoring), C‑634/21, EU:C:2023:957, paragraph 57).",
  "link": "https://curia.europa.eu/juris/document/document.jsf?text=&docid=295841&pageIndex=0&doclang=EN&mode=lst&dir=&occ=first&part=1&cid=14043925",
  "lat": null,
  "lng": null
  },
  {
    "region":"Germany",
    "court":"Federal Constitutional Court",
    "caseName":"Constitutional complaints against state laws related to automatic data processing",
    "year":2023,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"The Federal Constitutional Court of Germany ruled that sections of laws in Hesse and Hamburg authorizing automated data analysis by police are unconstitutional due to their lack of clear safeguards against excessive interference with personal rights, particularly with informational self-determination. \tThe Court emphasized that automated data analysis produces new intelligence that can significantly intrude on personal privacy. Moreover, the use of AI-driven predictive policing tools (e.g., detecting statistical anomalies) was left unrestricted, raising concerns about potential discrimination and wrongful targeting.\n",
    "excerpt":"\"The use of self-learning systems \u2013 i.e. artificial intelligence or AI \u2013 can interfere with fundamental rights in a particularly intrusive manner depending on the particular use in question. The advantages of such systems \u2013 as well as the specific dangers they pose \u2013 lie in the fact that they do not simply apply the criminologically sound profiles used by individual police officers, but rather that they automatically refine these profiles, or in some cases even create entirely new ones, and then continue to combine them during further stages of the analysis. (\u2026) This enables particularly far-reaching insights and assumptions to be generated about a person. The verification of such information can be difficult in practice because, over the course of the machine learning process, complex algorithmic systems can increasingly detach themselves from the human programming that created them, with the machine learning process and the results generated becoming increasingly difficult to scrutinise (cf. CJEU, Judgment of 21 June 2021, Ligue des droits humains , C-817\/19, ECLI:EU:C:2022:491, para. 195). State oversight over the technology could then be rendered impossible. Furthermore, if software from private actors or foreign states is deployed, there is a risk that third parties could manipulate or gain access to data in undetected ways ([...]). Another specific challenge is to prevent the emergence and application of algorithmic discrimination. Self-learning systems may only be used in police work if special procedural safeguards are in place to ensure that sufficient levels of protection are guaranteed despite the reduced possibilities for exercising scrutiny.\u201d",
    "link":"https:\/\/www.bundesverfassungsgericht.de\/SharedDocs\/Entscheidungen\/EN\/2023\/02\/rs20230216_1bvr154719en.html?nn=148454",
    "lat":51.1657,
    "lng":10.4515
  },
  {
    "region":"Germany",
    "court":"Federal Court of Justice",
    "caseName":"X ZB 5\/22",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The German Federal Court of Justice (FCJ) ruled that AI-generated inventions can be patented in Germany, but a human inventor must be named in the application. The decision confirms that patent protection is reserved for natural persons while recognizing that AI-assisted inventions meet existing patentability criteria.\n\nThe case involved a patent application for a food and beverage container created by the AI system DABUS, which was rejected because it listed only the AI as the inventor. The FCJ upheld the rejection but allowed the patent if a human who influenced the AI system was named instead.\n",
    "excerpt":"-",
    "link":"https:\/\/juris.bundesgerichtshof.de\/cgi-bin\/rechtsprechung\/document.py?Gericht=bgh&Art=en&az=X ZB 5\/22&nr=138469",
    "lat":51.1657,
    "lng":10.4515
  },
  {
    "region":"Germany",
    "court":"Hamburg Regional Court",
    "caseName":"Robert Knechte v. LAION, e.V",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The Hamburg Regional Court ruled that LAION\u2019s use of a copyrighted image for AI training data collection was legal under Germany\u2019s text and data mining (TDM) exception for scientific research. The court dismissed photographer Robert Kneschke\u2019s lawsuit, finding that downloading the image to verify its metadata was covered by Section 60d of the German Copyright Act, which allows TDM by non-commercial research organizations. It set three stages of AI development apart: dataset creation, AI model creation and the use of AI to generate content. The second step does not necessarily lead to the third, as, for example, the training process can fail.\n\n",
    "excerpt":"-",
    "link":"https:\/\/pdfupload.io\/docs\/4bcc432c",
    "lat":51.1657,
    "lng":10.4515
  },
  {
    "region":"France",
    "court":"French Constitutional Council",
    "caseName":"Decision 2024-866 DC",
    "year":2024,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The French Constitutional Council reviewed the Law to Secure and Regulate the Digital Space.\nIt invalidated provisions creating an offense for online insults, ruling that they violated freedom of expression and lacked legal clarity. It partially upheld the government\u2019s ability to collect data from platforms to regulate systemic risks but imposed safeguards. The Council ruled that the state cannot use facial recognition and must limit data retention to protect privacy.\n\n",
    "excerpt":"-",
    "link":"https:\/\/www.legifrance.gouv.fr\/cons\/id\/CONSTEXT000049582459?dateDecision=&init=true&page=1&query=\"Intelligence+artificielle\"&searchField=ALL&tab_selection=constit",
    "lat":46.6034,
    "lng":1.8883
  },
  {
    "region":"France",
    "court":"French Constitutional Council",
    "caseName":"Decision 2023-850 DC",
    "year":2023,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The French Constitutional Council upheld most provisions of the law related to surveillance related to the 2024 Olympic and Paralympic Games. The court recognized that the use of algorithmic video surveillance, including AI processing of images from public cameras and drones, served the constitutional objective of preventing threats to public order. However, it acknowledged concerns about the technology\u2019s impact on fundamental rights. In approving the experiment with AI-driven video analysis, the court insisted that such systems remain under strict human supervision. The judges maintained that these provisions do not in themselves violate privacy rights, but their implementation must include fundamental rights safeguards, and any extension beyond the experimental period could ensue a reassessment of their constitutional implications.",
    "excerpt":"\"To meet the objective of constitutional value of preventing violations of public order, the legislator may authorize the algorithmic processing of images collected by means of a video protection system or cameras installed on aircraft. Although such processing has neither the object nor the effect of modifying the conditions under which these images are collected, it nevertheless carries out a systematic and automated analysis of these images that may significantly increase the number and accuracy of the information that can be extracted from them. Therefore, the implementation of such monitoring systems must be accompanied by special safeguards to safeguard the right to respect for privacy.\u201d",
    "link":"https:\/\/www.legifrance.gouv.fr\/cons\/id\/CONSTEXT000047602516?dateDecision=&init=true&page=1&query=\"Intelligence+artificielle\"&searchField=ALL&tab_selection=constit",
    "lat":46.6034,
    "lng":1.8883
  },
  {
    "region":"France",
    "court":"Conseil d\u2019\u00c9tat",
    "caseName":"Conseil d'\u00c9tat, Juge des r\u00e9f\u00e9r\u00e9s, 21\/12\/2023, 489990",
    "year":2023,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The Conseil d\u2019\u00c9tat, acting as an urgent administrative judge, overturned a lower court ruling that had ordered the C\u0153ur C\u00f4te Fleurie intermunicipal authority to stop using the BriefCam software and erase all related data, except for a single copy placed under the control of the CNIL (French Data Protection Authority).\n\nThe Conseil d\u2019\u00c9tat found that the lower court had wrongly issued an emergency injunction without sufficient justification. It held that the mere presence of AI-powered video analytics functionalities, such as object and movement recognition, did not in itself constitute an urgent threat to fundamental rights. The ruling emphasized that while the software had capabilities for facial recognition, the intermunicipal authority had not activated them, and no evidence showed they had been used. Furthermore, the court noted that the AI-assisted surveillance was only applied to pre-recorded footage, not for real-time tracking or automated decision-making.\nGiven that CNIL was already investigating the use of AI in public surveillance, the Conseil d\u2019\u00c9tat ruled that there was no immediate need for additional measures. ",
    "excerpt":"\"9. On the other hand, if it is true that the software in question includes, in the \"Review\" module, image analysis functionality, in particular by applying filters, for example by sex, size or type of clothing, or analysis of movement behavior, the community of municipalities indicates that the software is not used to ensure, through the implementation of algorithmic processing, an automated monitoring of people or detect events and trigger alerts in real time, the \"Responde\" module with which the software can be equipped not being available. Deployed in the intercommunality for several years, for a limited number of cameras, it appears, in the state of the investigation, that this system, as it is calibrated and can reasonably be mobilized, is only used for a deferred proofreading, over a limited area and time, of the images collected by the cameras concerned, in particular for the purpose of vehicle analysis and a search for license plates, for the needs of an investigation and participates in the smooth running of the investigation by reducing the times for reading and exploitation of these images.\n\u201c",
    "link":"https:\/\/www.legifrance.gouv.fr\/ceta\/id\/CETATEXT000048659389?dateDecision=&query=\"Intelligence+artificielle\"&searchField=ALL&tab_selection=cetat",
    "lat":46.6034,
    "lng":1.8883
  },
  {
    "region":"France",
    "court":"Conseil d\u2019\u00c9tat",
    "caseName":"9th chambers united, 30\/12\/2021, 440376",
    "year":2021,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The Conseil d\u2019\u00c9tat rejected all challenges against the DataJust decree, which authorized an automated system to analyze court decisions for assessing compensation in bodily injury cases.\nThe court ruled that the decree complied with GDPR and French data protection laws, serving a legitimate public interest by improving legal predictability. It emphasized that the system was experimental, limited to two years, and did not affect judicial decision-making as it was not to be made available to magistrates oe parties.\nPrivacy concerns were dismissed, citing pseudonymization, a legitimate purpose, and that individual notification of data subjects was deemed impractical.\n",
    "excerpt":"\"Secondly, the applicants dispute the purposes of this processing on the grounds that the algorithm it aims to develop would be both contrary to the principles of individualization and full compensation for damage, unnecessary because of the existence of other tools having the same purpose, and biased because the processing does not take into account amicable compensation and the evolution of the law. However, it is clear from the documents in the file that the purpose of the processing authorized by the contested decree is to develop an algorithm for the development of an indicative reference framework for compensation for personal injury intended to be used to assess these injuries in the context of both the amicable and judicial settlement of disputes. It thus tends to ensure easier access to the case law on compensation for personal injury in order to guarantee the accessibility and predictability of the law. Moreover, and at this stage, this processing, the duration of which is reduced to two years, is limited to the development phase of an artificial intelligence tool, is only experimental and is not intended, at this stage, to be made available to magistrates or parties. It follows that the plea alleging that the purposes pursued by the processing are not legitimate must be dismissed.\u201d\n",
    "link":"https:\/\/www.legifrance.gouv.fr\/ceta\/id\/CETATEXT000044806169?dateDecision=&query=\"Intelligence+artificielle\"&searchField=ALL&tab_selection=cetat",
    "lat":46.6034,
    "lng":1.8883
  },
  {
    "region":"France",
    "court":"Cour de Cassation",
    "caseName":"Cour de cassation, civile, Chambre sociale, 12 avril 2018, 16-27.866",
    "year":2018,
    "issue":"Labor",
    "finalDecision":"Yes",
    "summary":"This case concerns whether the CHSCT (Comit\u00e9 d\u2019Hygi\u00e8ne, de S\u00e9curit\u00e9 et des Conditions de Travail) had the right to appoint an expert to assess the impact of IBM Watson, an AI tool introduced by Cr\u00e9dit Mutuel, on employees\u2019 working conditions. Under Article L. 4614-12 of the French Labor Code, the CHSCT can call for expert evaluations when a significant modification affects employees\u2019 health, safety, or working conditions. The CHSCT argued that Watson fundamentally changed working conditions, carrying itself the potential for redistribution of an employee activities, justifying an expert review. Cr\u00e9dit Mutuel contested this, claiming that Watson merely optimized email processing and workflow without altering core job functions.\n\nThe court ruled in favor of Cr\u00e9dit Mutuel, finding that Watson only facilitated certain tasks, such as sorting emails and suggesting responses, rather than redefining roles or work conditions in a way that would trigger CHSCT oversight.",
    "excerpt":"\"But having noted that the introduction of the Watson computer program will help account managers process the abundant emails they receive either by redirecting them from the keywords they contain to the counter where they can be directly processed because of the skills previously defined by the head of agency in view of the request, or by treating them in order of priority due to the urgency they present and which will be reported to them, or even by responding to them in an appropriate way by proposing a declination of situations to unforgetably adapt the answer to the question posed, that it therefore directly translates into minor consequences in the direct working conditions of employees whose tasks will be facilitated, the president of the high court, who was not obliged to follow the parties in the detail of their argument, was able to deduce that the existence of an important project modifying the health and safety conditions or the working conditions of employees was not demonstrated and rightly annulled the deliberation of the CHSCT apomining an expert; that the plea is not well-founded;\n\u201c",
    "link":"https:\/\/www.legifrance.gouv.fr\/juri\/id\/JURITEXT000036829790?dateDecision=&init=true&page=1&query=\"intelligence+artificielle\"&searchField=ALL&tab_selection=juri",
    "lat":46.6034,
    "lng":1.8883
  },
  {
    "region":"Italy",
    "court":"Garante Privacy",
    "caseName":"Measure of January 30, 2025 (10098477)",
    "year":2025,
    "issue":"Privacy",
    "finalDecision":"Yes",
    "summary":"The Italian Data Protection Authority has limited Hangzhou DeepSeek Artificial Intelligence Co., Ltd. and Beijing DeepSeek Artificial Intelligence Co., Ltd. from processing personal data of individuals in Italy. The companies claimed they were not operating in the Italian market, but the GPDP found that their service was still accessible via their website, meaning they were subject to the GDPR.",
    "excerpt":"\"CONSIDERED, in the light of the investigations carried out, that the fact that the Companies offer the DeepSeek service to interested parties who are located in the European Union, in particular in Italy and who, therefore, process the personal data of the latter is not revocable in doubt;\nCONSIDERED therefore that art. 3, par. 2, letter a), of the Regulation applies, which provides for a specific territorial scope of application of the regulation itself;\nNOTED that the Companies, through the response to the request for information forwarded by the Guarantor, did not clarify the main aspects regarding the processing activities implemented as part of the DeepSeek service, in violation of Article 31 of the Regulation;\nDETECTED that the privacy policy, updated to December 5, 2025, published on the website, is only available in English and does not exhaustively comply with the information obligations provided for by the legislation, in violation of articles 12, 13 and 14 of the Regulation;\nNOTED, in particular, that the privacy policy does not indicate in a punctual and granular way the conditions of lawfulness relating to each processing activity implemented as part of the DeepSeek service, in violation of Article 6 of the Regulation;\nNOTED that the lack of information regarding the processing activity carried out as part of the DeepSeek service gives rise to obvious consequences also with regard to the exercise of rights, in violation of the provisions of Chapter III of the Regulation;\nFOUND that, as it results from the privacy policy, the data collected by the data holder as part of the provision of the DeepSeek service are stored in the People's Republic of China, in violation of the guarantees provided for by the Regulation, in particular article 32 on data processing security;\nNOTED that the owner, despite being required to comply with the Regulations due to the service offered (pursuant to art. 3, par.2, of the Regulation), has not designated a representative in writing, in violation of article 27 of the Regulation;\nACCREED, therefore, the need to dispose, pursuant to art. 58, par. 2, lett. f), of the Regulation - as a matter of urgency and pending the completion of the necessary investigation with respect to what has so far emerged against the Companies, the measure of the definitive limitation of the processing of personal data of data subjects who are in Italian territory;\nCONSIDERED necessary to order the aforementioned limitation with immediate effect from the date of receipt of this provision, reserving any other determination to the outcome of the definition of the investigation initiated on the case;\n\"",
    "link":"https:\/\/www.garanteprivacy.it\/web\/guest\/home\/docweb\/-\/docweb-display\/docweb\/10098477",
    "lat":41.8719,
    "lng":12.5674
  },
  {
    "region":"Italy",
    "court":"Garante Privacy",
    "caseName":"Measure of March 30, 2023 (9870832)",
    "year":2023,
    "issue":"Privacy",
    "finalDecision":"Yes",
    "summary":"The Italian Data Protection Authority (GPDP) issued a limitation order on OpenAI\u2019s ChatGPT service in Italy due to multiple GDPR violations. The authority found that OpenAI failed to provide adequate information to users and affected individuals about how their data was collected and processed. It also determined that OpenAI lacked a legal basis for collecting personal data to train ChatGPT\u2019s algorithms, processed inaccurate personal data, and failed to implement age verification measures.",
    "excerpt":"\"DETECTED, from a verification carried out in this regard, that no information is provided to users, nor to interested parties whose data have been collected by OpenAI, L.L.C. and processed through the ChatGPT service;\nDETECTED the absence of an appropriate legal basis in relation to the collection of personal data and their processing for the purpose of training the algorithms underlying the operation of ChatGPT;\nDETECTED that the processing of personal data of the data subjects is inaccurate as the information provided by ChatGPT does not always correspond to the real data;\nNOTED, moreover, the absence of any verification of the age of users in relation to the ChatGPT service which, according to the terms published by OpenAI L.L.C., is reserved for subjects who have reached at least 13 years of age;\nCONSIDERING that the absence of filters for children under the age of 13 exposes them to absolutely unsate responses with respect to their degree of development and self-awareness;\n\u201c",
    "link":"https:\/\/www.garanteprivacy.it\/web\/guest\/home\/docweb\/-\/docweb-display\/docweb\/9870832",
    "lat":41.8719,
    "lng":12.5674
  },
  {
    "region":"Italy",
    "court":"Garante Privacy",
    "caseName":"Measure of January 11, 2024 (9977020)",
    "year":2024,
    "issue":"Privacy",
    "finalDecision":"Yes",
    "summary":"The Italian Data Protection Authority found that the Municipality of Trento unlawfully processed personal data, including sensitive information and data related to crimes, as part of the \u201cMarvel\u201d and \u201cProtector\u201d projects. The municipality failed to provide a valid legal basis for data collection, did not ensure effective anonymization, lacked transparency in informing the public, and improperly shared data with third parties, including foreign authorities. Additionally, the required Data Protection Impact Assessment was inadequate. As a result, the authority imposed a \u20ac50,000 fine, ordered the deletion of collected data, and prohibited further processing.",
    "excerpt":"\"Given that urban security cameras and microphones placed on public roads have been used with the specific objective of identifying and analyzing facts relevant to the protection of public security, which can therefore integrate criminal cases, and considering that users who post hate messages\/comments on the Twitter (\"X\") and YouTube platforms, analyzed in order to detect threats to the security of places of worship, may commit specific crimes (see, for example, art. 604-bis c.p. in the field of propaganda and incitement to commit crimes on grounds of racial, ethnic and religious discrimination), the Municipality, in the context of the two projects, has implemented a processing of personal data relating to crimes (see art. 10 of the Regulation and 2-octies of the Code). (\u2026) Furthermore, given that the aforementioned messages\/comments acquired by social networks concern the religious sphere and may reveal the religious beliefs of the relative authors or third parties mentioned in said messages, the Municipality has also implemented a processing of personal data belonging to particular categories (see art. 9 of the Regulation and 2-sexies of the Code).\"",
    "link":"https:\/\/www.garanteprivacy.it\/web\/guest\/home\/docweb\/-\/docweb-display\/docweb\/9977020",
    "lat":41.8719,
    "lng":12.5674
  },
  {
    "region":"Italy",
    "court":"Garante Privacy",
    "caseName":"Injunction order against Clearview AI (9751362)",
    "year":2022,
    "issue":"Biometrics",
    "finalDecision":"Yes",
    "summary":"The Italian Data Protection Authority fined Clearview AI \u20ac20 million for unlawfully processing biometric and geolocation data of individuals in Italy. The company collected over 10 billion facial images worldwide through web scraping and used AI to create biometric profiles without a valid legal basis, violating GDPR principles such as transparency, purpose limitation, and storage limitation. The authority ordered Clearview AI to delete data related to individuals in Italy, banned further data collection and processing through its facial recognition system, and required the company to appoint an EU representative to facilitate data subject rights.",
    "excerpt":"\"Likewise, it is noted that even the publication on the Internet of personal data by the subject to whom they refer, for example in the context of a social media network, does not, in itself, entail a sufficient condition to justify its free reuse by third parties. If, in fact, it is true that the Regulation (and, therefore, in this case, the principle of purpose referred to in art. 5, para. 1, letter b), of the Regulation) does not apply to the processing of personal data carried out by a natural person for the exercise of activities of an exclusively personal or domestic nature (so-called household exemption, referred to in art. 2, para. 2, letter c), of the Regulation), even with reference to online activities, it is also true that the derogation must be interpreted in a restrictive sense. As sanctioned by the Court of Justice of the European Union, the derogation \"includes only activities that fall within the scope of the private or family life of individuals, which manifestly does not occur in the case of the processing of personal data consisting of their publication on the Internet in such a way as to make such data accessible to an indefinite number of people\" (see judgment 6 November 2003, case C-101\/01, par. 47) It must therefore be considered that even the publication of personal data by the interested party on social networks is bound to the mere purpose for which the interested party intended to make them public (for example, visibility within a particular social network for the sole purposes underlying the use of this SNS).\nThe correctness of the thesis is supported by the Article 29 Working Group, which clarified \"that, even if they have been made accessible to the public, personal data continue to be considered such and, consequently, adequate guarantees continue to be necessary for their processing\" (cf. Opinion 6\/2014 - WP217) and, more recently, by the Committee for the protection of personal data, which established that \"any communication of personal data constitutes a specific processing for which the data controller must have a legal basis among those referred to in Article 6\", that \"the transmission of footage to third parties for purposes other than those for which the data were collected is possible pursuant to Article 6, paragraph 4\" and, finally, that \"the third party recipient must carry out its own legal analysis, in particular by identifying the legal basis of its processing pursuant to Article 6\" (cf. Guidelines 3\/2019 on the processing of personal data through video devices, version 2.0, January 29, 2020).\nAs for, in particular data scraping, this is a particular method of collection that takes place completely without the knowledge of the interested parties.\u201d",
    "link":"https:\/\/www.garanteprivacy.it\/web\/guest\/home\/docweb\/-\/docweb-display\/docweb\/9751362",
    "lat":41.8719,
    "lng":12.5674
  },
  {
    "region":"Italy",
    "court":"Garante Privacy",
    "caseName":"Injunction Order against Foodinho s.r.l (9675440)",
    "year":2021,
    "issue":"Bias",
    "finalDecision":"Yes",
    "summary":"The Italian Data Protection Authority fined Foodinho S.r.l. \u20ac2.6 million for GDPR violations, particularly concerning its use of automated profiling systems to evaluate and rank delivery riders. The company used algorithms to score riders based on customer and retailer feedback, which influenced their priority in booking work shifts. However, Foodinho failed to provide meaningful information about how these algorithms operated, the logic behind them, or their impact on riders\u2019 opportunities. The system also lacked safeguards to allow riders to contest automated decisions or obtain human intervention, violating GDPR\u2019s Article 22. Additionally, the authority found that the company\u2019s algorithmic decision-making was not regularly checked for fairness and accuracy, increasing the risk of errors and potential discrimination.",
    "excerpt":"\"Considering that in the concrete case one of the exemptions provided for in art. 22 is applicable with respect to the right not to be subject to a decision based solely on automated processing, including profiling, which produces legal effects or that has a significant impact on the data subject and that, in particular, it turns out that the processing is necessary for the execution of a contract stipulated between the parties (see art. 22, par. 2, letter a) of the Regulation, however, it does not appear that the company has implemented appropriate measures to \"protect the rights, freedoms and legitimate interests of the interested party, at least the right to obtain human intervention [...], to express one's opinion and to challenge the decision\u201d.\nUnlike what the company claims, there is no evidence of the adoption of measures related to the exercise of rights through the activation of dedicated channels (chat accessible through the application, dedicated counters, emails: see defensive memories, p. 12) Nor does it appear that the interested parties were in any way aware of the possibility of exercising these rights with respect to the decisions taken through the use of the platform.\nFurthermore, it does not appear that the company, in relation to the processing carried out as a data controller, has adopted technical and organizational measures to protect data subjects aimed at periodically verifying the correctness and accuracy of the results of the algorithmic systems, the accuracy, relevance and adequacy of the data used by the system with respect to the purposes pursued, and to reduce as much as possible the risk of distorted or discriminatory effects, with reference to the operation of the digital platform, including the scoring system and the order assignment system (see specific references in this regard in Recital 71, cit.; v. European Commission, A Union of Equality: The Strategy for Gender Equality 2020-2025, 5.3.2020, COM(2020) 152 final, \"Arth algorithms and related machine learning, if not sufficiently transparent and robust, are likely to reproduce, amplify or contribute to gender bias that programmers may not be aware of or which are the result of a specific data selection\"). This also in relation to the obligations imposed by the sector discipline regarding the operation of the platforms (see art. 47-quinquies, d. lgs. n. 81\/2015, in force since 3.11.2019 \"1. The anti-discrimination rules and those to protect the freedom and dignity of the worker provided for employees, including access to the platform, apply to workers referred to in Article 47-bis. 2. The exclusion from the platform and the reductions of work opportunities attributable to the non-acceptance of the service are prohibited.\u201d, on which, more fully, par. 3.3.9.; v. Consultative Committee of the Convention for the Protection of Individuals with regard to automatic processing of personal data (Convention 108), Guidelines on Artificial Intelligence and Data Protection, Strasbourg, 25 January 2019, \u201cAI developers, manufacturers, and service providers should adopt forms of algorithm vigilance that promote the accountability of all relevant stakeholders throughout the entire life cycle of these applications, to ensure compliance with data protection and human rights law and principles\u201d.\n\u201c",
    "link":"https:\/\/www.garanteprivacy.it\/web\/guest\/home\/docweb\/-\/docweb-display\/docweb\/9675440",
    "lat":41.8719,
    "lng":12.5674
  },
  {
    "region":"Netherlands",
    "court":"Rechtbank Den Haag",
    "caseName":"SyRI legislation in breach of European Convention on Human Rights (ECLI:NL:RBDHA:2020:1878)",
    "year":2020,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The District Court of The Hague ruled that the Netherlands\u2019 AI-based welfare fraud detection system (DyRI) violated art. 8 of the European Convention on Human Rights due to its lack of transparency and explainability. It noted the system used proprietary algorithms to generate risk profiles of welfare recipients, but neither the court nor individuals affected could understand how the model worked or challenge its decisions.",
    "excerpt":"-",
    "link":"https:\/\/uitspraken.rechtspraak.nl\/details?id=ECLI:NL:RBDHA:2020:1878",
    "lat":52.1326,
    "lng":5.2913
  },
  {
    "region":"Netherlands",
    "court":"Rechtbank Gelderland",
    "caseName":"ECLI:NL:RBGEL:2024:3636",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"A judge from the Gelderland District Court in the Netherlands utilized ChatGPT, and cited it expressly, to determine the average lifespan of solar panels and the prevailing electricity price per kWh during a property dispute.",
    "excerpt":"\"The district court estimates, partly with the help of ChatGPT, the average lifespan of solar panels from 2009 at 25 to 30 years; that service life is therefore set at 27.5 years here. So those panels still had about 15 years to go in 20225. So over that remaining time, it is a maximum (probably decreasing) 7.5 mWh yield loss. Assuming, again on the basis of ChatGPT, a current average kWh price of \u20ac 0.30 (\u20ac 0.29 to \u20ac 0.34, depending on the type of contract, but [claiming party in the convention] has not said anything about that)6, the loss of return, with a more or less constant kWh price, is thus about \u20ac 2,250,--. Why not join the amount of \u20ac 13,963.20 mentioned by [claiming party in the agreement] is sufficiently justified with the above and the notes 4 to 7.7\u201d",
    "link":"https:\/\/uitspraken.rechtspraak.nl\/details?id=ECLI:NL:RBGEL:2024:3636&showbutton=true&keyword=chatgpt&idx=1",
    "lat":52.1326,
    "lng":5.2913
  },
  {
    "region":"Netherlands",
    "court":"Dutch Supervisory Authority",
    "caseName":"Decision penalty Clearview AI",
    "year":2024,
    "issue":"Biometrics",
    "finalDecision":"Yes",
    "summary":"The Dutch Supervisory Authority fined Clearview AI \u20ac30.5 million for illegally collecting and processing biometric data of individuals in the Netherlands without a legal basis and failing to comply with transparency and data subject rights under the GDPR.",
    "excerpt":"-",
    "link":"https:\/\/autoriteitpersoonsgegevens.nl\/actueel\/ap-legt-clearview-boete-op-voor-illegale-dataverzameling-voor-gezichtsherkenning",
    "lat":52.1326,
    "lng":5.2913
  },
  {
    "region":"China",
    "court":"Beijing Internet Court",
    "caseName":"Li v. LIU",
    "year":2023,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The plaintiff, LI, generated an AI-created image using Stable Diffusion and posted it on Little Red Book, later discovering that the defendant, LIU, had used the image without permission, removed its watermark, and published it on Baijiahao. The Beijing Internet Court ruled that the AI-generated image qualified as a copyrighted work under Chinese law and that LI was its author, because the image reflected his original intellectual investment. The Court ordered LIU to publicly apologize on Baijiahao for 24 hours and compensate LI with 500 yuan for economic losses.",
    "excerpt":"\"Therefore, the plaintiff believes that the model, the prompt and negative prompt words,\nand the parameters all reflect the choice, selection, arrangement, and design made by the\nplaintiff; they are the result of the plaintiff\u2019s intellectual labor, which is obviously original. In\naddition, from an objective perspective, the picture involved obviously conforms to the\ncharacteristics of a work; and it has garnered many views and likes after being posted by the\nplaintiff on Little Red Book, which means that it can be identified as a work with originality\naccording to the standard of the general public.\u201d",
    "link":"https:\/\/english.bjinternetcourt.gov.cn\/pdf\/BeijingInternetCourtCivilJudgment112792023.pdf",
    "lat":35.8617,
    "lng":104.1954
  },
  {
    "region":"China",
    "court":"Guangzhou Internet Court",
    "caseName":"Yue 0192 Civil Judgment of First Instance No. 113",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"China\u2019s Guangzhou Internet Court ruled that an AI company infringed copyright by generating Ultraman images through its AI painting service, violating the plaintiff\u2019s rights of reproduction and adaptation. The Court found that the AI-generated images were substantially similar to the plaintiff\u2019s copyrighted works and that the AI company had access to these works due to their high reputation. The defendant was ordered to prevent further infringement, compensate the plaintiff RMB 10,000, and implement compliance measures",
    "excerpt":"-",
    "link":"https:\/\/www.ciplawyer.cn\/articles\/152937.html?prid=170",
    "lat":35.8617,
    "lng":104.1954
  },
  {
    "region":"China",
    "court":"Hangzhou Internet Court",
    "caseName":"Case No. Zhejiang 0192 Civil No. 1587",
    "year":2025,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The Hangzhou Internet Court ruled that an AI platform operator committed contributory infringement of copyright by enabling users to generate Ultraman-related images through a LoRA model trained on copyrighted Ultraman works. The Court found that the defendant\u2019s platform actively facilitated infringement by providing tailored AI services, deriving direct economic benefit, and failing to implement reasonable preventive measures despite having the ability to do so. As a result, the Court ordered the defendant to cease infringement and compensate the plaintiff 30,000 RMB for economic losses and related expenses.",
    "excerpt":"-",
    "link":"https:\/\/mp.weixin.qq.com\/s?__biz=MzU4NzExNTkyMQ==&mid=2247507667&idx=1&sn=c524cc81dff2bf48a3469f94173fa8b7&scene=25&ascene=60&devicetype=android-35&version=28003842&nettype=h2g2&abtest_cookie=AAACAA==&lang=en&session_us=gh_512c7f738a36&countrycode=US&exportkey=n_ChQIAhIQVqEbFU3Qel6lUFUfvTmSHRLkAQIE97dBBAEAAAAAAPUIC7ifeLMAAAAOpnltbLcz9gKNyK89dVj0szNvVpdxYa4yL2j+xzxnkln8fScT3fvqoxf3bPpwPzw79qGNAcaxztKTEupPeUjnFPKU0hzhoaeIPZQ5EmzgJdwRMZ1qxTsHEjMsTZoxvBB4iy9og0l30J\/MiYclNo6MuY1bCfScbfphulkH3Mlj0U5ZCfe6jBivxtXkRyjYRWUeEKeBH36zntaymdQYBvjtvy34gSS0T5bqHhLKJYdQrzOvm0IN7BNAw7M\/D6CK3jDZ4TR2apnMeb1e7GJkYA==&pass_ticket=PWGM6uRv2tJ+Ie1AeeXpOZ1uQGTVwnfUM7JiPfCXArERXSKAJTpoxrMP9BXrRz9V&wx_header=3",
    "lat":35.8617,
    "lng":104.1954
  },
  {
    "region":"China",
    "court":"Beijing Internet Court",
    "caseName":"(2023) Jing 0491 Min Chu No. 12142",
    "year":2024,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"A professional voice actor discovered that her voice had been replicated without consent using AI and distributed through text-to-speech applications, after a media company unlawfully provided her recordings for AI training. The Beijing Internet Court ruled that AI-generated voices can infringe personality rights if they are recognizable, finding that the unauthorized use of the plaintiff\u2019s voice constituted infringement. The Court ordered the defendants responsible for the AI training and commercialization to apologize and pay RMB 250,000 in damages for economic losses and emotional distress.",
    "excerpt":"-",
    "link":"https:\/\/mp.weixin.qq.com\/s\/_GxGaG6Q2NYHJWQuOtMyrQ?from=industrynews&version=4.1.20.6024&platform=win",
    "lat":35.8617,
    "lng":104.1954
  },
  {
    "region":"Brazil",
    "court":"Superior Court of Justice",
    "caseName":"HABEAS CORPUS N\u00ba 980750 - DF",
    "year":2025,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"A habeas corpus was filed to clarify whether the AI tool STJ Logos was issuing judicial decisions without proper human review, allegedly violating constitutional and legal principles.\nThe Superior Court of Justice dismissed the request due to lack of jurisdiction and improper use of habeas corpus, which is limited to protecting freedom of movement. The petitioner was sanctioned with a fine for repeated frivolous filings, including unrelated requests in prior cases, and warned of further penalties for continued abuse of judicial resources.",
    "excerpt":"-",
    "link":"https:\/\/processo.stj.jus.br\/processo\/pesquisa\/?num_registro=202500421470",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Superior Court of Justice",
    "caseName":"AREsp 1786691",
    "year":2025,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"A company contested a lower court\u2019s decision requiring it to compensate a consumer for improper debt collection, arguing that AI-related inconsistencies in automated systems should not be equated with bad faith. The court upheld the ruling, noting that it was prevented from re-analyzing the facts.",
    "excerpt":"-",
    "link":"https:\/\/scon.stj.jus.br\/SCON\/pesquisar.jsp?pesquisaAmigavel=+AREsp+1786691&b=DTXT&numDocsPagina=10&i=1&O=&ref=&processo=&ementa=&nota=&filtroPorNota=&orgao=&relator=&uf=&classe=&data=&dtpb=&dtde=&tp=T&operador=e&livre=AREsp+1786691",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Superior Court of Justice",
    "caseName":"RE nos EDcl no AREsp 2585475",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"A party argued that a court decision was improperly influenced by artificial intelligence and lacked sufficient judicial reasoning, challenging it based on constitutional due process guarantees. The Superior Court of Justice denied the appeal, noting that it did not specify in which points the decision was incomplete. ",
    "excerpt":"-",
    "link":"https:\/\/processo.stj.jus.br\/processo\/pesquisa\/?num_registro=202400708277",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Superior Court of Justice",
    "caseName":"Pet 16878",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"A lawyer requested extensive technical and transparency-related information about the AI systems used in judicial decision-making, arguing that it was necessary for legal defense and an upcoming appeal. The request was denied on the grounds that the petitioner failed to justify its relevance to the case. The court also noted that such information should be sought through administrative channels.",
    "excerpt":"-",
    "link":"https:\/\/processo.stj.jus.br\/processo\/pesquisa\/?num_registro=202402131136",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Superior Court of Justice",
    "caseName":"EDcl no AREsp 2495123",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"A litigant argued that AI-generated judicial decisions were leading to \u201cprefabricated\u201d rulings that disregarded case-specific details, challenging the rejection of their appeal as improperly reasoned. The court dismissed the motion, stating that the prior ruling was properly reasoned and that judges are not required to address every argument individually if the decision is sufficiently justified. The court warned the litigant that further similar filings would be considered frivolous and subject to financial penalties.",
    "excerpt":"-",
    "link":"https:\/\/processo.stj.jus.br\/processo\/pesquisa\/?num_registro=202303476857",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Superior Court of Justice",
    "caseName":"EDcl no AREsp 2221189",
    "year":2022,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"Banco do Brasil challenged a court decision, arguing that the use of artificial intelligence in filtering appeals led to an erroneous dismissal of its claims. The court rejected the appeal, affirming that the prior decision properly addressed the relevant legal issues and that judges are not required to individually refute every argument. It warned the bank against repetitive filings, imposing a potential fine for further frivolous motions.",
    "excerpt":"-",
    "link":"https:\/\/processo.stj.jus.br\/processo\/pesquisa\/?num_registro=202203109187",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Court of Justice of the Federal District",
    "caseName":"Ac\u00f3rd\u00e3o 1190541, 0703585-15.2017.8.07.0014",
    "year":2019,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"A consumer sought double repayment for an already settled debt, arguing that the bank engaged in bad faith by charging an undue amount.\nThe court ruled that excessive but unintentional charges do not justify double repayment under Article 940 of the Civil Code, as bad faith must be proven. It emphasized that errors from AI-based or automated systems do not equate to fraudulent intent.",
    "excerpt":"\"5. H\u00e1 que se repensar conceitos que n\u00e3o poder\u00e3o receber dos juristas as antigas solu\u00e7\u00f5es impostas pelo Direito Romano ao vendedor de balc\u00e3o, com caderneta de apontamentos pessoais dos seus fregueses, contempor\u00e2nea da 1\u00aa Revolu\u00e7\u00e3o Industrial, a era da m\u00e1quina movida a vapor.\n6. As inconsist\u00eancias do emprego de intelig\u00eancia artificial e da informatiza\u00e7\u00e3o em geral n\u00e3o podem ser punidas com o r\u00f3tulo da m\u00e1-f\u00e9, atributo exclusivamente humano, \u00ednsito a quem anota, naquela mencionada caderneta, uma compra que n\u00e3o foi feita ou uma d\u00edvida que j\u00e1 foi paga, para dobrar, fraudulentamente, o lucro no fim do m\u00eas. \u201c",
    "link":"https:\/\/jurisdf.tjdft.jus.br\/acordaos\/2fabf9b2-4194-4e96-87ee-98eb95159441",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Court of Justice of the Federal District",
    "caseName":"Ac\u00f3rd\u00e3o 1226451, 0707352-84.2019.8.07.0016",
    "year":2020,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"A consumer sought double repayment for an already settled debt, arguing that the bank engaged in bad faith by charging an undue amount.\nThe court ruled that excessive but unintentional charges do not justify double repayment under Article 940 of the Civil Code, as bad faith must be proven. It emphasized that errors from AI-based or automated systems do not equate to fraudulent intent.",
    "excerpt":"\"5. H\u00e1 que se repensar conceitos que n\u00e3o poder\u00e3o receber dos juristas as antigas solu\u00e7\u00f5es impostas pelo Direito Romano ao vendedor de balc\u00e3o, com caderneta de apontamentos pessoais dos seus fregueses, contempor\u00e2nea da 1\u00aa Revolu\u00e7\u00e3o Industrial, a era da m\u00e1quina movida a vapor.\n6. As inconsist\u00eancias do emprego de intelig\u00eancia artificial e da informatiza\u00e7\u00e3o em geral n\u00e3o podem ser punidas com o r\u00f3tulo da m\u00e1-f\u00e9, atributo exclusivamente humano, \u00ednsito a quem anota, naquela mencionada caderneta, uma compra que n\u00e3o foi feita ou uma d\u00edvida que j\u00e1 foi paga, para dobrar, fraudulentamente, o lucro no fim do m\u00eas. \u201c",
    "link":"https:\/\/jurisdf.tjdft.jus.br\/acordaos\/b4a483a7-c7d7-4577-bc1e-d56e7f73a4ed",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Court of Justice of the Federal District",
    "caseName":"Ac\u00f3rd\u00e3o 1244221, 0717557-51.2018.8.07.0003",
    "year":2020,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"A consumer sought double repayment for an already settled debt, arguing that the bank engaged in bad faith by charging an undue amount.\nThe court ruled that excessive but unintentional charges do not justify double repayment under Article 940 of the Civil Code, as bad faith must be proven. It emphasized that errors from AI-based or automated systems do not equate to fraudulent intent.",
    "excerpt":"\"5. H\u00e1 que se repensar conceitos que n\u00e3o poder\u00e3o receber dos juristas as antigas solu\u00e7\u00f5es impostas pelo Direito Romano ao vendedor de balc\u00e3o, com caderneta de apontamentos pessoais dos seus fregueses, contempor\u00e2nea da 1\u00aa Revolu\u00e7\u00e3o Industrial, a era da m\u00e1quina movida a vapor.\n6. As inconsist\u00eancias do emprego de intelig\u00eancia artificial e da informatiza\u00e7\u00e3o em geral n\u00e3o podem ser punidas com o r\u00f3tulo da m\u00e1-f\u00e9, atributo exclusivamente humano, \u00ednsito a quem anota, naquela mencionada caderneta, uma compra que n\u00e3o foi feita ou uma d\u00edvida que j\u00e1 foi paga, para dobrar, fraudulentamente, o lucro no fim do m\u00eas. \u201c",
    "link":"https:\/\/jurisdf.tjdft.jus.br\/acordaos\/73cd07f6-f89e-428c-922f-a3eb7217f6f0",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Court of Justice of Paran\u00e1",
    "caseName":"0008107-93.2024.8.16.0188",
    "year":2025,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The court identified a grave misuse of AI-generated references, which falsified legal precedents. It sanctioned the party for bad-faith litigation.",
    "excerpt":"-",
    "link":"https:\/\/portal.tjpr.jus.br\/jurisprudencia\/j\/4100000029500681\/Ac\u00f3rd\u00e3o-0008107-93.2024.8.16.0188",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Court of Justice of Paran\u00e1",
    "caseName":"0011205-80.2015.8.16.0001",
    "year":2021,
    "issue":null,
    "finalDecision":"Yes",
    "summary":"A consumer sought to obtain a five-year record of calls made from their prepaid phone line, but the court dismissed the case for lack of interest in acting, as the consumer failed to prove a valid prior request to the company. The court upheld the dismissal, ruling that a request made via an AI-powered virtual assistant (chatbot) does not constitute a formal notification of resistance by the company. ",
    "excerpt":"\"Conforme se depreende do documento juntado pelo autor (mov.\n1.10), a pretens\u00e3o foi endere\u00e7ada ao assistente virtual da companhia telef\u00f4nica e,\ncomo tal, se presta \u00e0 satisfa\u00e7\u00e3o de quest\u00f5es simples e r\u00e1pidas \u2013 n\u00e3o para tratar\nespecificamente de apresenta\u00e7\u00e3o de relat\u00f3rio de liga\u00e7\u00f5es, ainda mais\nconsiderando pelo per\u00edodo indicado de 5 (cinco) anos\n\u2013, de modo que a\nresposta \u00e9 fornecida de acordo com a disponibilidade da informa\u00e7\u00e3o mais relevante\npara a necessidade do consumidor. Ali\u00e1s, ao que tudo indica, sequer o \u201crob\u00f4\u201d tinha\no conhecimento, em seu sistema eletr\u00f4nico, do que exatamente pretendia a parte\nautora, n\u00e3o se cogitando de pretens\u00e3o resistida quando a pessoa jur\u00eddica, a bem da\nverdade, n\u00e3o foi instada.\u201d",
    "link":"https:\/\/portal.tjpr.jus.br\/jurisprudencia\/j\/4100000008006841\/Ac\u00f3rd\u00e3o-0011205-80.2015.8.16.0001",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"Court of Justice of Paran\u00e1",
    "caseName":"0000244-62.2021.8.16.0036",
    "year":2021,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"A consumer sued commercial companies after being improperly charged for a debt that had already been paid. The charge was made via an AI-powered chatbot on WhatsApp, leading the consumer to seek both a declaration of debt inexistence and moral damages.\nThe court denied moral damages, ruling that an automated debt collection message does not constitute a serious violation of personality rights. The ruling emphasized that mere inconvenience caused by AI-driven interactions does not justify compensation.",
    "excerpt":"\"Alega o recorrente, ainda, que n\u00e3o h\u00e1 que se falar em indeniza\u00e7\u00e3o por danos\nmorais, por considerar se tratar de mero dissabor, uma vez que n\u00e3o se vislumbra qualquer\ngrave les\u00e3o ao direito da parte autora, por ter respondido perguntas de intelig\u00eancia\nartificial\u201d",
    "link":"https:\/\/portal.tjpr.jus.br\/jurisprudencia\/j\/2100000018177841\/Ac\u00f3rd\u00e3o-0000244-62.2021.8.16.0036",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSC",
    "caseName":"Habeas Corpus Criminal n. 5001175-27.2025.8.24.0000",
    "year":2025,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"A defendant sought to revoke urgent protective measures imposed in a domestic violence case, filing a habeas corpus petition that appeared to have been generated by artificial intelligence, citing nonexistent case law to mislead the court. The court warned the defense attorney for submitting AI-generated arguments with fabricated precedents, characterizing the act as bad faith litigation and disrespect to the judiciary.",
    "excerpt":"-",
    "link":"https:\/\/busca.tjsc.jus.br\/jurisprudencia\/buscaForm.do#",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSC",
    "caseName":"Agravo de Instrumento n. 5042849-19.2024.8.24.0000",
    "year":2025,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"A public civil action sought to suspend Meta\u2019s collection of user data from Facebook, Instagram, and WhatsApp for training its generative AI model, Llama 3. The court denied the injunction, as Brazil\u2019s Data Protection Authority (ANPD) had already ordered Meta to suspend its new privacy policy. The plaintiff appealed, arguing that Meta had not followed the legal bases required under the LGPD.\nThe appellate court partially dismissed the appeal, finding that many of the plaintiff\u2019s arguments were new and not raised in the first instance, making them inadmissible. On the merits, the court upheld the trial decision, ruling that the administrative measure by the ANPD already achieved the intended outcome. The fine imposed (R$ 50,000 per day) was deemed sufficient, and further judicial intervention was unnecessary.",
    "excerpt":"-",
    "link":"https:\/\/eprocwebcon.tjsc.jus.br\/consulta2g\/externo_controlador.php?acao=processo_seleciona_publica&acao_origem=processo_consulta_publica&acao_retorno=processo_consulta_publica&num_processo=50428491920248240000&num_chave=&num_chave_documento=&hash=56d95645b164ce427567c08931572739",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSC",
    "caseName":"5038933-16.2020.8.24.0000",
    "year":2021,
    "issue":"Public procurement",
    "finalDecision":"Yes",
    "summary":"A company was disqualified from a public tender for landscaping and maintenance services in state schools due to a lack of technical capacity documentation. It alleged a competing bidder had improperly used AI to place bids, raising concerns about fairness. The AI-related allegations were not considered, as they were not part of the initial administrative dispute",
    "excerpt":"-",
    "link":"https:\/\/eprocwebcon.tjsc.jus.br\/consulta2g\/externo_controlador.php?acao=processo_seleciona_publica&acao_origem=processo_consulta_publica&acao_retorno=processo_consulta_publica&num_processo=50389331620208240000&num_chave=&num_chave_documento=&hash=fec1969fe27b4d20c54e1f4c5a2bbabf",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSP",
    "caseName":"Agravo de Instrumento 2284835-63.2024.8.26.0000",
    "year":2025,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"In a case involving a request for private sale of a seized asset, the court found that the petition included fabricated case law citations, likely generated by artificial intelligence (AI) without human verification. The court dismissed the appeal and referred the matter to the Tribunal\u2019s Presidency for investigation into the improper use of AI in legal filings.",
    "excerpt":"-",
    "link":"https:\/\/esaj.tjsp.jus.br\/cjsg\/getArquivo.do?cdAcordao=18785118&cdForo=0",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSP",
    "caseName":"Apela\u00e7\u00e3o C\u00edvel 1009223-69.2024.8.26.0405",
    "year":2025,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The appellant argued that the trial court\u2019s decision was null because it was allegedly generated by artificial intelligence. The court rejected the claim, stating that there was no evidence that AI had produced the judgment. It emphasized that while AI tools assist judicial activities, they do not replace human judgment. The court also noted that the appellant\u2019s reliance on ChatGPT to assess the judgment\u2019s authenticity was insufficient as evidence. ",
    "excerpt":"\"Em suma, a apelante aduz que, em raz\u00e3o da boa formula\u00e7\u00e3o e\nfundamenta\u00e7\u00e3o do julgado, este provavelmente n\u00e3o teria sido elaborado por trabalho\nhumano, mas sim por uma m\u00e1quina. Como anteriormente explanado, a acusa\u00e7\u00e3o que\na autora sustenta \u00e9 muito grave, devendo ser pautada em ind\u00edcios reais de uso\nanti\u00e9tico da tecnologia. Exemplos disso seria a prola\u00e7\u00e3o de senten\u00e7a teratol\u00f3gica ou a\nindica\u00e7\u00e3o de jurisprud\u00eancia inexistente (comumente inventada pelas ferramentas\ndigitais).\u201d",
    "link":"https:\/\/esaj.tjsp.jus.br\/cjsg\/getArquivo.do?cdAcordao=18767159&cdForo=0",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSP",
    "caseName":"Apela\u00e7\u00e3o C\u00edvel 1119021-41.2023.8.26.0100",
    "year":2024,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":" The plaintiff, a voice actor, sued a shopping mall association for using his voice without authorization in a commercial, alleging AI-generated voice cloning. The defendant claimed it used an AI-generated synthetic voice rather than the plaintiff\u2019s actual voice. The court annulled the initial judgment, which had dismissed the claim, ruling that the case required further investigation. It emphasized that AI-generated content can still infringe personality rights, highlighting concerns over AI\u2019s potential to mimic real voices and the risks of unauthorized use.",
    "excerpt":"\"Em suma, v\u00ea-se que o uso de Intelig\u00eancia Artificial, por si s\u00f3,\nbem pelo contr\u00e1rio, agrava o risco de utiliza\u00e7\u00e3o indevida\nde direitos de terceiros.\nA recorr\u00eancia das a\u00e7\u00f5es que apenas comprova que a IA\nesteja, de forma recorrente, gerando voz similar \u00e0 do autor, n\u00e3o afastando\na probabilidade de se tratar rigorosamente da mesma voz.\nN\u00e3o se pode excluir, portanto, a possibilidade de que, ao\nrealizar o uso de voz gerada por um software, tenha a r\u00e9 infringido o dever\nde cuidado quanto \u00e0 utiliza\u00e7\u00e3o da PIA, sendo respons\u00e1vel por este\nmotivo, pela repara\u00e7\u00e3o dos danos gerados.\u201d",
    "link":"https:\/\/esaj.tjsp.jus.br\/cjsg\/getArquivo.do?cdAcordao=18522575&cdForo=0",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSP",
    "caseName":"Apela\u00e7\u00e3o C\u00edvel 1009442-04.2022.8.26.0001",
    "year":2024,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"A company sued Serasa Experian, alleging that its credit score was unjustly low despite having no outstanding debts, and demanded that the score be increased. The court ruled that the credit score calculation, performed by artificial intelligence, follows statistical models that cannot be arbitrarily altered. It emphasized that simply clearing debts does not automatically increase the score and that a long-term record of financial responsibility is required. The AI-driven process was deemed lawful, and no misuse of data was found, leading to the rejection of the claims for score adjustment and moral damages.",
    "excerpt":"\"Ou seja, o c\u00e1lculo \u00e9 feito por uma intelig\u00eancia artificial, n\u00e3o\nsendo poss\u00edvel alterar os par\u00e2metros para eleva\u00e7\u00e3o da pontua\u00e7\u00e3o a bel\nprazer da parte ou de qualquer outra pessoa.\nPara que o score aumente, a autora deve cumprir os requisitos\nindicados e continuar sendo boa pagadora por um longo per\u00edodo. O\npercentual n\u00e3o tem como ser elevado simplesmente porque houve a\nquita\u00e7\u00e3o de todas as d\u00edvidas em um curto per\u00edodo de 6 meses, como\ndemonstrado por documentos nos autos.\u201d",
    "link":"https:\/\/esaj.tjsp.jus.br\/cjsg\/getArquivo.do?cdAcordao=18091221&cdForo=0",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSP",
    "caseName":"Apela\u00e7\u00e3o C\u00edvel 1028716-35.2023.8.26.0577",
    "year":2024,
    "issue":null,
    "finalDecision":null,
    "summary":"The plaintiff sued two online legal research platforms, Jusbrasil and Escavador, seeking the removal of publicly available information about his labor lawsuits, arguing that the disclosure harmed his employment prospects. The defendants use artificial intelligence to extract case data from official gazettes. The court ruled that the defendants\u2019 AI-driven data extraction did not constitute an unlawful act, as the information was publicly accessible by constitutional mandate",
    "excerpt":"\"Pois bem. As apeladas operam intelig\u00eancia\nartificial para extrair de di\u00e1rios oficiais informa\u00e7\u00f5es relativas a\nprocessos, que, por for\u00e7a de expressa previs\u00e3o constitucional, s\u00e3o, em regra, p\u00fablicas.3\nNesse sentido, esta Corte Bandeirante\nentende que a mera exibi\u00e7\u00e3o de dados processuais p\u00fablicos em\nbuscadores n\u00e3o caracteriza ato il\u00edcito (\u2026)\u201d",
    "link":"https:\/\/esaj.tjsp.jus.br\/cjsg\/getArquivo.do?cdAcordao=18271367&cdForo=0",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSP",
    "caseName":"Apela\u00e7\u00e3o C\u00edvel 1070390-71.2020.8.26.0100",
    "year":2021,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The case involves the unauthorized creation of pages using the appellant hospital\u2019s name and logo by Facebook\u2019s AI-generated system, without consent. The court ruled in favor of the hospital, ordering Facebook to remove the pages within 10 days, under penalty of a daily fine, recognizing that the AI-generated content posed reputational risks. ",
    "excerpt":"\"Com efeito, em que pese o entendimento adotado\npelo magistrado a quo, vislumbro o uso desautorizado de marca,\nnome e logotipo da empresa apelante, em p\u00e1ginas criadas\nautomaticamente pela intelig\u00eancia artificial da plataforma apelada,\nsem consentimento da empresa.\nNestes termos, a situa\u00e7\u00e3o descrita evidencia o\npotencial danoso \u00e0 imagem da recorrente, tendo em vista que n\u00e3o\npoder\u00e1 controlar o teor das postagens realizadas em tais p\u00e1ginas,\nque, repito, utilizam do nome e da imagem da marca da empresa em\nquest\u00e3o.\u201d",
    "link":"https:\/\/esaj.tjsp.jus.br\/cjsg\/getArquivo.do?cdAcordao=15252180&cdForo=0",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"Brazil",
    "court":"TJSP",
    "caseName":"Embargos de Declara\u00e7\u00e3o 9066697-35.2009.8.26.0000",
    "year":2009,
    "issue":null,
    "finalDecision":null,
    "summary":"The S\u00e3o Paulo Court of Justice reviewed a motion for clarification in an environmental case concerning the burning of sugarcane fields. The appellant argued that the judgment was incomplete for failing to address specific legal points and evidence.\n\nThe court rejected the motion, emphasizing that judicial decisions are unique, personal acts of reasoning that cannot be reduced to automated outputs. The ruling explicitly rejected the notion that artificial intelligence could replace judicial decision-making, asserting that fundamental legal reasoning requires human judgment.",
    "excerpt":"\"Anote-se, inicialmente, que um ac\u00f3rd\u00e3o \u00e9 uma\npe\u00e7a t\u00e9cnica elaborada pelo julgador com o prop\u00f3sito de\nresponder a uma demanda concreta. Sua elabora\u00e7\u00e3o\nainda reside na personalidade do decideur, que \u00e9 ser\nhumano e tem seu estilo, sua forma\u00e7\u00e3o cultural, sua\nexperi\u00eancia da vida e outros elementos que tornam cada\ndecis\u00e3o um ato individual, peculiar e irrepet\u00edvel. N\u00e3o fora\nassim e se justificaria a ado\u00e7\u00e3o de outra metodologia de\njulgamento, em que as m\u00e1quinas substituiriam com\nin\u00fameras vantagens o ser humano incumbido de julgar.\u201d",
    "link":"https:\/\/esaj.tjsp.jus.br\/cjsg\/getArquivo.do?cdAcordao=4098906&cdForo=0",
    "lat":-14.235,
    "lng":-51.9253
  },
  {
    "region":"India",
    "court":"Delhi High Court",
    "caseName":"ANI Media PVT LTD v. OpenAI Inc. & ANR - CS(COMM) 1028\/2024",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainant alleges OpenAI used ANI\u2019s copyrighted news content without authorization to train its AI model, ChatGPT, violating its copyright, and is seeking \u20b92 crore in damages and an injunction to prevent further use of its content",
    "excerpt":"-",
    "link":"https:\/\/dhcappl.nic.in\/dhcorderportal\/",
    "lat":20.5937,
    "lng":78.9629
  },
  {
    "region":"India",
    "court":"Delhi High Court",
    "caseName":"Anil Kapoor v. Simply Life India - CS(COMM) 652\/2023",
    "year":2023,
    "issue":"Civil liability",
    "finalDecision":"No",
    "summary":"The complainant alleges that various entities, including Simply Life India, misused his image, voice, name, and persona without consent for commercial gain through unauthorized endorsements and AI-generated deepfakes.",
    "excerpt":"- ",
    "link":"https:\/\/dhcappl.nic.in\/dhcorderportal\/",
    "lat":20.5937,
    "lng":78.9629
  },
  {
    "region":"India",
    "court":"High Court of Manipur",
    "caseName":"Md. Zakir Hussain vs. State of Manipur - WP(C) No. 70 of 2023",
    "year":2023,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The complainant alleges that he was unlawfully disengaged from the Village Defence Force (VDF) without proper inquiry, violating principles of natural justice, leading the Manipur High Court to set aside the disengagement order, reinstate him with back honorarium and allowances, and notably utilize ChatGPT to aid in understanding the VDF\u2019s service conditions",
    "excerpt":"\"In the circumstances, this\n\nCourt is compelled to do extra research through Google and ChatGTP 3.5.\n\nThe following important information regarding the VDF is collected.\u201d",
    "link":"https:\/\/indiankanoon.org\/doc\/36204805\/",
    "lat":20.5937,
    "lng":78.9629
  },
  {
    "region":"India",
    "court":"High Court of Judicature at Madras",
    "caseName":"All India Gaming Federation vs The State of Tamil Nadu",
    "year":2023,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The court struck down Tamil Nadu\u2019s law banning online rummy and poker, ruling it unconstitutional, as it found no evidence that AI or bots manipulated game outcomes and rejected the claim that online versions differed fundamentally from offline games.",
    "excerpt":"\"The contention of the State that the petitioners may use bots __________ https:\/\/www.mhc.tn.gov.in\/judis W.P.Nos.13203 of 2023 etc would be without any basis. There is nothing on record to substantiate the contention of the State that the dealer (software) knows all the cards all the time, including which card is going to be dealt with, or that the dealer (software) knows all the cards in the hands of each player or that the dealer (software) can change the unopened cards. The said propositions, on behalf of the State, are merely on surmise. We can understand that the game is played online and the State could not gather authentic evidences about bots being used or that the software knows all the cards in the hands of each player, so also the unopened cards or the software could change the unopened cards. In the absence thereof, it will be too far fetched only on the basis of the assumptions by the State to conclude that the game of rummy, played online, partakes the character of game of chance and is distinctly different than the one played offline.\u201d",
    "link":"https:\/\/indiankanoon.org\/doc\/117010180\/",
    "lat":20.5937,
    "lng":78.9629
  },
  {
    "region":"India",
    "court":"Delhi High Court",
    "caseName":"Mrs X vs Union of India And Ors ",
    "year":2023,
    "issue":"Platforms",
    "finalDecision":"Yes",
    "summary":"The Delhi High Court ruled on a petition seeking the removal of non-consensual intimate images (NCII) and enforcement of intermediary liability. It rejected the argument that search engines merely index content, emphasizing that they actively construct knowledge by determining accessibility, ranking, and visibility of information. The court held that search engines are responsible for de-indexing unlawful content upon notification and must use existing AI tools, like those deployed for CSAM and copyright enforcement, to proactively prevent NCII dissemination.",
    "excerpt":"\"What can be culled out from the aforesaid legal literature is that a search engine plays an important role in the dissemination of content and its powers in connecting the said content to the consumers is undeniable. When viewed in this light, it is unfathomable as to how a search engine can feign helplessness when it comes to removal of or disabling access to links which prima facie contain content that is illegal as declared by the Court. There resides a social obligation in these intermediaries to be proactive (\u2026)\u201d",
    "link":"https:\/\/indiankanoon.org\/doc\/105980506\/",
    "lat":20.5937,
    "lng":78.9629
  },
  {
    "region":"India",
    "court":"Bombay High Court",
    "caseName":"Arijit Singh v Coddle Ventures Llp",
    "year":2024,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"Arijit Singh filed a suit against AI platforms, e-commerce websites, and event organizers for unauthorized commercial use of his name, voice, image, and likeness, including AI-generated voice cloning and merchandise sales. The court found that such activities violate his personality and publicity rights, as well as his moral rights under the Copyright Act, since they exploit his identity without consent for profit. An interim injunction was granted, ordering the removal of infringing content and restricting further unauthorized use of his persona.",
    "excerpt":"\"The technological tools that are now freely available make it possible for any illegal and unauthorised user to use, produce or imitate any celebrity's persona, by using any tools including Artificial Intelligence. The celebrity enjoys the right of privacy, and does not wish that his or her image, voice, likeness is portrayed in a dark or grim manner, as portrayed on the porn websites. Moreover, the Plaintiff's image is being morphed along with other 6-ial-23560-2024.doc actresses in videos and images generated in a manner, which are not merely offensive or derogatory to the Plaintiff, but also to such other third-party celebrities and actresses.\n43. The Court cannot turn a blind eye to such misuse of a personality's name and other elements of his persona. Dilution, tarnishment, blurring are all actionable torts which the Plaintiff would have to be protected against.\n44. Even the domain names that have been registered are just being squatted upon, and there can be no reason why the same could be allowed to be squatted upon. The creation of ringtones and GIF images for commercial gains would also be a complete misuse of Plaintiff's rights.\n45. Under these circumstances, this Court has no doubt in holding that the Plaintiff's name, likeness, image, persona, etc., deserves to be protected, not only for Plaintiff's own sake but also for the sake of his family and friends who would not like to see his image, name and other elements being misused, especially for such tarnishing and negative use.\n46. The present case shows how elements of intellectual property that protect the attributes of an individual, in fact have other dimensions including rights protected by the Constitution of India\u201d",
    "link":"https:\/\/indiankanoon.org\/doc\/103091928\/",
    "lat":20.5937,
    "lng":78.9629
  },
  {
    "region":"South Korea",
    "court":"South Korea Personal Information Protection Commission",
    "caseName":"Temporary suspension of the DeepSeek Application Service",
    "year":2025,
    "issue":"Privacy",
    "finalDecision":"Yes",
    "summary":"South Korea\u2019s Personal Information Protection Commission recommended that DeepSeek temporarily suspend its AI chatbot service due to concerns over third-party data transfers and insufficient transparency in its privacy policy.",
    "excerpt":"\"Following the launch of DeepSeek's R1 LLM AI chatbot, the Personal Information Protection Commission (PIPC) sent an inquiry requesting details on what personal data is collected, the legal basis for its processing, and whether user data is stored in China. The PIPC also initiated an analysis on how this chatbot functions.\n\u00a0\nAmid media outlets\u2019 voicing concerns over this AI chatbot service, the PIPC\u2019s analysis found out traffic generated by third-party data transfers and insufficient transparency in DeepSeek\u2019s privacy policy.\n\u00a0\nDeepSeek appointed a domestic agent on February 10. The company has committed to actively cooperating with the PIPC, saying it failed to take into account meeting the legal requirements pursuant to the PIPA when launching its service globally.\n\u00a0\nTo mitigate further concerns, the PIPC recommended that DeepSeek temporarily suspend its chatbot service until necessary updates are implemented. In agreement with this recommendation, DeepSeek removed its application from Apple\u2019s App Store and Google Play on February 15, 2025.\n\n\n\u201c",
    "link":"https:\/\/www.pipc.go.kr\/eng\/user\/ltn\/new\/noticeDetail.do?bbsId=BBSMSTR_000000000001&nttId=2784",
    "lat":35.9078,
    "lng":127.7669
  },
  {
    "region":"South Korea",
    "court":"Seoul Central District",
    "caseName":"KBS, MBC and SBS v. Naver",
    "year":2025,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainants allege their content were used without their consent to train Naver\u2019s AI models, infringing on their copyright.",
    "excerpt":"-",
    "link":"https:\/\/www.koreatimes.co.kr\/www\/nation\/2025\/02\/113_390373.html",
    "lat":35.9078,
    "lng":127.7669
  },
  {
    "region":"Japan",
    "court":"Intellectual Property High Court of Japan",
    "caseName":"Case No. 2024 (Gyo-ko) No. 10006",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"Japan\u2019s Intellectual Property High Court ruled on January 30, 2025, that AI cannot be listed as an inventor under the Patent Act, affirming the decision against an application naming the AI system DABUS as the inventor. The court reasoned that patent rights are granted only to natural persons and that the current legal framework does not provide a mechanism for recognizing AI-generated inventions. It emphasized that changes in AI inventorship must come from legislative action, not judicial reinterpretation.",
    "excerpt":"-",
    "link":"https:\/\/www.courts.go.jp\/app\/hanrei_jp\/detail7?id=93757",
    "lat":36.2048,
    "lng":138.2529
  },
  {
    "region":"Canada",
    "court":"Canadian Federal Court",
    "caseName":"Espinosa Cotacachi v. Canada",
    "year":2024,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The Canadian Federal Court dismissed Maria Alexandra Espinosa Cotacachi\u2019s judicial review application, affirming the immigration officer\u2019s decision to deny her work permit due to concerns she would not leave Canada at the end of her authorized stay. Cotacachi argued that the officer unfairly relied on AI, specifically the Chinook tool, to generate a quick rejection without properly assessing her case. However, the court ruled that there was no evidence that the use of Chinook led to procedural unfairness, as the decision was made by a human officer and aligned with immigration regulations.",
    "excerpt":"\"[27] In Haghshenas v Canada (Citizenship and Immigration), 2023 FC 464, Justice Brown addressed similar arguments as advanced by Ms. Cotacachi\u2014that there is no way to determine if the decision was made by the Officer or the Chinook software. Justice Brown noted at para 24:\n(\u2026) [28] Similarly, in Raja v Canada (Minister of Citizenship and Immigration), 2023 FC 719 at paras 28\u201330, Justice Ahmed explained why the use of the Chinook tool to extract information from applications does not necessarily constitute a breach of procedural fairness:\n(\u2026) [29] The jurisprudence is clear that the issue is whether the decision is reasonable and\/or procedurally fair based on the record before the Court and the principles established in the jurisprudence regarding reasonableness review and the duty of procedural fairness owed in the circumstances.\n\n[30] In the present case, even if the Officer was aided by the Chinook tool, the Officer\u2019s reasons for refusing Ms. Cotacachi\u2019s work permit reflect the facts and the law. The issue for the Court is whether the Officer\u2019s decision is reasonable in that the decision is based on a rational chain of analysis and permits the Court to understand why the permit was refused.\u201d\n\n",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2024\/2024fc2081\/2024fc2081.html?resultId=e6b37be326cd4a75833909d13ecd4f29&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Canadian Federal Court",
    "caseName":"Haghshenas v. Canada",
    "year":2023,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainant alleges the immigration officer unfairly relied on AI, specifically the Chinook tool, to generate a quick rejection without properly assessing their case. However, the court ruled that there was no evidence that the use of Chinook led to procedural unfairness, as the decision was made by a human officer and aligned with immigration regulations.",
    "excerpt":"\"[24] As to artificial intelligence, the Applicant submits the Decision is based on artificial intelligence generated by Microsoft in the form of \u201c\u201cChinook\u201d\u201d software. However, the evidence is that the Decision was made by a Visa Officer and not by software. I agree the Decision had input assembled by artificial intelligence, but it seems to me the Court on judicial review is to look at the record and the Decision and determine its reasonableness in accordance with Vavilov. Whether a decision is reasonable or unreasonable will determine if it is upheld or set aside, whether or not artificial intelligence was used. To hold otherwise would elevate process over substance.\u201d (\u2026) [28] Regarding the use of the \u201cChinook\u201d software, the Applicant suggests that there are questions about its reliability and efficacy. In this way, the Applicant suggests that a decision rendered using Chinook cannot be termed reasonable until it is elaborated to all stakeholders how machine learning has replaced human input and how it affects application outcomes. I have already dealt with this argument under procedural fairness, and found the use of artificial intelligence is irrelevant given that (a) an Officer made the Decision in question, and that (b) judicial review deals with the procedural fairness and or reasonableness of the Decision as required by Vavilov.\u201d",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2023\/2023fc464\/2023fc464.html?resultId=d841c57b6a744a8394ba90a84d5850fe&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"British Columbia Civil Resolution Tribunal",
    "caseName":"Yang v. Gibbs (dba D & G Cedar Fencing)",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The British Columbia Civil Resolution Tribunal dismissed claims that the defendant was unjustly enriched by a duplicate $4,300 e-transfer payment. The applicants attempted to use ChatGPT to analyze email metadata and argue that Gibbs had received the e-transfer, but the tribunal found AI-generated evidence unreliable. Citing recent court decisions warning against generative AI in legal disputes, the tribunal ruled that the applicants failed to prove their claim and dismissed the case.",
    "excerpt":"\"The BC Supreme Court recently discussed the risks of relying on generative artificial intelligence tools such as ChatGPT in a case in which ChatGPT generated references to non-existent court decisions.[2] The court noted that there is an express warning on the ChatGPT website that the output could be inaccurate, and that using ChatGPT is not a substitute for professional advice. Similarly, the Ontario Superior Court of Justice has noted the inherent risks of unregulated artificial intelligence tools and declined to rely on ChatGPT-generated research.[3] Based on these decisions and absent any evidence to the contrary, I find information provided by ChatGPT is unreliable at best. So, I give no weight to the applicants\u2019 ChatGPT evidence about the origin of the emails they received.\u201d",
    "link":"https:\/\/www.canlii.org\/en\/bc\/bccrt\/doc\/2024\/2024bccrt613\/2024bccrt613.html?resultId=a88b6d84829e4ff9a3aadce757a9bbbe&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Ontario Superior Court of Justice",
    "caseName":"Floryan v. Luke et al",
    "year":2023,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The Ontario Superior Court of Justice dismissed a civil lawsuit against the University of Western Ontario. The judge refused to consider AI-generated legal research (from ChatGPT), citing concerns over its reliability and the lack of a regulatory framework for AI in legal proceedings.",
    "excerpt":"\"a.\u00a0\u00a0 \u00a0\u00a0 I believe I am entitled to take a degree of judicial notice that the potential benefits and dangers of artificial intelligence, (underlying tools such as ChatGPT currently being made available to the public), currently are the subject of intense debate and scrutiny.\nb.\u00a0\u00a0 \u00a0\u00a0 As emphasized by Innovation, Science and Economic Development Canada, (a department of the Government of Canada previously known as Industry Canada), there currently is no regulatory framework in Canada specific to artificial intelligence.\u00a0 In particular, while some regulations in specific areas such as health and finance apply to certain uses of artificial intelligence, there currently is no generally applicable approach to ensure that artificial intelligence systems, (such as ChatGPT), address systemic risks during their design and development.\n(\u2026) g.\u00a0\u00a0 \u00a0\u00a0 It seems likely that legal systems and the teaching of law, like all other areas of human activity, will be affected by advancements in artificial intelligence.[33]\u00a0 Again, however, the benefits in that regard also come with inherent risks that currently are unregulated.\nh.\u00a0\u00a0 \u00a0\u00a0 Having regard to all of the above, while there may come a time when legal research and submissions generated by artificial intelligence will be recognized and accorded value in our courts, in my view that time has not yet arrived.\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/on\/onsc\/doc\/2023\/2023onsc5108\/2023onsc5108.html?resultId=37196fa1913f4e82ac7c8fe5145ab1b7&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Canadian Federal Court",
    "caseName":"Kumar v. Canada",
    "year":2024,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainant alleges the immigration officer unfairly relied on AI, specifically the Chinook tool, to generate a quick rejection without properly assessing their case. However, the court ruled that there was no evidence that the use of Chinook led to procedural unfairness, as the decision was made by a human officer and aligned with immigration regulations.",
    "excerpt":"-",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2024\/2024fc81\/2024fc81.html?resultId=2f4afaa9965a4499afbbb66263458923&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Information and Privacy Commissioner",
    "caseName":"Oder PO-4258, Appeal PA17-377-3, Ministry of Finance",
    "year":2022,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The adjudicator upheld the Ministry\u2019s refusal to disclose the records related to an AI project based on concerns over personal privacy and the government\u2019s economic interests. The records contained identifiable personal information, which could not be released without violating privacy protections. Additionally, disclosure was found to pose a risk to the government\u2019s financial position, potentially exposing funding negotiations and arrangements in a competitive field such as AI.",
    "excerpt":"\"The ministry submits that the disclosure of this information would have reasonably prejudiced on-going funding negotiations and would give competitors knowledge of the expenses, total cost, who to approach for investment, and how much investment can be expected on similar projects. The ministry submits that artificial intelligence is a highly competitive space and disclosure of the aggregate information about funding would unduly benefit competitors. (\u2026) After my review of the severed information in this group of records, I am satisfied that if the information is disclosed it could harm the named organization because it contains information concerning funding commitment details and disclosure would prejudice ongoing funding negotiations and\/or arrangements.\n\u00a0\n\n[118]\u00a0\u00a0 Despite the appellant\u2019s focus on the statements that the named organization is not competing with others in the industry, it is clear from reviewing the records that an organization is being established which requires ongoing funding. In my view, whether the organization is for, or not-for profit, in a highly competitive industry, I find that releasing the information could cause harm to the named organization. If this information is disclosed, it could clearly give others operating in this industry knowledge of which they would otherwise not have access to.\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/on\/onipc\/doc\/2022\/2022canlii38096\/2022canlii38096.html?resultId=5dd9ff6aee5843cfb76620337e8b03e8&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Canadian Federal Court",
    "caseName":"Luk v. Canada",
    "year":2024,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainant alleges the immigration officer unfairly relied on AI, specifically the Chinook tool, to generate a quick rejection without properly assessing their case. However, the court ruled that there was no evidence that the use of Chinook led to procedural unfairness, as the decision was made by a human officer and aligned with immigration regulations.",
    "excerpt":"\"[15] However, there is no evidence before the Court that artificial intelligence or an algorithm was used in rendering a decision on the Applicant\u2019s study permit application. The evidence before the Court is that the decision was made by an Officer and the Officer has provided reasons for their decision. Even if there was evidence that the decision had been made with the assistance of artificial intelligence or an algorithm, I am not satisfied that any such assistance, on its own, constitutes a breach of procedural fairness. Whether or not there has been a breach of procedural fairness will turn on the particular facts of the case, with reference to the procedure that was followed and the reasons for decision [see Haghshenas v Canada (Citizenship and Immigration), 2023 FC 464 at para 24]. When those factors are considered, I find that the Applicant has failed to demonstrate any breach of his procedural fairness rights.\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2024\/2024fc623\/2024fc623.html?resultId=b582724a730d4be7b8134216e1e18556&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Information and Privacy Commissioner",
    "caseName":"McMaster University (Re)",
    "year":2024,
    "issue":"Privacy",
    "finalDecision":"Yes",
    "summary":"The Information and Privacy Commissioner of Ontario (IPC) investigated McMaster University\u2019s use of Respondus Monitor, an AI-powered exam proctoring tool, due to concerns about biometric data collection and AI-driven decision-making. The report acknowledged that AI-based proctoring is a lawful activity but raised significant risks, including biased algorithmic flagging, potential misuse of student data for system improvement, and inadequate transparency regarding AI\u2019s role in academic integrity assessments. The IPC recommended that McMaster secure a commitment from Respondus to cease using student data for AI training without consent, conduct an algorithmic impact assessment, allow students to opt out of AI-based proctoring, and establish stronger oversight mechanisms to mitigate AI-related harms.",
    "excerpt":"\u00a0\n\n[143]\u00a0\u00a0 I recommend that McMaster carry out this necessary consultation step with representatives of its many diverse communities among its student population, particularly those from vulnerable or historically marginalized groups. These consultations should also include necessary experts in privacy and human rights, as well as technologists with relevant expertise to understand how the underlying algorithms work and their potential adverse or differential impacts on communities. (\u2026) [147]\u00a0\u00a0 It is not within my mandate to make findings or recommendations under human rights law. However, I encourage McMaster to make special arrangements not only for students requesting formal accommodation under a protected ground in human rights legislation, but also for any other students having serious apprehensions about the AI-enabled software and the significant impacts it can have on them and their personal information.\u00a0 Now that in-person invigilation is possible post COVID, all students should be provided with the general opportunity to opt out of online exam proctoring in favor of in-person exams depending on their personal circumstances and general level of comfort with this relatively invasive technology. (\u2026) [154]\u00a0\u00a0 However, given the fallibility of many AI tools, I recommend that McMaster provide a less formal means for students to challenge flags identified by the Respondus Monitor software, including their instructor\u2019s subsequent review, prior to invoking the formal academic integrity process that can be a very heavy one.\u00a0 Students should be provided with a meaningful opportunity to explain their situation. Where warranted, students should have the right to correct the information, and have the flag removed and any inferences or allegations based on the flag deleted from their student record. It is possible that McMaster already provides students with this informal opportunity to explain in practice. However, I recommend that its FAQs aimed at students provide explicitly for the possibility of this informal step and communicate it in a way that is understandable and actionable for its intended audience.\n(\u2026) [164]\u00a0\u00a0 On a broader level, McMaster remains accountable for the continued use of AI technologies throughout their lifecycle and across the variety of circumstances in which they are used. This includes continually evaluating the reliability of the tool. Even once a particularized agreement is in place for the use of Respondus Monitor, McMaster should continue to monitor for and alert Respondus to potential inappropriate uses or biased outcomes that may not have been disclosed as a potential limitation of their system. Conversely, McMaster should require Respondus to also monitor for, and inform the university of any weaknesses, biases or vulnerabilities it discovers about the program.\n\u00a0\n\n[165]\u00a0\u00a0 The adoption and application of the above guardrails would allow institutions such as McMaster to make responsible use of AI technologies to help carry out its lawfully authorized activities, while protecting against discriminatory impacts and promoting students\u2019 privacy. I acknowledge that several of McMaster's practices already demonstrate an understanding of the heightened need to protect the privacy rights of students when utilizing these types of technologies.\u00a0 However, to the extent there may be gaps, I recommend McMaster adopt the additional guardrails above and build them into its online proctoring program and\/or its contractual provisions with Respondus as appropriate. \u00a0\n\u201c\n\n",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2023\/2023fc166\/2023fc166.html?resultId=3df1d4286d2e4fdebd57efaa65ce3fdc&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Canadian Federal Court",
    "caseName":"James v. amazon.com.ca",
    "year":2023,
    "issue":"Privacy",
    "finalDecision":"Yes",
    "summary":"Tamara James sued Amazon under PIPEDA, claiming it unlawfully denied her access to her personal information due to an automated identity verification system. The court ruled that Amazon\u2019s refusal was justified because it could not verify her identity, a necessary safeguard under PIPEDA. It also rejected her AI-related arguments, stating there was no evidence that automated decision-making, rather than human review, caused the denial.",
    "excerpt":"\"[101] As for the suggestion made by the Applicant that artificial intelligence (and the use of automated decision-making systems) had something to do with the alleged violation of principles 6 and 9, it is difficult to see how it fits in this case within the confines of section 14 of PIPEDA. This suggestion was never part of the complaint made on the Report of Findings because it was not made. Moreover, in the case at hand, there is a complete lack of evidence; on the contrary, the evidence is that the Applicant was in contact with representatives of the Respondent, including a human Privacy Officer. The Applicant\u2019s suggestion is of no assistance in resolving the issue.\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2023\/2023fc166\/2023fc166.html?resultId=3df1d4286d2e4fdebd57efaa65ce3fdc&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Superior Court of Justice",
    "caseName":"Stephen Drummond v. The Cadillac Fairview Corporation Limited",
    "year":2018,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"Drummond won against Cadillac Fairview, with damages to be assessed. The court awarded him $18,500 in legal fees and upheld legal research costs, recognizing the growing role of AI in legal practice as recoverable.",
    "excerpt":"\"[10]\u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0 My own view is that the hours spent on legal research is recoverable both as a component of counsel fee and as a disbursement. The reality is that computer-assisted legal research is a necessity for the contemporary practice of law and computer assisted legal research is here to stay with further advances in artificial intelligence to be anticipated and to be encouraged. Properly done, computer assisted legal research provides a more comprehensive and more accurate answer to a legal question in shorter time than the conventional research methodologies, which, however, also remain useful and valuable. \u00a0Provided that the expenditure both in terms of lawyer time and computer time is reasonable and appropriate for the particular legal problem, I regard computer-assisted legal research as recoverable counsel fee item and also a recoverable disbursement.\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/on\/onsc\/doc\/2018\/2018onsc5350\/2018onsc5350.html?resultId=8c039f82a2ea4fd484f6ce24a0699426&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Federal Court",
    "caseName":"Khorasgani v. Canada",
    "year":2023,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainant alleges the immigration officer unfairly relied on AI, specifically the Chinook tool, to generate a quick rejection without properly assessing their case. However, the court ruled that there was no evidence that the use of Chinook led to procedural unfairness, as the decision was made by a human officer and aligned with immigration regulations.",
    "excerpt":"\"[6] I am not persuaded that the use of the Chinook 3+ tool in assessing an application, in itself, results in a breach of procedural fairness or unreasonableness: Haghshenas v Canada (Citizenship and Immigration), 2023 FC 464 at paras 24, 28; Ardestani v Canada (Citizenship and Immigration), 2023 FC 874 at para 34. Where the evidence shows that an officer made a decision, as opposed to artificial intelligence or AI, the focus is on the decision and the reasons where required or supplied, as the Supreme Court guides in Vavilov, above.\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2023\/2023fc1581\/2023fc1581.html?resultId=62e4305724214de880db4c8af3ce82ac&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Federal Court",
    "caseName":"Stross v. Tred Hunter Inc.",
    "year":2020,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"Trend Hunter used AI to analyze user interactions with content, including copyrighted photographs, as part of its market research. The court agreed that this constituted \u201cresearch\u201d under the Copyright Act\u2019s fair dealing provisions but found the use unfair due to the commercial nature of the research, the unauthorized reproduction of entire works, and the availability of alternatives. The court ruled that Trend Hunter failed to follow its own copyright policies, and despite the limited financial impact, the photographer was awarded damages.",
    "excerpt":"-",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2020\/2020fc201\/2020fc201.html?resultId=a24a76eed8fc4528bb7df78b0c5bfdd3&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Supreme Court of British Columbia",
    "caseName":"Zhang v. Chen",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":2024,
    "summary":"A lawyer cited fake cases in court filings that were generated by ChatGPT, leading to unnecessary costs for opposing counsel. The court found that while the use of AI-generated cases was a serious mistake, it was not an intentional deception or misconduct warranting special costs, but it justified making the lawyer personally liable for the extra legal expenses caused. ",
    "excerpt":"\"In my view, the circumstances do not justify the imposition of a special costs award against Ms.\u00a0Ke which include the significant negative publicity to which she has been subjected.\u00a0 I accept her evidence that she was na\u00efve about the risks of using ChatGPT and that she took steps to have the error corrected.\u00a0 Though her legal education is extensive, there is a significant difference between academics and lawyering.\u00a0 I do not find that she had the intention to deceive or misdirect.\u00a0 I accept the sincerity of Ms.\u00a0Ke\u2019s apology to counsel and the court.\u00a0 Her regret was clearly evident during her appearance and oral submissions in court.\n\n[33]\u00a0\u00a0 \u00a0\u00a0 It is unfortunate that Ms.\u00a0Ke was not aware of the various notices from the Law Society regarding the risks of generative AI.\u00a0\u00a0(\u2026) [43]\u00a0\u00a0 \u00a0\u00a0 Additional effort and expense were incurred because of Ms.\u00a0Ke\u2019s insertion of the fake cases.\u00a0 This additional effort and expense is to be borne personally by Ms.\u00a0Ke.\u00a0 As she herself notes, this was a \u201cserious mistake\u201d attributable solely to her own conduct.\u00a0 The costs are to be reviewed by the Registrar in accordance with the Schedule in Appendix\u00a0B of the Rules (including disbursements reasonably incurred).\u00a0 In terms of hearing day increments, the minimum is a one-half day under the rules.\u00a0 Costs are allowed for January\u00a015 (1\/2 day), 23 (1\/2 day), and 31 (1\/2 day), 2024, and February\u00a02, 2024 (1\/2 day)\u201d",
    "link":"https:\/\/www.canlii.org\/en\/bc\/bcsc\/doc\/2024\/2024bcsc285\/2024bcsc285.html?resultId=714356c68c744759935ead8c687bdc69&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Immigration and Refugee Board of Canada",
    "caseName":"X (RE), CanLII 152060 (CA IRB)",
    "year":2021,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The Canadian Refugee Protection Division (RPD) revoked the refugee status of two claimants after finding they had lied about their identities. The claimants argued the government used AI-based facial recognition (Clearview AI) to identify them, but the panel dismissed this, stating the software was banned in Canada and the government wasn\u2019t required to reveal its methods. ",
    "excerpt":"\"The panel has carefully considered the submissions of both parties. On July 6, 2020, Clearview AI has advised Canadian privacy protection authorities that, in response to their joint investigation, it will cease offering its facial recognition services in Canada. This step includes the indefinite suspension of Clearview AI\u2019s contract with the RCMP, which was its last remaining client in Canada.\u00a0 An App that is banned to operate in Canada would certainly not be used by a law enforcement agency such as the CBSA.\u00a0 Minister\u2019s counsel, an officer of the Court, as the Respondent\u2019s counsel is, is not privy to providing an affidavit stating the methodology used in procuring the evidence presented to the parties at the hearing. I concur with the Minister\u2019s counsel that to use it would be violating the Privacy Act as mentioned by counsel.\u00a0 Respondent\u2019s counsel\u2019s motion is denied.\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/ca\/irb\/doc\/2021\/2021canlii152060\/2021canlii152060.html?resultId=fadd63ef873043f88c8dc12e1d19e365&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Ontario Labour Relations Board",
    "caseName":"Michael Joseph Murphy v Ontario Public Service Employees Union",
    "year":2023,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The applicant alleged that his union, OPSEU, failed to fairly represent him after his termination, which he linked to his public complaints about racism. The Board noted that Murphy\u2019s submissions were assisted by ChatGPT but did not assess the tool\u2019s reliability, instead emphasizing that submissions must be evaluated on their content rather than their method of generation.",
    "excerpt":"\"12.\u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0 Mr. Murphy filed lengthy submissions in response to the motion before the Board. He was assisted in those submissions by ChatGBT, an artificial intelligence chat box. Both OPSEU and the Ministry assert that the Board should be cautious of these submissions because ChatGBT has generated an inaccurate list of what Mr. Murphy says are relevant cases and therefore the Board should treat the submissions with extreme caution. I make no comments about the reliability or accuracy of the ChatGBT platform or its helpfulness in creating submissions used in the course of legal proceedings.\u00a0 Ultimately, the Board must assess a party\u2019s position based upon the contents of the submissions.\u00a0\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/on\/onlrb\/doc\/2023\/2023canlii43759\/2023canlii43759.html?resultId=4d462ccaa13e4fe29f48d264ae66b1db&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"British Columbia Human Rights Tribunal ",
    "caseName":"Duarte v. City of Richmond",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"Nathan Duarte cited three legal cases to support his claims, but the City of Richmond argued that these cases were likely fabricated by a generative AI tool, as they could not be found in legal databases and appeared inconsistent with standard case law citation practices. The Tribunal rejected Duarte\u2019s cited cases, cautioning against the risks of using AI-generated legal references without verification. It emphasized that parties must critically assess AI outputs to avoid submitting fabricated information.",
    "excerpt":"\"[52]\u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0 I pause here to note that Mr. Duarte provided three cases which he states stand for the position that this Tribunal has previously recognized union affiliation as a basis for protection against discrimination. Although he provides the names and years of these cases, he does not provide citations. The City says it tried to review these decisions but could not find them. I also could not find the cases in my own searches. The City offers the conclusion that the cases either do not exist or were fabricated by a generative artificial intelligence [AI] application. The City points to one example cited by Mr. Duarte: \u201cR v. C.P. Rail (1994).\u201d The City says the \u201cR\u201d suggests a criminal case, and Canada Pacific Railway is a federally-regulated organization. Further, the City says the Tribunal does not have authority over criminal or federal matters, and the Canadian Human Rights Act, which does apply to federal organizations, does not include political belief as a protected characteristic. As a result, the City says it is unlikely that any such case was decided by either this Tribunal or the Canadian Human Rights Tribunal.\n\n[53]\u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0 While it is not necessary for me to determine if Mr. Duarte intended to mislead the Tribunal, I cannot rely on these \u201cauthorities\u201d he cites in his submission. At the very least, Mr. Duarte has not followed the Tribunal\u2019s Practice Direction for Legal Authorities, which requires parties, if possible, to provide a neutral citation so other participants can access a copy of the authority without cost. Still, I am compelled to issue a caution to parties who engage the assistance of generative AI technology while preparing submissions to the Tribunal, in case that is what occurred here. AI tools may have benefits. However, such applications have been known to create information, including case law, which is not derived from real or legitimate sources. It is therefore incumbent on those using AI tools to critically assess the information that it produces, including verifying the case citations for accuracy using legitimate sources. Failure to do so can have serious consequences. For lawyers, such errors have led to disciplinary action by the Law Society: see for example, Zhang v Chen, 2024 BCSC 285. Deliberate attempts to mislead the Tribunal, or even careless submission of fabricated information, could also form the basis for an award of costs under s. 37(4) of the Code.\u00a0 The integrity of the Tribunal\u2019s process, and the justice system more broadly, requires parties to exercise diligence in ensuring that their engagement with artificial intelligence does not supersede their own judgement and credibility.\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/bc\/bchrt\/doc\/2024\/2024bchrt347\/2024bchrt347.html?resultId=0fc14be718ae4990ba0f0e35bd54c354&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Court of Qu\u00e9bec",
    "caseName":"R. c. Larouche",
    "year":2023,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"This case is the first in Canada to address the use of deepfake technology in the creation of child pornography. The court ruled that while the use of deepfake technology was novel, it did not alter the fundamental nature of the offence of producing child pornography. Despite the lack of evidence of distribution, the court imposed a 42-month sentence, emphasizing the ongoing harm to victims and the need for deterrence.",
    "excerpt":"\"The use of deepfake technology by criminals is chilling. This type of software makes it possible to commit crimes that could involve practically every child in our communities. A simple video excerpt of a child on social media or a surreptitious screenshot of children in a public place could transform them into potential child pornography victims. All a cybercriminal has to do is sequence the video and exchange the child\u2019s face with the face of a sexual assault victim found online. New files are thus created and the children\u2019s sexual and psychological image and integrity are irreparably harmed, with the potential for that file to be disseminated everywhere on the Internet, without any control.\n[71]\u00a0\u00a0 \u00a0\u00a0 \u00a0 Production of child pornography is fueled by the market for it, and the market in turn is fueled by those who seek to possess it.[41] This market, on the lookout for anything new, is thus being fuelled by the creation of new files, be they genuine or deepfakes.\n\n[72]\u00a0\u00a0 \u00a0\u00a0 \u00a0 It should be recalled that the harms of child pornography are known and many: child pornography promotes cognitive distortions in offenders by banalizing the awful. It fuels fantasies that incite sexual offences against children. It is used to groom and seduce victims and leads others to produce new material to fuel the market of possession[42] by assaulting and abusing real children. By producing this type of content, the offender is serving this market of cruelty to children.\n\n(\u2026)[75]\u00a0\u00a0 \u00a0\u00a0 \u00a0 While it is true that children were not sexually assaulted again or exploited in another way to make this new material, the fact remains that their image and their sexual integrity related to this image was again violated. However, it would be contrary to the philosophy of our criminal law (and would be an error of law) for a person to suffer a disproportionate punishment simply to send a message to discourage others from offending.[43] The court\u2019s primary role is to impose fair punishments.[44]\n\n[76]\u00a0\u00a0 \u00a0\u00a0 \u00a0 In this sense, using technology to make deepfake material does not substantially change the essence of the offence of making child pornography. While the case at bar is unique because of the technology used, this does not mean that it should be treated exceptionally. Whether it was made using technology to create deepfake photos or videos or using better-known technologies matters little when determining the fit sentence. Potential offenders will understand from the sentence imposed that they cannot expect any special leniency from the Court by claiming that they are [translation] \u201cmere tinkerers\u201d using existing images of abused children. They will face the same punishments.\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/qc\/qccq\/doc\/2023\/2023qccq1853\/2023qccq1853.html?resultId=8917bec279eb4504a18a26ad7308ab93&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"British Columbia Civil Resolution Tribunal",
    "caseName":"Geismayr v. The Owners",
    "year":2025,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The complainants bought a condo unit with unauthorized alterations and sought retroactive approval from the strata, which was denied. The tribunal rejected their claim, finding the strata\u2019s refusal was not significantly unfair and highlighting that the applicants relied on hallucinated case law from an AI chatbot (Copilot), which misrepresented the legal framework.",
    "excerpt":"\"25.\u00a0\u00a0 The Geismayrs\u2019 submissions reference ten decisions where they say courts ruled that a strata could not force the removal of strata lot alterations. These cases have the parties\u2019 names and the years published, but no legal citation. Nine of these cases do not exist. The remaining case, \u201cThe Owners, Strata Plan LMS 2768 v. Jordison (2013)\u201d, has three court decisions published in 2013, however, none of these are related to unauthorized alterations. The Geismayrs listed the source of these cases as a \u201cConversation with Copilot\u201d which is an artificial intelligence chatbot. I find it likely that these cases are \u201challucinations\u201d where artificial intelligence generates false or misleading results.\n\n26.\u00a0\u00a0 The state of the law is very different than what Copilot reported. Multiple CRT decisions say that owners cannot reasonably expect retroactive approval for alterations done without the strata\u2019s prior authorization. For recent examples, see Champoux v. The Owners, Strata Plan EPS5773, 2024 BCCRT 522, Liang v. The Owners, Strata Plan LMS 2195, 2024 BCCRT 1244, and Duck v. The Owners, Strata Plan K196, 2024 BCCRT 1300.\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/bc\/bccrt\/doc\/2025\/2025bccrt217\/2025bccrt217.html?resultId=b942d4cd19a846278bf74d005ee595be&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Court of Quebec",
    "caseName":"R. c. Pryde",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"In R. v. Pryde, the accused chose an English-language criminal trial, but a new Quebec law required that the final written judgment be filed with a simultaneous French translation, causing delays. The Court found that the mandatory simultaneous translation under s. 10 of the Charter of the French Language would delay verdicts in English trials, violating federal language rights under the Criminal Code and interfering with judicial independence. The Court rejected the Attorney-General\u2019s suggestion that AI translations could solve the issue, as sharing draft judgments with AI tools for pre-release translation posed serious confidentiality risks and was inappropriate. Even if AI could speed up translation, the judgment process is fluid and last-minute edits are common, making instant, secure translation unfeasible and incompatible with judicial practice.",
    "excerpt":"\"[163]\u00a0\u00a0 \u00a0 Deep in the schedules to the second affidavit, the Attorney-General\u2019s materials allude to \u201ctranslation tools\u201d (i.e., software) and artificial intelligence that could hopefully streamline the translation process and make it quick and efficient. Software and artificial intelligence to translate the carefully chosen, carefully crafted words, expressions, terms of art and legal standards that a judge meticulously ponders during the drafting process. The language of Shakespeare might be converted to the language of Moli\u00e8re by way of R2D2.\n\n[164]\u00a0\u00a0 \u00a0 Of course, that is the government\u2019s prerogative. Whether this is a good or bad idea is not for the Court to decide. Whether this will render legal translators obsolete cannot be the Court\u2019s concern. The government is free to opine: if artificial intelligence can write simulations of Drake and Taylor Swift songs, it must be able to accurately translate legal decisions dealing with citizens\u2019 liberty interests, right? Ultimately, this is a political decision about administrative operations. Only the electorate can determine the wisdom of this approach or otherwise criticize its appropriateness.\n\n[165]\u00a0\u00a0 \u00a0 That being said, it is important to recall that a draft-judgment, until the exact moment it is publicly filed in open court, must remain extremely confidential, privileged and protected. A draft-judgment is never to be passed around. Granted, such a document may be shared with a human, breathing legal secretary in some cases. However, the wisdom of entrusting a highly sensitive draft-judgment to software or artificial intelligence in the pre-release stage is alarming to say the least.\n\n[166]\u00a0\u00a0 \u00a0 Indeed, the same concerns apply equally to the prospect of sending unpublished, pre-release judgments to human interpreters at SOQUIJ. Such a practice would be highly inappropriate.\n\n[167]\u00a0\u00a0 \u00a0 On another note, even assuming that software or artificial intelligence will dramatically increase the speed of the translation, the process will still not be instantaneous. It is not uncommon that a judge drafts (and edits, and re-edits, and re-edits, and re-edits) his reasons until the day before their delivery. Sometimes, he makes changes until the morning of. That is the lot of judges sitting in high volume metropolitan districts.\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/qc\/qccq\/doc\/2024\/2024qccq1794\/2024qccq1794.html?resultId=da072c52c41742be9cc6497c704633a9&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Ontario Law Society Tribunal Hearing Division",
    "caseName":"Law Society of Ontario v. Henry",
    "year":2022,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"In Law Society of Ontario v. Henry, lawyer Shirley Henry was found to have engaged in professional misconduct by borrowing money from a vulnerable elderly client and encouraging her to invest in a fraudulent scheme (HKCG), while misrepresenting her role and fabricating evidence during the investigation.\nThe Tribunal determined that Henry acted while in a clear conflict of interest, borrowing $5,000 from her client without disclosure or independent legal advice, and later facilitating the client\u2019s investment in HKCG, a fictitious company. Henry promoted the investment knowing or disregarding that it showed multiple red flags (e.g., implausibly high returns, offshore accounts, use of aliases, AI-generated trading claims).",
    "excerpt":"\"[24]\u00a0\u00a0 \u00a0\u00a0 \u00a0 Any enquiries Ms. Henry made of the investment opportunity concerned only the 20% administration fee which, according to her research, was higher than other online trading forums. Ms. Henry advised that her concerns were purportedly alleviated when Mr. Bisram explained that higher fees were warranted because \u201cthe expense is all on [HKCG\u2019s] side,\u201d given that the HKCG platform purportedly relied on artificial intelligence which automatically made trade decisions on behalf of investors, and which required investment from HKCG above and beyond what was traditionally needed for a trading platform.\n\n[25]\u00a0\u00a0 \u00a0\u00a0 \u00a0 Ms. Henry advised that she was satisfied with this explanation and with her own due diligence which involved simply looking up the company online and \u201cit seemed like it was a legitimate company.\u201d\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/on\/onlst\/doc\/2022\/2022onlsth106\/2022onlsth106.html?resultId=5175e6f0004c48ec9f1f83c144ddf605&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Federal Court",
    "caseName":"Farshid v. Canada",
    "year":2024,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The complainant alleges the immigration officer unfairly relied on AI, specifically the Chinook tool, to generate a quick rejection without properly assessing their case. However, the court ruled that there was no evidence that the use of Chinook led to procedural unfairness, as the decision was made by a human officer and aligned with immigration regulations.",
    "excerpt":"\"[12] As a preliminary point, I wish to address the Applicant\u2019s submission that the GCMS notes disclose not only that the Applicant\u2019s file was processed with the assistance of an artificial intelligence tool, \u201c\u201cChinook 3+,\u201d\u201d but that the Decision was made by Chinook 3+ before the Officer even accessed the file. The impact of this observation is far from clear and invites speculation, none of which changes the Court\u2019s role in judicial review, which is to look at the decision and determine whether it is both reasonable and procedurally fair (Haghshenas v Canada (Citizenship and Immigration), 2023 FC 464 at para 24).\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2024\/2024fc1573\/2024fc1573.html?resultId=70ff83ab73164635b5918ba9ac962ef8&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Social Security Tribunal",
    "caseName":"KM v. Canada Employment Insurance Commission",
    "year":2024,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The Tribunal ruled that the appellant must repay employment insurance parental benefits he mistakenly received. Although the appellant argued the Commission should have used AI or software to detect the error earlier, the Tribunal acknowledged this technological gap but emphasized that legal provisions make the first parent\u2019s choice binding and overpayments repayable regardless of administrative delays.",
    "excerpt":"\"[17] For the sake of completeness, I would note that I agree with the Appellant on this point. It would seem to me that, our age of technology and sophisticated artificial intelligence, the Commission should be able to implement a computer program or software that could conduct an initial vetting of an individual\u2019s EI claim for parental benefits. The fact is that parents across Canada are routinely making the same mistake the Appellant has made and are accidentally applying for a type of parental benefits they are not entitled to receive. I personally have heard numerous appeals that address this same issue. Parents are also routinely making the mistake of applying to receive too many weeks of benefits over and above the 40-week combined maximum for standard parental benefits or the 69 combined week maximum for extended parental benefits. I personally have also heard numerous appeals that address this same issue. In almost all of these cases, the individuals end up accidentally receiving parental benefits they are not entitled to receive and are then compelled to re-pay the Commission sometimes thousands of dollars in overpayments. This problem is compounded because, as the Commission obviously has a heavy workload, it often does not notice these mistakes until many months or sometimes years after the individual has already received their parental benefits. The large overpayments that individuals like the Appellant face could easily be avoided if the Commission were proactively vetting applications and catching these very obvious mistakes earlier in the application process.\n\n[18] However, regardless of how articulately the Appellant voiced his concerns and regardless of my opinion on this matter, the fact remains that the Appellant chose to receive standard parental benefits that he was not entitled to receive.\u201d",
    "link":"https:\/\/www.canlii.org\/en\/ca\/sst\/doc\/2024\/2024sst594\/2024sst594.html?resultId=b84379d9b6cb4408bf1b1fffe926a65c&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Calgary Assessment Review Board",
    "caseName":"CARB 188903M-2024",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The Calgary Assessment Review Board rejected a tax exemption request after the complainant submitted potentially AI-generated fake legal citations. The Board noted concerns over the unreliability of AI tools like ChatGPT for legal research, gave no weight to unverified or outdated materials, and found the complainant did not meet the legal threshold for exemption.",
    "excerpt":"\"[1]\u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0 The Respondent raised a preliminary matter regarding three legal cases cited in the Complainant\u2019s rebuttal document (page 619, pp 44-46, consolidated document). The Respondent challenged the authenticity of the cases since they could not be found using standard case research sources. The Respondent questioned whether the citations may have been generated by an artificial intelligence (AI) tool such as ChatGPT.\n\n[2]\u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0 The Complainant claimed that he had read the three references in an article. The Complainant confirmed that the cases could not be located through standard research sources and that he could not confirm their authenticity. On that basis, the Complainant suggested that the Board put no weight on those references.\u00a0 The Complainant did not provide a reference to the alleged article.\n\n[3]\u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0 The Respondent agreed not to press the issue any further given the Complainant\u2019s position. The Board agreed to ignore the cases and proceeded with the merit hearing.\u00a0 The Board notes that the issue of the potential submission of AI generated false legal citations is of grave concern, and that the issue would be referred to the General Chair of the Board to consider what actions may be appropriate to prevent this type of incident from recurring.\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/ab\/abcgyarb\/doc\/2024\/2024abcgyarb2188903\/2024abcgyarb2188903.html?resultId=7c6ea0ce08aa4d98adfeeec70cbaf2c9&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Ontario Superior Court of Justice",
    "caseName":"R. v. Galleon",
    "year":2025,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"In R. v. Gallerno, 2025 ONSC 236, the court found Mr. Gallerno guilty of aggravated assault based primarily on video surveillance evidence, despite challenges to its chain of custody and suggestions that it might have been altered or unreliable. The judge acknowledged flaws in the Crown\u2019s handling of the video and chain of custody but ruled that the possibility of AI manipulation or fabrication was speculative and unsupported by evidence, and the combination of circumstantial and corroborating evidence proved Gallerno\u2019s identity and guilt beyond reasonable doubt.",
    "excerpt":"\"[12]\u00a0\u00a0 \u00a0\u00a0 \u00a0\u00a0 \u00a0 First, there is simply no evidence whatsoever that the clip in question was faked and the circumstantial evidence renders that hypothesis unlikely:\na.\u00a0\u00a0 \u00a0\u00a0 It was received by the police portal on the morning of February 10, 2023 (less than a day after it was requested by the special constable calling the number posted on the building) even if not forwarded internally by police to the special constable until February 14, 2023.\u00a0 The sender was from an email domain name identified as being apparently the same organization that the special constable had contacted and recorded the name of in his notes.\u00a0\nb.\u00a0\u00a0 \u00a0\u00a0 The clip itself did not \u201csolve\u201d the crime but provided an image of a face which, when run through facial recognition software provided police with a lead on the identity of the assailant after some delay.\u00a0 On a stand-alone basis, the evidence was nothing resembling conclusive or even reliable evidence by itself.\u00a0 It took the circumstances of luck (that Mr. Gallerno had other contemporary filmed interactions with police), legwork and many weeks of effort to proceed from a clip uploaded to the case file on February 14, 2023 until Det. Pischedda had the grounds for the search warrant he sought on April 20, 2023.\u00a0 As noted, he did not even realize that the uploaded clip captured the incident until he viewed it on April 8, 2023 \u2013 almost two months following its receipt.\u00a0 Further, February 2023 is long before the advent of and broad access to artificial intelligence tools for the relatively swift creation of faked videos.\u00a0\n\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/on\/onsc\/doc\/2025\/2025onsc236\/2025onsc236.html?resultId=427f9381e42042ddbd7b05c6e3958040&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Federal Court",
    "caseName":"Hassan v. Canada",
    "year":2023,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The Federal Court upheld the Refugee Protection Division\u2019s decision to vacate the applicant\u2019s refugee status under s. 109 of the IRPA, finding she had misrepresented her identity. Arguments that facial recognition technology had been used were dismissed as speculative and unsupported by evidence. The Court also held there was no breach of procedural fairness.",
    "excerpt":"\"However, at the hearing before the RPD, counsel for the Applicant conceded that he had no evidence that the Minister or CBSA was using artificial intelligence and accepted that they were not using Clearview AI, but was of the view that it \u201c\u201cdefied logic\u201d\u201d to suggest that they located the photos and information about Ms. Mohamed by other means.\u201d",
    "link":"https:\/\/www.canlii.org\/en\/ca\/fct\/doc\/2023\/2023fc1550\/2023fc1550.html?resultId=5b624a9343ec4e12b3efc4d6f9b3f082&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Court of Appeal for British Columbia",
    "caseName":"R. v. Dancho",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"In R. v. Dancho, 2024 BCCA 393, the appellant sought to appoint counsel under s. 684 of the Criminal Code to assist with an appeal concerning a denied extension of time to challenge a guilty plea. Among his arguments, Mr. Dancho emphasized the role of Artificial Intelligence (AI), stating that without appointed legal counsel, he would be forced to rely on AI tools to conduct legal research, tools he claimed were inadequate and prone to error, especially for a layperson. Justice Horsman acknowledged the appellant\u2019s concerns about the difficulties of navigating the legal system without representation, but was not persuaded the grounds of appeal were meritorious.",
    "excerpt":"\"e)\u00a0\u00a0 The issues raised on Mr.\u00a0Dancho\u2019s proposed appeal are complex. The case exposes fundamental issues about access to justice, and the impact of administrative errors on persons with cognitive impairments. Without the assistance of counsel, Mr.\u00a0Dancho would be left having to rely on Artificial Intelligence (\u201cA.I.\u201d) to assist his legal research, which will lead to errors in the information he provides to the Court. The limits of A.I. demonstrate the essential role of counsel in presenting the legal issues within their proper jurisprudential context.\n\u201c",
    "link":"https:\/\/www.canlii.org\/en\/bc\/bcca\/doc\/2024\/2024bcca393\/2024bcca393.html?resultId=bed9a969297b4600afe3fb077c2262c4&searchId=2025-03-04T13:54:29:726\/28f0db0452594e6c9f03a70ccb396c3d&searchUrlHash=AAAAAQAZImFydGlmaWNpYWwgaW50ZWxsaWdlbmNlIgAAAAAB",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"British Columbia Civil Resolution Tribunal",
    "caseName":"Moffatt v. Air Canada",
    "year":2024,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"In Moffatt v. Air Canada, the Civil Resolution Tribunal ruled that Air Canada was liable for misleading information provided by its chatbot, which falsely indicated that bereavement fare refunds could be requested retroactively. The Tribunal found that Air Canada negligently misrepresented its policy by failing to ensure its AI chatbot\u2019s information aligned with its official webpage, and held the airline responsible for the chatbot\u2019s misleading statements.",
    "excerpt":"\"Air Canada argues it cannot be held liable for information provided by one of its agents, servants, or representatives \u2013 including a chatbot. It does not explain why it believes that is the case. In effect, Air Canada suggests the chatbot is a separate legal entity that is responsible for its own actions. This is a remarkable submission. While a chatbot has an interactive component, it is still just a part of Air Canada\u2019s website. It should be obvious to Air Canada that it is responsible for all the information on its website. It makes no difference whether the information comes from a static page or a chatbot.\n\n28.\u00a0\u00a0 I find Air Canada did not take reasonable care to ensure its chatbot was accurate. While Air Canada argues Mr. Moffatt could find the correct information on another part of its website, it does not explain why the webpage titled \u201cBereavement travel\u201d was inherently more trustworthy than its chatbot. It also does not explain why customers should have to double-check information found in one part of its website on another part of its website.\n\n29.\u00a0\u00a0 Mr. Moffatt says, and I accept, that they relied upon the chatbot to provide accurate information. I find that was reasonable in the circumstances. There is no reason why Mr. Moffatt should know that one section of Air Canada\u2019s webpage is accurate, and another is not.\"",
    "link":"https:\/\/www.canlii.org\/en\/bc\/bccrt\/doc\/2024\/2024bccrt149\/2024bccrt149.html",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"British Columbia Supreme Court",
    "caseName":"CanLII v. Caseway AI Legal",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"CanLII is suing Caseway AI for allegedly using millions of its legal records to train and power a legal chatbot, claiming both copyright infringement and violation of its website\u2019s terms of service. The case is notable for raising questions about the copyrightability of enhanced public legal materials and for including claims related to the chatbot\u2019s ongoing distribution of CanLII content.",
    "excerpt":"-",
    "link":"https:\/\/archive.org\/details\/notice-of-civil-claim",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Canada",
    "court":"Ontario Superior Court of Justice",
    "caseName":"Toronto Star Newspapers Limited et al v. OpenAI, Inc et al",
    "year":2024,
    "issue":"Intellectual property",
    "finalDecision":"No",
    "summary":"The complainant alleges their content were used to train AI without their consent, infringing on their copyright.",
    "excerpt":"-",
    "link":"https:\/\/litigate.com\/CanadianNewsMediaCompaniesvOpenAI",
    "lat":56.1304,
    "lng":-106.3468
  },
  {
    "region":"Australia",
    "court":"Federal Court of Australia",
    "caseName":"Commissioner of Patents v Thaler",
    "year":2022,
    "issue":"Intellectual property",
    "finalDecision":"Yes",
    "summary":"The Australian Full Federal Court ruled that an artificial intelligence system like DABUS cannot be considered an \u201cinventor\u201d under the Patents Act 1990 (Cth) and its Regulations, overturning a prior decision that had allowed it. The Court held that the statutory language and legislative history of Australian patent law clearly assume that an inventor must be a natural person, as only a human can generate the \u201cinventive concept\u201d that forms the basis of patent entitlement. While acknowledging the growing role of AI in innovation, the Court emphasized that any policy change to include AI as inventors must come from legislative reform, not judicial interpretation.",
    "excerpt":"\"\tFirst, in filing the application, Dr Thaler no doubt intended to provoke debate as to the role that artificial intelligence may take within the scheme of the Patents Act and Regulations. Such debate is important and worthwhile. However, in the present case it clouded consideration of the prosaic question before the primary judge, which concerned the proper construction of s 15 and reg 3.2C(2)(aa). In our view, there are many propositions that arise for consideration in the context of artificial intelligence and inventions. They include whether, as a matter of policy, a person who is an inventor should be redefined to include an artificial intelligence. If so, to whom should a patent be granted in respect of its output? The options include one or more of: the owner of the machine upon which the artificial intelligence software runs, the developer of the artificial intelligence software, the owner of the copyright in its source code, the person who inputs the data used by the artificial intelligence to develop its output, and no doubt others. If an artificial intelligence is capable of being recognised as an inventor, should the standard of inventive step be recalibrated such that it is no longer judged by reference to the knowledge and thought processes of the hypothetical uninventive skilled worker in the field? If so, how? What continuing role might the ground of revocation for false suggestion or misrepresentation have, in circumstances where the inventor is a machine?\n\tThose questions and many more require consideration. Having regard to the agreed facts in the present case, it would appear that this should be attended to with some urgency. However, the Court must be cautious about approaching the task of statutory construction by reference to what it might regard as desirable policy, imputing that policy to the legislation, and then characterising that as the purpose of the legislation: Deal at [37]; Miller v Miller [2011] HCA 9; 242 CLR 446 at [29] (French CJ, Gummow, Hayne, Crennan, Kiefel and Bell JJ). It would appear that this was the approach favoured by the primary judge. \n\u201c",
    "link":"https:\/\/jade.io\/article\/912670?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"County Court of Victoria at Melbourne Criminal Division",
    "caseName":"Director of Public Prosecutions v. Robin James Smith",
    "year":2024,
    "issue":"Criminal justice",
    "finalDecision":"Yes",
    "summary":"The complainant was charged with using AI to produce CSAM material, and was convicted and sentenced to 4 months imprisonment.",
    "excerpt":"\"The use of AI to generate pornography is in its relevant infancy but is fast proliferating. In the sense that there is no evidence that your content did not use images of real children it can be likened to pornography using animated cartoons or drawings.\n18\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Whilst no real children were harmed in the making of these images, Courts have observed that child exploitation material tends to normalise exploitative sexual activity involving children[6]. It serves to fuel the demand for such material, and may tend to encourage viewers to take a step further and move from the fictitious to the real world, and harm real children. In your case you moved from the production of A.I. child abuse material for personal use, to the transmission of text based material with a live recipient.\u201d",
    "link":"https:\/\/jade.io\/article\/1085050?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Federal Circuit and Family Court of Australia",
    "caseName":"Valu v. Minister for Immigration and Multicultural Affairs",
    "year":2020,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The Court referred a solicitor to the NSW Legal Services Commissioner after he filed submissions containing fake case citations and quotes generated by ChatGPT. Despite expressing remorse and attributing the error to health issues and unfamiliarity with AI, the Court found the conduct fell below professional standards and warranted regulatory scrutiny due to the public interest in addressing AI misuse in legal practice",
    "excerpt":"\"\tThe conduct of the ALR, in filing an application and submissions which contained citations to Federal Court of Australia cases which do not exist and alleged quotes from the Tribunal\u2019s decision which do not exist, falls short of the standard of competence and diligence that the applicant in the substantive proceedings was entitled to expect from his legal representative. The conduct also falls short of a legal practitioner\u2019s duty to the Court, including the duty to ensure that the Court is not deceived or mislead, even if unintentionally: r 19.1 of the Conduct Rules.\n\u201c",
    "link":"https:\/\/jade.io\/article\/1115083?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Federal Circuit and Family Court of Australia",
    "caseName":"Handa & Mallick",
    "year":2023,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"A solicitor tendered a list of legal authorities at a family law enforcement hearing that could not be verified. The list was generated using LEAP, a legal software package employing AI. The Court gave the practitioner one month to explain why his conduct should not be referred to the Victorian Legal Services Board and Commissioner, citing concerns about competence and ethics arising from reliance on inaccurate AI-generated material.",
    "excerpt":"\"\tWhen the matter returned to court, I asked Mr B if the list of authorities had been provided using artificial intelligence. He informed me the list had been prepared from LEAP, being a legal software package, as I understand it, used for legal practice management and other purposes. I asked if LEAP relies on artificial intelligence. He indicated that it does, answering \u201cthere is an artificial intelligence for LEAP.\u201d I foreshadowed making procedural orders later in the day, requiring Mr B to provide an explanation as to what had occurred. Mr B clarified this afternoon that he prepared the list of authorities and not Ms Aus Lawyers. \n\tI informed the parties and their legal representatives this morning that as a concern had arisen in relation to the veracity of information provided in the list of authorities, a concern had in turn been raised in relation to the competency and ethics of Mr B. In light of what transpired, I asked that the husband be assisted to seek advice from a duty lawyer in relation to Mr B continuing to assist him today. The husband has been present in court throughout these discussions. He informed the court via Mr B and also directly in court after seeing the duty lawyer that he is comfortable for Mr B to continue assisting him today.\u00a0 \n\u201c",
    "link":"https:\/\/jade.io\/article\/1088721?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Federal Circuit and Family Court of Australia",
    "caseName":"Dayal MLC 10532\/2024",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"A solicitor submitted a list of case authorities generated by AI that turned out to be entirely fictitious. He admitted he did not verify the content before filing it and offered an unconditional apology. Despite expressing remorse and taking remedial steps, the Court referred him to the Victorian Legal Services Board and Commissioner, citing public interest and the need for professional oversight in the use of AI tools in litigation.",
    "excerpt":"\"The solicitor has acknowledged a breach of the professional standards expected of a solicitor in this court, by his conduct in tendering a list and summary of authorities that do not exist, generated without disclosing the source of the information presented to the court and without verifying its accuracy. \u00a0\n\u201c",
    "link":"https:\/\/jade.io\/article\/1092470?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Administrative Review Tribunal",
    "caseName":"Body by Michael Pty Ltd v. Industry Innovation and Science Australia",
    "year":2025,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The party was reprimanded for using AI for legal research, as it led to references to non-existent cases. ",
    "excerpt":"\"\tThe use of artificial intelligence: Finally, in cross-examination Mr Abdallah conceded that Chat GPT had been used to assist in the preparation of the BBM SFIC. BBM had, prior to the hearing, asked that paragraphs\u00a035\u201337 of the BBM SFIC be withdrawn and not considered by the Tribunal. This was because those paragraphs contained references to non-existent cases. It appears that this matter had been drawn to BBM\u2019s attention by IISA, rather than BBM identifying this problem, but that is unclear. Nevertheless, due to that withdrawal being requested prior to the hearing, I have not considered those paragraphs, these reasons for decision do not take account of those paragraphs and I merely make some general comments below applicable to all parties that appear before the Tribunal. \n\tThe use of Chat GPT is problematic for the Tribunal. It perhaps goes without saying that it is not acceptable for a party to attempt to mislead the Tribunal by citing case law that is non-existent or citing legal conclusions that do not follow, whether that attempt is deliberate or otherwise. All parties should be aware that the Tribunal checks and considers all cases and conclusions referred to in both parties\u2019 submissions in any event. This matter would have inevitably been discovered, and adverse inferences may have been drawn. To ensure no such adverse inferences are drawn, parties are encouraged to use publicly available databases to search for case law and not to seek to rely on artificial intelligence.[169] \u2028\u201c",
    "link":"https:\/\/jade.io\/article\/1114970?at.hl=%22artificial+intelligence%22&url.hash=_ftn2",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Supreme Court of Victoria Court of Appeal",
    "caseName":"Dilpreet Kaur v. Royal Melbourne Institute of Technology",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The party used AI for legal research and it led to references to non-existent cases, so the cases were not considered. ",
    "excerpt":"\"[19]\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0I note that several of these documents appeared to have been drafted with the assistance of a large language model artificial intelligence (\u2018LLM AI\u2019), such as ChatGPT. In particular, they contained some case citations to cases that do not exist. I have not reproduced those citations, lest they contribute to the problem of LLM AI inventing case citations.\n\u201c",
    "link":"https:\/\/jade.io\/article\/1106845?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Supreme Court of Tasmania",
    "caseName":"Natasha Lake v. Carli McConkey",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The party used AI for legal research and it led to references to non-existent and irrelevant cases.",
    "excerpt":"-",
    "link":"https:\/\/jade.io\/article\/1081902?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Queensland Industrial Relations Commission",
    "caseName":"Robertson v. McDonald\u2019s Australia Limited",
    "year":2023,
    "issue":"Bias",
    "finalDecision":"Yes",
    "summary":"The complainant alleged McDonald\u2019s used AI tools in its hiring process to infer age and prefer younger applicants. However, he failed\u2014after multiple attempts\u2014to clearly articulate how AI caused unlawful discrimination or how it related to his specific case and, thus, did not ground a viable discrimination claim.",
    "excerpt":"\"\tAs best as I can make out, Mr Robertson's complaint, in a very general sense, now seems to be that McDonald's uses an online recruitment system provided by a third-party which, by artificial intelligence and the provision of 'R.T.W documents' or right to work documents, determines the age of applicants and is biased in favour of applicants who would be considered 'Juniors'. Mr Robertson then contends that it is for this reason that he did not apply, online, for employment at the McDonald's Targo Street, Bundaberg 'outlet' after he noted an employment vacancy sign at that outlet. \n\tThis general complaint can only concern alleged discrimination in the pre-work area within the meaning of the Anti-Discrimination Act 1991.\n\tIn terms of what seems to be an allegation of direct discrimination, Mr Robertson does not clearly contend how McDonald's treated or proposed to treat him less favourably in the pre-work area within the meaning of s 14(a)-(f) of the Anti-Discrimination Act\u00a01991 when in fact he did not apply for the advertised vacant position at the McDonald's outlet in Bundaberg and when McDonald's (presumably) had no knowledge of him or of his age. The allegations about this issue are vague. McDonald's is left to interpret these paragraphs to be able to discern what is actually being alleged against it.\n\tSimilarly, in terms of what seems to be an allegation of indirect discrimination, Mr Robertson does not clearly contend how McDonald's imposed or proposed to impose a term on him such that he was the subject of unlawful discrimination in the pre\u2011work area within the meaning of s 14(a)-(f) of the Anti-Discrimination Act 1991. The alleged imposed term of 'Junior' is said to be '\u2026 clandestine, namely silent.' Mr Robertson does not clearly state how this term was imposed or proposed to be imposed on him when he did not apply for the vacant position at the McDonald's outlet in Bundaberg and when McDonald's (presumably) had no knowledge of him or of his age. Mr\u00a0Robertson does not contend why any such term, if indeed one was imposed or proposed to be imposed on him, was not reasonable.\u201d",
    "link":"https:\/\/jade.io\/article\/1035084?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Federal Court of Australia",
    "caseName":"Tickle v. Giggle for Girls Pty Ltd",
    "year":2023,
    "issue":"Bias",
    "finalDecision":"No",
    "summary":"A transgender woman was blocked from using the women-only app Giggle after an AI initially granted her access, leading her to allege gender identity discrimination.\nThe Court found her claim under the Sex Discrimination Act was reasonably arguable, warranting further examination at trial. Later, the court found that the denial amounter to indirect discrimination.",
    "excerpt":"-",
    "link":"https:\/\/jade.io\/article\/1087587?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Administrative Review Tribunal",
    "caseName":"QWYN and Commissioner of Taxation",
    "year":2025,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The party used AI for legal research and it led to references to non-existent cases.",
    "excerpt":"\"It has been noted by others that AI bots are prone to hallucinations.[35] That appears to be what has happened here. It is my assessment that submitting unverified material generated by AI, is not consistent with a party\u2019s duty to use their best endeavours to assist the Tribunal to achieve its statutory objectives. To expect the Tribunal to read and consider material which a party does not know is authentic impedes the Tribunal\u2019s attempts to provide a mechanism of review that ensures that applications are resolved as quickly and with as little expense as a proper consideration of the issues permits. \u00a0\u00a0\n\u201c",
    "link":"https:\/\/jade.io\/article\/1115994?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Federal Court of Australia",
    "caseName":"Luck v Principal Registrar and Chief Executive Officer of the Federal Court of Australia",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The party used AI for legal research and it led to references to non-existent cases.",
    "excerpt":"\"\tThe body of the rejected application was about 28 pages in length. The applicant informed the Court during the hearing that as an unrepresented litigant she had benefited from using artificial intelligence, or AI, technology in the preparation of her documents. She apologised in advance for the prospect that the Court might identify that some of the citations in her documents were not accurate. Indeed, there is at least one case cited by the applicant in her written material that does not exist. I will not identify it, lest it be picked up by other AI processes.\n\u201c",
    "link":"https:\/\/jade.io\/article\/1106072?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Federal Circuit and Family Court of Australia",
    "caseName":"Raj v. Minister for Immigration, Citizenship, Migrant Services and Multicultural Affairs",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The party used AI-created arguments to support his claim, indicating ChatGPT as the source. It was not considered precedent by the court, which indicated it was more of a philosophical contention than a legal argument",
    "excerpt":"\"\tThe Court has considered carefully the applicant\u2019s written submissions as well as the \u2018Notes re Ministerial Direction 69 and s 499 of the Migration Act, Context: rhetoric, mandate, propaganda\u2019 provided at hearing. The Court notes this last document is devoid of any reference to case law that might assist in supporting the propositions being put. Curiously, at page three of the document, Counsel for the applicant sets out questions he posed to ChatGPT. While the Court acknowledges the significant advances made in artificial intelligence tools freely available to the public, they have not reached the stage where they have been accepted by the Courts as either binding precedent or even of persuasive importance. The Court places little weight on this part of the document. Further, the document can best be described as putting forward more philosophical contentions rather than legal argument in the strict sense.\n\u201c",
    "link":"https:\/\/jade.io\/article\/1092760?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Federal Court of Australia",
    "caseName":"Australian Securities and Investments Commission v Union Standard International Group Pty Ltd",
    "year":2024,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"EuropeFX outsourced its marketing to third parties, which used deceptive online ads falsely promoting AI-powered automated Bitcoin trading endorsed by celebrities, leading inexperienced users to engage with EuropeFX. The Court found these ads mischaracterized the services offered, misleading consumers into believing they were accessing a simple, AI-driven investment tool, when in reality they were being funneled into complex and risky CFD trading. It held that the use of AI in the marketing was intentionally exploitative, targeting vulnerable consumers and forming part of a systemic and unconscionable strategy.",
    "excerpt":"\"\tThe webpage viewed by Mr Parry included effusive endorsements of that program by Mr Forrest, Mr Aly and other prominent people. The webpage stated that the program let the customer profit from various cryptocurrencies by \u201c[using] artificial intelligence (AI) to automatically handle long and short selling\u201d for the user so the user can \u201cmake money around the clock, even while you sleep\u201d. The webpage included instructions for registering online and depositing funds. A supposed user of the webpage reported that, as they navigated to the deposit page, they were contacted by an account manager.\n(\u2026)\tIn all the circumstances, I would readily infer and conclude, from the evidence as a whole, that EuropeFX utilised, most likely through its contracts with Affilimedia, BAFF and Bolacom, online advertisements, promotions and marketing techniques which sought to attract customers using the lure of a trading program, supposedly endorsed by prominent businesspeople and celebrities, that somehow enabled users to automatically trade in Bitcoin and other cryptocurrencies and thereby make handsome profits.\u00a0 I would also infer that those advertisements, promotions and marketing strategies were misleading and deceptive.\u00a0 While there was some evidence that EuropeFX may have facilitated trading in Bitcoin CFDs, the promotion identified by Mr Parry, and the promotions referred to by the witnesses and documentary evidence referred to earlier, concerned a program that involved automated Bitcoin trading.\u00a0 Moreover, there was no evidence whatsoever to suggest that any of the celebrities referred to in the promotional material had in fact endorsed EuropeFX\u2019s CFD and Margin FX Contract trading.\u00a0 The nature and content of the material would tend to support the inference that there were no such celebrity endorsements. \u00a0The absence of any evidence from any officer, employee or agent EuropeFX concerning its promotions and marketing makes those inferences all the easier to draw.\u00a0 I am not persuaded by any of the arguments advanced by EuropeFX about why those inferences cannot or should not be drawn.\n\u201c",
    "link":"https:\/\/jade.io\/article\/1112400?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Queensland Industrial Relations Commission",
    "caseName":"Goodchild v State of Queensland",
    "year":2025,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The party used AI for legal research and it led to references to non-existent cases.",
    "excerpt":"\"[39]\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0The Commission accepts the Applicant's explanation. Given that there appears to be significant doubt over whether the authorities cited by the Applicant represent actual decisions from the Fair Work Commission, I will give the authorities cited by the Applicant no weight in determining whether she has provided an explanation for the delay. This appears to be a salutary lesson for litigants in the dangers of relying on general search engines on the internet or artificial intelligence when preparing legal documents. \u2028\u201c",
    "link":"https:\/\/jade.io\/article\/1116887?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Federal Court of Australia",
    "caseName":"Selkirk v Hocking",
    "year":2023,
    "issue":"Civil liability",
    "finalDecision":"Yes",
    "summary":"The case involved a defamation claim over an AI-generated republication of a News Corp article on the MyLocalPages website about Simone Selkirk\u2019s overturned fraud conviction. The Court found that the AI-generated article, though poorly translated, substantially repeated existing public information and had extremely limited reach (only three views). Thus, the court considered no evidence was presented that the AI-generated article caused new or serious reputational harm, the claim was dismissed.",
    "excerpt":"\"\tThe evidence was that the MyLocalPages article was \u201ctranslated\u201d from the original, which had appeared in the mainstream press (News Corp), by some unidentified tool of artificial intelligence, in the process of \u201cfeeding\u201d it into what was described as the \u201cfiller section\u201d containing some 60,000 articles on the MyLocalPages website. The translation was in parts quite curious. To understand why I say that, I set out below the original article (annexed to the first statement of claim) and the article about which complaint is made in this proceeding (which I will refer to in these reasons as the article).\n(\u2026) \tThat which was \u201clost in translation\u201d is obvious enough.\u00a0 \u201cSimone Olivia will appeal after being found guilty\u201d became \u201cSimone Olivia will attraction soon after remaining uncovered responsible\u201d.\u00a0 \u201cWhere the items originated from remains a mystery, with the court hearing last year there were no records of the clothes and bedding ever being bought from the department stores\u201d became \u201cIn which the objects originated from stays a thriller, with the court docket hearing last 12 months there were being no records of the apparel and bedding ever staying acquired from the office merchants\u201d.\u00a0 \u201cSelkirk lodged an appeal\u201d became \u201cSelkirk lodged an attraction\u201d.\u00a0 \u201c[D]ishonestly obtain financial advantage by deception\u201d became \u201cdishonestly receive fiscal edge by deception\u201d. \u00a0And so on.\n (\u2026) \u201c",
    "link":"https:\/\/jade.io\/article\/1046308?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Administrative Review Tribunal",
    "caseName":"Johnstone and National Disability Insurance Agency",
    "year":2025,
    "issue":"Public services",
    "finalDecision":"Yes",
    "summary":"The applicant requested funding for a subscription to ChatGPT, arguing that the paid version provided significant support benefits over the free version, including task simplification and communication assistance. The Tribunal acknowledged the usefulness of ChatGPT and the applicant\u2019s awareness of its limitations but found that most benefits cited were available in the free version. It concluded that the paid version did not offer sufficient additional value to justify its cost and was therefore not a reasonable and necessary support.",
    "excerpt":"\"I agree with the Agency\u2019s contention that the paid version of ChatGPT does not represent value-for-money compared with the free version. I cannot see anything specifically in Mr\u00a0Widmer\u2019s report that deals with the additional advantages of the paid version. The bulk of the features which would reduce carer burden on Mrs Johnstone appear to be available in the free version. The Applicant\u2019s lived experience with the free version not being suitable is of some weight, but ultimately provides little else to support a finding that the paid version is value-for-money. I am not satisfied that the subscription to ChatGPT is a reasonable and necessary support.\n\u201c",
    "link":"https:\/\/jade.io\/article\/1117170?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Victorian Civil and Administrative Tribunal",
    "caseName":"Ekaterina Send v Department of Jobs, Precincts and Regions",
    "year":2023,
    "issue":"Privacy",
    "finalDecision":"No",
    "summary":"The complainant challenged the use of an AI tool, PredictiveHire (Phai), in a government recruitment process, alleging multiple privacy breaches, and the Victorian tribunal refused to summarily dismiss her complaint.\nThe Tribunal found that the claims, such as excessive collection of inferred personal data, lack of informed consent for AI use and data transfer, inadequate explanation of the personality profiling, and failure to ensure accuracy, raised serious factual disputes that could not be resolved without a full hearing.",
    "excerpt":"-",
    "link":"https:\/\/jade.io\/article\/1054628?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"Fair Work Commission",
    "caseName":"Candice Dias v Angle Auto Finance Pty Ltd",
    "year":2024,
    "issue":"Legal profession",
    "finalDecision":"Yes",
    "summary":"The party used AI for legal research and it led to references to non-existent cases.",
    "excerpt":"\"\tDespite presenting as actual cases from the Commission, Full Bench of the Commission and a Full Court of the Federal Court of Australia it is apparent that these are not cases related to the principles the Applicant advanced in opposition to the granting of legal representation or are not real cases. As will become apparent further in this decision, the Applicant has also advanced other cases that do not appear to be real in support of her substantive application. While it may not have been the intention of the Applicant to include references to incorrect or false case law, it seems likely that the source from which she has obtained this information, whether through artificial intelligence or otherwise, has provided or generated false information which she has sought to rely on. While we live in an information age and parties may seek to rely on sources of information extracted from an online and\/or artificial intelligence enabled environment, use of information that is not from a credible and\/or reliable source creates a risk that the information from such sources may be wrong or misleading and parties before the Commission should exercise caution in this regard. \n\u201c",
    "link":"https:\/\/jade.io\/article\/1114198?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"Australia",
    "court":"District Court of New South Wales",
    "caseName":"J&T v Department of Communities and Justice ",
    "year":2023,
    "issue":"Administrative use of AI",
    "finalDecision":"Yes",
    "summary":"The Court allowed an appeal by parents seeking to regain custody of their two daughters who had been placed with prospective adoptive carers by the Department of Communities and Justice. The Department\u2019s decision-making was based on flawed assumptions about the parents\u2019 mental health, which were perpetuated through a system resembling an uncritical, automated process, likened to a Kafkaesque operation of artificial intelligence.\n",
    "excerpt":"\"\tThose decisions emerged following a critical review of the evidence, not all of which was before the Children\u2019s Court at the prior hearing. That review identified the fact that in the lead-up to the hearing in that Court, and continuing into the de novo hearing in this Court, the Secretary\u2019s position was, in a material respect, based on a materially flawed premise which was then systemically perpetuated in a continuum, in a manner akin to a Kafkaesque operation of artificial intelligence in the departmental records system.\n\tThis occurred in circumstances where departmental caseworkers and managers were unable to reconsider and effectively override matters of systemically assumed child protection risks that, on the evidence that was readily available to them, ought to have been materially downgraded as to significance and likelihood of occurrence. \n\u201c",
    "link":"https:\/\/jade.io\/article\/971884?at.hl=\"artificial+intelligence\"",
    "lat":-25.2744,
    "lng":133.7751
  },
  {
    "region":"United States",
    "court":"District Court for the District of New Jersey",
    "caseName":"Cornish-Adebiyi et al v. Caesars Entertainment et al",
    "year":2024,
    "issue":"Antitrust",
    "finalDecision":"Yes",
    "summary":"The complainants allege a price-fixing conspiracy among Atlantic City casino-hotels facilitated by their shared use of Cendyn\u2019s Rainmaker algorithmic pricing software. The Court dismissed the claim with prejudice, finding that the complainants failed to plausibly allege any horizontal agreement or exchange of confidential data through the software.",
    "excerpt":"\"Another  significant  gap  in  the  Amended  Complaint  lies  in  the  unique  antitrust  theory \nPlaintiffs  have  proposed.  The  parallel  conduct  from  which  Plaintiffs  ask  this  Court  to  infer  an \nillegal  price-fixing  agreement  is  the  Casino-Hotels\n\u2019\n\u201cknowing\u201d  and  \u201cpurposeful\u201d  use  of  the \nRainmaker products. But how is their mere use of the specific software here suggestive of culpable \nconspiracy\n? Plaintiffs repeatedly and emphatically emphasize that the Casino-\nHotels \u201c\nknowingly \nprovid\ned\u201d their \u201cnon\n-publi\nc room pricing and occupancy data\u201d to the \nRainmaker  products. \nSee\nAm. Compl. \u00b6\u00b6 6, 9, 22, 24, 136, 139, 160, 205, 220\n\u2013\n21, 224\n\u2013\n26. As to how this data \nis used once \nit is handed over, Plaintiffs do not say. But that is precisely what appears to be missing. Without \nit, their antitrust theory \nis factually and legally incomplete.\u201d",
    "link":"https:\/\/law.justia.com\/cases\/federal\/district-courts\/new-jersey\/njdce\/1:2023cv02536\/512272\/139\/",
    "lat":37.0902,
    "lng":-95.7129
  }
]
